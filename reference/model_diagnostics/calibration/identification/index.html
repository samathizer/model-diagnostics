
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Tools for diagnostics and assessment of (machine learning) models">
      
      
        <meta name="author" content="Christian Lorentzen">
      
      
        <link rel="canonical" href="https://lorentzenchr.github.io/model-diagnostics/reference/model_diagnostics/calibration/identification/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../plots/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.31">
    
    
      
        <title>identification - Model Diagnostics</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model_diagnostics.calibration.identification" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Model Diagnostics" class="md-header__button md-logo" aria-label="Model Diagnostics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Model Diagnostics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              identification
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/lorentzenchr/model-diagnostics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lorentzenchr/model-diagnostics
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../.." class="md-tabs__link">
          
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../examples/regression_on_workers_compensation/" class="md-tabs__link">
          
  
  Examples

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../development/" class="md-tabs__link">
        
  
    
  
  Development

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="https://github.com/lorentzenchr/model-diagnostics/releases" class="md-tabs__link">
        
  
    
  
  Release Notes

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Model Diagnostics" class="md-nav__button md-logo" aria-label="Model Diagnostics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Model Diagnostics
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/lorentzenchr/model-diagnostics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lorentzenchr/model-diagnostics
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Home
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/regression_on_workers_compensation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Regression on Workers' Compensation Dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/quantile_regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quantile Regression on Synthetic Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../examples/classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Classification on Nursery Dataset
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    model_diagnostics
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1" id="__nav_3_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            model_diagnostics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    calibration
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            calibration
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    identification
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    identification
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification" class="md-nav__link">
    <span class="md-ellipsis">
      identification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="identification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification.compute_bias" class="md-nav__link">
    <span class="md-ellipsis">
      compute_bias
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification.compute_marginal" class="md-nav__link">
    <span class="md-ellipsis">
      compute_marginal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification.identification_function" class="md-nav__link">
    <span class="md-ellipsis">
      identification_function
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../plots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    plots
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_1_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../scoring/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    scoring
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            scoring
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../scoring/plots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    plots
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../scoring/scoring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scoring
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../development/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Development
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/lorentzenchr/model-diagnostics/releases" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Release Notes
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification" class="md-nav__link">
    <span class="md-ellipsis">
      identification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="identification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification.compute_bias" class="md-nav__link">
    <span class="md-ellipsis">
      compute_bias
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification.compute_marginal" class="md-nav__link">
    <span class="md-ellipsis">
      compute_marginal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification.identification_function" class="md-nav__link">
    <span class="md-ellipsis">
      identification_function
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>identification</h1>

<div class="doc doc-object doc-module">



<h2 id="model_diagnostics.calibration.identification" class="doc doc-heading">
            <code>identification</code>


<a href="#model_diagnostics.calibration.identification" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.identification.compute_bias" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_bias</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bin_method</span><span class="o">=</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.identification.compute_bias" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Compute generalised bias conditional on a feature.</p>
<p>This function computes and aggregates the generalised bias, i.e. the values of the
canonical identification function, versus (grouped by) a feature.
This is a good way to assess whether a model is conditionally calibrated or not.
Well calibrated models have bias terms around zero.
For the mean functional, the generalised bias is the negative residual
<code>y_pred - y_obs</code>.
See <a href="#model_diagnostics.calibration.identification.compute_bias--notes">Notes</a> for further details.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs) or (n_obs, n_models)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values, e.g. for the conditional expectation of the response,
<code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Some feature column.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights. If given, the bias is calculated as weighted average of the
identification function with these weights.
Note that the standard errors and p-values in the output are based on the
assumption that the variance of the bias is inverse proportional to the
weights. See the Notes section for details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The functional that is induced by the identification function <code>V</code>. Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile of quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> and <code>functional="expectile"</code> gives the mean.
<code>level=0.5</code> and <code>functional="quantile"</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of bins for numerical features and the maximal number of (most
frequent) categories shown for categorical features. Due to ties, the effective
number of bins might be smaller than <code>n_bins</code>. Null values are always included
in the output, accounting for one bin. NaN values are treated as null values.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bin_method</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The method to use for finding bin edges (boundaries). Options are:</p>
<ul>
<li><code>"quantile"</code></li>
<li><code>"uniform"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;quantile&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>df</code></td>            <td>
                  <code><span title="polars.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The result table contains at least the columns:</p>
<ul>
<li><code>bias_mean</code>: Mean of the bias</li>
<li><code>bias_cout</code>: Number of data rows</li>
<li><code>bias_weights</code>: Sum of weights</li>
<li><code>bias_stderr</code>: Standard error, i.e. standard deviation of <code>bias_mean</code></li>
<li><code>p_value</code>: p-value of the 2-sided t-test with null hypothesis:
  <code>bias_mean = 0</code></li>
</ul>
<p>If <code>feautre</code> is not None, then there is also the column:</p>
<ul>
<li><code>feature_name</code>: The actual name of the feature with the (binned) feature
  values.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><a href="" id="notes"></a>
A model <a href="" id="model_diagnostics.calibration.identification.compute_bias--notes"></a>
A model <span class="arithmatex">\(m(X)\)</span> is conditionally calibrated iff
<span class="arithmatex">\(\mathbb{E}(V(m(X), Y)|X)=0\)</span> almost surely with canonical identification
function <span class="arithmatex">\(V\)</span>.
The empirical version, given some data, reads
<span class="arithmatex">\(\bar{V} = \frac{1}{n}\sum_i \phi(x_i) V(m(x_i), y_i)\)</span> with a test function
<span class="arithmatex">\(\phi(x_i)\)</span> that projects on the specified feature.
For a feature with only two distinct values <code>"a"</code> and <code>"b"</code>, this becomes
<span class="arithmatex">\(\bar{V} = \frac{1}{n_a}\sum_{i \text{ with }x_i=a} V(m(a), y_i)\)</span> with
<span class="arithmatex">\(n_a=\sum_{i \text{ with }x_i=a}\)</span> and similar for <code>"b"</code>.
With case weights, this reads
<span class="arithmatex">\(\bar{V} = \frac{1}{\sum_i w_i}\sum_i w_i \phi(x_i) V(m(x_i), y_i)\)</span>.
This generalises the classical residual (up to a minus sign) for target functionals
other than the mean. See <code>[FLM2022]</code>.</p>
<p>The standard error for <span class="arithmatex">\(\bar{V}\)</span> is calculated in the standard way as
<span class="arithmatex">\(\mathrm{SE} = \sqrt{\operatorname{Var}(\bar{V})} = \frac{\sigma}{\sqrt{n}}\)</span> and
the standard variance estimator for <span class="arithmatex">\(\sigma^2 = \operatorname{Var}(\phi(x_i)
V(m(x_i), y_i))\)</span> with Bessel correction, i.e. division by <span class="arithmatex">\(n-1\)</span> instead of
<span class="arithmatex">\(n\)</span>.</p>
<p>With case weights, the variance estimator becomes <span class="arithmatex">\(\operatorname{Var}(\bar{V})
= \frac{1}{n-1} \frac{1}{\sum_i w_i} \sum_i w_i (V(m(x_i), y_i) - \bar{V})^2\)</span> with
the implied relation <span class="arithmatex">\(\operatorname{Var}(V(m(x_i), y_i)) \sim \frac{1}{w_i} \)</span>.
If your weights are for repeated observations, so-called frequency weights, then
the above estimate is conservative because it uses <span class="arithmatex">\(n - 1\)</span> instead
of <span class="arithmatex">\((\sum_i w_i) - 1\)</span>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[FLM2022]</code></dt>
<dd>
<p>T. Fissler, C. Lorentzen, and M. Mayer.
"Model Comparison and Calibration Assessment". (2022)
<a href="https://arxiv.org/abs/2202.12780">arxiv:2202.12780</a>.</p>
</dd>
</dl>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">compute_bias</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">shape: (1, 5)</span>
<span class="go">┌───────────┬────────────┬──────────────┬─────────────┬──────────┐</span>
<span class="go">│ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value  │</span>
<span class="go">│ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---      │</span>
<span class="go">│ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64      │</span>
<span class="go">╞═══════════╪════════════╪══════════════╪═════════════╪══════════╡</span>
<span class="go">│ 0.25      ┆ 4          ┆ 4.0          ┆ 0.478714    ┆ 0.637618 │</span>
<span class="go">└───────────┴────────────┴──────────────┴─────────────┴──────────┘</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">compute_bias</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span><span class="n">feature</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">])</span>
<span class="go">shape: (2, 6)</span>
<span class="go">┌─────────┬───────────┬────────────┬──────────────┬─────────────┬─────────┐</span>
<span class="go">│ feature ┆ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value │</span>
<span class="go">│ ---     ┆ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---     │</span>
<span class="go">│ str     ┆ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64     │</span>
<span class="go">╞═════════╪═══════════╪════════════╪══════════════╪═════════════╪═════════╡</span>
<span class="go">│ a       ┆ 0.0       ┆ 2          ┆ 2.0          ┆ 1.0         ┆ 1.0     │</span>
<span class="go">│ b       ┆ 0.5       ┆ 2          ┆ 2.0          ┆ 0.5         ┆ 0.5     │</span>
<span class="go">└─────────┴───────────┴────────────┴──────────────┴─────────────┴─────────┘</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/identification.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_bias</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">feature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">functional</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">n_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">bin_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;quantile&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute generalised bias conditional on a feature.</span>

<span class="sd">    This function computes and aggregates the generalised bias, i.e. the values of the</span>
<span class="sd">    canonical identification function, versus (grouped by) a feature.</span>
<span class="sd">    This is a good way to assess whether a model is conditionally calibrated or not.</span>
<span class="sd">    Well calibrated models have bias terms around zero.</span>
<span class="sd">    For the mean functional, the generalised bias is the negative residual</span>
<span class="sd">    `y_pred - y_obs`.</span>
<span class="sd">    See [Notes](#notes) for further details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs) or (n_obs, n_models)</span>
<span class="sd">        Predicted values, e.g. for the conditional expectation of the response,</span>
<span class="sd">        `E(Y|X)`.</span>
<span class="sd">    feature : array-like of shape (n_obs) or None</span>
<span class="sd">        Some feature column.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights. If given, the bias is calculated as weighted average of the</span>
<span class="sd">        identification function with these weights.</span>
<span class="sd">        Note that the standard errors and p-values in the output are based on the</span>
<span class="sd">        assumption that the variance of the bias is inverse proportional to the</span>
<span class="sd">        weights. See the Notes section for details.</span>
<span class="sd">    functional : str</span>
<span class="sd">        The functional that is induced by the identification function `V`. Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile of quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` and `functional=&quot;expectile&quot;` gives the mean.</span>
<span class="sd">        `level=0.5` and `functional=&quot;quantile&quot;` gives the median.</span>
<span class="sd">    n_bins : int</span>
<span class="sd">        The number of bins for numerical features and the maximal number of (most</span>
<span class="sd">        frequent) categories shown for categorical features. Due to ties, the effective</span>
<span class="sd">        number of bins might be smaller than `n_bins`. Null values are always included</span>
<span class="sd">        in the output, accounting for one bin. NaN values are treated as null values.</span>
<span class="sd">    bin_method : str</span>
<span class="sd">        The method to use for finding bin edges (boundaries). Options are:</span>

<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">        - `&quot;uniform&quot;`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    df : polars.DataFrame</span>
<span class="sd">        The result table contains at least the columns:</span>

<span class="sd">        - `bias_mean`: Mean of the bias</span>
<span class="sd">        - `bias_cout`: Number of data rows</span>
<span class="sd">        - `bias_weights`: Sum of weights</span>
<span class="sd">        - `bias_stderr`: Standard error, i.e. standard deviation of `bias_mean`</span>
<span class="sd">        - `p_value`: p-value of the 2-sided t-test with null hypothesis:</span>
<span class="sd">          `bias_mean = 0`</span>

<span class="sd">        If `feautre ` is not None, then there is also the column:</span>

<span class="sd">        - `feature_name`: The actual name of the feature with the (binned) feature</span>
<span class="sd">          values.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    [](){#notes}</span>
<span class="sd">    A model \(m(X)\) is conditionally calibrated iff</span>
<span class="sd">    \(\mathbb{E}(V(m(X), Y)|X)=0\) almost surely with canonical identification</span>
<span class="sd">    function \(V\).</span>
<span class="sd">    The empirical version, given some data, reads</span>
<span class="sd">    \(\bar{V} = \frac{1}{n}\sum_i \phi(x_i) V(m(x_i), y_i)\) with a test function</span>
<span class="sd">    \(\phi(x_i)\) that projects on the specified feature.</span>
<span class="sd">    For a feature with only two distinct values `&quot;a&quot;` and `&quot;b&quot;`, this becomes</span>
<span class="sd">    \(\bar{V} = \frac{1}{n_a}\sum_{i \text{ with }x_i=a} V(m(a), y_i)\) with</span>
<span class="sd">    \(n_a=\sum_{i \text{ with }x_i=a}\) and similar for `&quot;b&quot;`.</span>
<span class="sd">    With case weights, this reads</span>
<span class="sd">    \(\bar{V} = \frac{1}{\sum_i w_i}\sum_i w_i \phi(x_i) V(m(x_i), y_i)\).</span>
<span class="sd">    This generalises the classical residual (up to a minus sign) for target functionals</span>
<span class="sd">    other than the mean. See `[FLM2022]`.</span>

<span class="sd">    The standard error for \(\bar{V}\) is calculated in the standard way as</span>
<span class="sd">    \(\mathrm{SE} = \sqrt{\operatorname{Var}(\bar{V})} = \frac{\sigma}{\sqrt{n}}\) and</span>
<span class="sd">    the standard variance estimator for \(\sigma^2 = \operatorname{Var}(\phi(x_i)</span>
<span class="sd">    V(m(x_i), y_i))\) with Bessel correction, i.e. division by \(n-1\) instead of</span>
<span class="sd">    \(n\).</span>

<span class="sd">    With case weights, the variance estimator becomes \(\operatorname{Var}(\bar{V})</span>
<span class="sd">    = \frac{1}{n-1} \frac{1}{\sum_i w_i} \sum_i w_i (V(m(x_i), y_i) - \bar{V})^2\) with</span>
<span class="sd">    the implied relation \(\operatorname{Var}(V(m(x_i), y_i)) \sim \frac{1}{w_i} \).</span>
<span class="sd">    If your weights are for repeated observations, so-called frequency weights, then</span>
<span class="sd">    the above estimate is conservative because it uses \(n - 1\) instead</span>
<span class="sd">    of \((\sum_i w_i) - 1\).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[FLM2022]`</span>

<span class="sd">    :   T. Fissler, C. Lorentzen, and M. Mayer.</span>
<span class="sd">        &quot;Model Comparison and Calibration Assessment&quot;. (2022)</span>
<span class="sd">        [arxiv:2202.12780](https://arxiv.org/abs/2202.12780).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; compute_bias(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2])</span>
<span class="sd">    shape: (1, 5)</span>
<span class="sd">    ┌───────────┬────────────┬──────────────┬─────────────┬──────────┐</span>
<span class="sd">    │ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value  │</span>
<span class="sd">    │ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---      │</span>
<span class="sd">    │ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64      │</span>
<span class="sd">    ╞═══════════╪════════════╪══════════════╪═════════════╪══════════╡</span>
<span class="sd">    │ 0.25      ┆ 4          ┆ 4.0          ┆ 0.478714    ┆ 0.637618 │</span>
<span class="sd">    └───────────┴────────────┴──────────────┴─────────────┴──────────┘</span>
<span class="sd">    &gt;&gt;&gt; compute_bias(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2],</span>
<span class="sd">    ... feature=[&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;])</span>
<span class="sd">    shape: (2, 6)</span>
<span class="sd">    ┌─────────┬───────────┬────────────┬──────────────┬─────────────┬─────────┐</span>
<span class="sd">    │ feature ┆ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value │</span>
<span class="sd">    │ ---     ┆ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---     │</span>
<span class="sd">    │ str     ┆ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64     │</span>
<span class="sd">    ╞═════════╪═══════════╪════════════╪══════════════╪═════════════╪═════════╡</span>
<span class="sd">    │ a       ┆ 0.0       ┆ 2          ┆ 2.0          ┆ 1.0         ┆ 1.0     │</span>
<span class="sd">    │ b       ┆ 0.5       ┆ 2          ┆ 2.0          ┆ 0.5         ┆ 0.5     │</span>
<span class="sd">    └─────────┴───────────┴────────────┴──────────────┴─────────────┴─────────┘</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">n_pred</span> <span class="o">=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">pred_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;The array weights must be 1-dimensional, got weights.ndim=</span><span class="si">{</span><span class="n">w</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

    <span class="n">df_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">pl</span><span class="o">.</span><span class="n">StringCache</span><span class="p">():</span>
        <span class="n">feature</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">is_categorical</span><span class="p">,</span> <span class="n">is_string</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">f_binned</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">bin_feature</span><span class="p">(</span>
                <span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
                <span class="n">feature_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
                <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
                <span class="n">bin_method</span><span class="o">=</span><span class="n">bin_method</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">)):</span>
            <span class="c1"># Loop over columns of y_pred.</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

            <span class="n">bias</span> <span class="o">=</span> <span class="n">identification_function</span><span class="p">(</span>
                <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
                <span class="n">y_pred</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                <span class="n">functional</span><span class="o">=</span><span class="n">functional</span><span class="p">,</span>
                <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">feature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">bias_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
                <span class="n">bias_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
                <span class="n">bias_count</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="c1"># Note: with Bessel correction</span>
                <span class="n">bias_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">((</span><span class="n">bias</span> <span class="o">-</span> <span class="n">bias_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias_count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;bias_mean&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">bias_mean</span><span class="p">],</span>
                        <span class="s2">&quot;bias_count&quot;</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">bias_count</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">UInt32</span><span class="p">),</span>
                        <span class="s2">&quot;bias_weights&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">bias_weights</span><span class="p">],</span>
                        <span class="s2">&quot;bias_stderr&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">bias_stddev</span><span class="p">)],</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;y_obs&quot;</span><span class="p">:</span> <span class="n">y_obs</span><span class="p">,</span>
                        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                        <span class="n">feature_name</span><span class="p">:</span> <span class="n">feature</span><span class="p">,</span>
                        <span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="n">bias</span><span class="p">,</span>
                        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span>
                    <span class="p">}</span>
                <span class="p">)</span>

                <span class="n">agg_list</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">(),</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">),</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_weights&quot;</span><span class="p">),</span>
                    <span class="p">(</span>
                        <span class="p">(</span>
                            <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span>
                            <span class="o">*</span> <span class="p">((</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                        <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;variance&quot;</span><span class="p">),</span>
                <span class="p">]</span>

                <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">is_string</span><span class="p">:</span>
                    <span class="n">groupby_name</span> <span class="o">=</span> <span class="n">feature_name</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">f_binned</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bin&quot;</span><span class="p">)])</span>
                    <span class="n">groupby_name</span> <span class="o">=</span> <span class="s2">&quot;bin&quot;</span>
                    <span class="n">agg_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

                <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">df</span><span class="o">.</span><span class="n">lazy</span><span class="p">()</span>
                    <span class="o">.</span><span class="n">select</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span>
                        <span class="p">(</span>
                            <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                            <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">),</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">agg_list</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
                            <span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;variance&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;variance&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">),</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                    <span class="c1"># With sort and head alone, we could lose the null value, but we</span>
                    <span class="c1"># want to keep it.</span>
                    <span class="c1"># .sort(&quot;bias_count&quot;, descending=True)</span>
                    <span class="c1"># .head(n_bins)</span>
                    <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_null</span><span class="p">())</span>
                        <span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">))</span>
                        <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;__priority&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;__priority&quot;</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># FIXME: When n_bins=0, the result should be an empty dataframe</span>
                <span class="c1"># (0 rows and some columns). For some unknown reason as of</span>
                <span class="c1"># polars 0.20.20, the following sort neglects the head(0) statement.</span>
                <span class="c1"># Therefore, we place an explicit collect here. This should not be</span>
                <span class="c1"># needed!</span>
                <span class="k">if</span> <span class="n">n_bins</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">feature</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">lazy</span><span class="p">()</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_weights&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

                <span class="c1"># if is_categorical:</span>
                <span class="c1">#     # Pyarrow does not yet support sorting dictionary type arrays,</span>
                <span class="c1">#     # see https://github.com/apache/arrow/issues/29887</span>
                <span class="c1">#     # We resort to pandas instead.</span>
                <span class="c1">#     import pyarrow as pa</span>
                <span class="c1">#     df = df.to_pandas().sort_values(feature_name)</span>
                <span class="c1">#     df = pa.Table.from_pandas(df)</span>

            <span class="c1"># Add column with p-value of 2-sided t-test.</span>
            <span class="c1"># We explicitly convert &quot;to_numpy&quot;, because otherwise we get:</span>
            <span class="c1">#   RuntimeWarning: A builtin ctypes object gave a PEP3118 format string</span>
            <span class="c1">#   that does not match its itemsize, so a best-guess will be made of the</span>
            <span class="c1">#   data type. Newer versions of python may behave correctly.</span>
            <span class="n">stderr_</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">)</span>
            <span class="n">p_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">stderr_</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span>
            <span class="n">p_value</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">((</span><span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">stderr_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">stderr_</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">stderr</span> <span class="o">=</span> <span class="n">stderr_</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="c1"># t-statistic t (-|t| and factor of 2 because of 2-sided test)</span>
            <span class="n">p_value</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">special</span><span class="o">.</span><span class="n">stdtr</span><span class="p">(</span>
                <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># degrees of freedom</span>
                <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">stderr</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="s2">&quot;p_value&quot;</span><span class="p">,</span> <span class="n">p_value</span><span class="p">))</span>

            <span class="c1"># Add column &quot;model&quot;.</span>
            <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">model_col_name</span> <span class="o">=</span> <span class="s2">&quot;model_&quot;</span> <span class="k">if</span> <span class="n">feature_name</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span> <span class="k">else</span> <span class="s2">&quot;model&quot;</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model_col_name</span><span class="p">,</span> <span class="p">[</span><span class="n">pred_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="p">)</span>

            <span class="c1"># Select the columns in the correct order.</span>
            <span class="n">col_selection</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">col_selection</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_col_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="n">col_selection</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>
            <span class="n">col_selection</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="s2">&quot;bias_mean&quot;</span><span class="p">,</span>
                <span class="s2">&quot;bias_count&quot;</span><span class="p">,</span>
                <span class="s2">&quot;bias_weights&quot;</span><span class="p">,</span>
                <span class="s2">&quot;bias_stderr&quot;</span><span class="p">,</span>
                <span class="s2">&quot;p_value&quot;</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="n">df_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col_selection</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">df_list</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.identification.compute_marginal" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_marginal</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feature_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">predict_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bin_method</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">n_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.identification.compute_marginal" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Compute the marginal expectation conditional on a single feature.</p>
<p>This function computes the (weighted) average of observed response and predictions
conditional on a given feature.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs) or (n_obs, n_models)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values, e.g. for the conditional expectation of the response,
<code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code>array-like of shape (n_obs, n_features) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dataframe or array of features to be passed to the model predict function.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature_name</code></td>
            <td>
                  <code>(int, str or None)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Column name (str) or index (int) of feature in <code>X</code>. If None, the total marginal
is computed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>predict_function</code></td>
            <td>
                  <code>callable or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A callable to get prediction, i.e. <code>predict_function(X)</code>. Used to compute
partial dependence. If <code>None</code>, partial dependence is omitted.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights. If given, the bias is calculated as weighted average of the
identification function with these weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of bins for numerical features and the maximal number of (most
frequent) categories shown for categorical features. Due to ties, the effective
number of bins might be smaller than <code>n_bins</code>. Null values are always included
in the output, accounting for one bin. NaN values are treated as null values.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bin_method</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The method to use for finding bin edges (boundaries). Options are:</p>
<ul>
<li><code>"quantile"</code></li>
<li><code>"uniform"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;uniform&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_max</code></td>
            <td>
                  <code>int or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Used only for partial dependence computation. The number of rows to subsample
from X. This speeds up computation, in particular for slow predict functions.</p>
              </div>
            </td>
            <td>
                  <code>1000</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>rng</code></td>
            <td>
                  <code>(<span title="numpy.random.Generator">Generator</span>, int or None)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Used only for partial dependence computation. The random number generator used
for subsampling of <code>n_max</code> rows. The input is internally wrapped by
<code>np.random.default_rng(rng)</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>df</code></td>            <td>
                  <code><span title="polars.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The result table contains at least the columns:</p>
<ul>
<li><code>y_obs_mean</code>: Mean of <code>y_obs</code></li>
<li><code>y_pred_mean</code>: Mean of <code>y_pred</code></li>
<li><code>y_obs_stderr</code>: Standard error, i.e. standard deviation of <code>y_obs_mean</code></li>
<li><code>y_pred_stderr</code>: Standard error, i.e. standard deviation of <code>y_pred_mean</code></li>
<li><code>count</code>: Number of data rows</li>
<li><code>weights</code>: Sum of weights</li>
</ul>
<p>If <code>feature</code> is not None, then there is also the column:</p>
<ul>
<li><code>feature_name</code>: The actual name of the feature with the (binned) feature
  values.</li>
</ul>
<p>If <code>feature</code> is numerical, one also has:</p>
<ul>
<li><code>bin_edges</code>: The edges and standard deviation of the bins, i.e.
  (min, std, max).</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p>The marginal values are computed as an estimation of:</p>
<ul>
<li><code>y_obs</code>: <span class="arithmatex">\(\mathbb{E}(Y|feature)\)</span></li>
<li><code>y_pred</code>: <span class="arithmatex">\(\mathbb{E}(m(X)|feature)\)</span></li>
</ul>
<p>with <span class="arithmatex">\(feature\)</span> the column specified by <code>feature_name</code>.
Computationally that is more or less a group-by-aggregate operation on a dataset.</p>
<p>The standard error for both are calculated in the standard way as
<span class="arithmatex">\(\mathrm{SE} = \sqrt{\operatorname{Var}(\bar{Y})} = \frac{\sigma}{\sqrt{n}}\)</span> and
the standard variance estimator for <span class="arithmatex">\(\sigma^2\)</span> with Bessel correction, i.e.
division by <span class="arithmatex">\(n-1\)</span> instead of <span class="arithmatex">\(n\)</span>.</p>
<p>With case weights, the variance estimator becomes <span class="arithmatex">\(\operatorname{Var}(\bar{Y})
= \frac{1}{n-1} \frac{1}{\sum_i w_i} \sum_i w_i (y_i - \bar{y})^2\)</span> with
the implied relation <span class="arithmatex">\(\operatorname{Var}(y_i) \sim \frac{1}{w_i} \)</span>.
If your weights are for repeated observations, so-called frequency weights, then
the above estimate is conservative because it uses <span class="arithmatex">\(n - 1\)</span> instead
of <span class="arithmatex">\((\sum_i w_i) - 1\)</span>.</p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">compute_marginal</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">shape: (1, 6)</span>
<span class="go">┌────────────┬─────────────┬──────────────┬───────────────┬───────┬─────────┐</span>
<span class="go">│ y_obs_mean ┆ y_pred_mean ┆ y_obs_stderr ┆ y_pred_stderr ┆ count ┆ weights │</span>
<span class="go">│ ---        ┆ ---         ┆ ---          ┆ ---           ┆ ---   ┆ ---     │</span>
<span class="go">│ f64        ┆ f64         ┆ f64          ┆ f64           ┆ u32   ┆ f64     │</span>
<span class="go">╞════════════╪═════════════╪══════════════╪═══════════════╪═══════╪═════════╡</span>
<span class="go">│ 0.5        ┆ 0.75        ┆ 0.288675     ┆ 0.629153      ┆ 4     ┆ 4.0     │</span>
<span class="go">└────────────┴─────────────┴──────────────┴───────────────┴───────┴─────────┘</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">polars</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pl</span><span class="o">.</span><span class="n">Config</span><span class="o">.</span><span class="n">set_tbl_width_chars</span><span class="p">(</span><span class="mi">84</span><span class="p">)</span>
<span class="go">&lt;class &#39;polars.config.Config&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_obs</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">compute_marginal</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_name</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span><span class="n">predict_function</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">)</span>
<span class="go">shape: (3, 9)</span>
<span class="go">┌──────────┬─────────┬─────────┬─────────┬───┬───────┬─────────┬─────────┬─────────┐</span>
<span class="go">│ feature  ┆ y_obs_m ┆ y_pred_ ┆ y_obs_s ┆ … ┆ count ┆ weights ┆ bin_edg ┆ partial │</span>
<span class="go">│ 0        ┆ ean     ┆ mean    ┆ tderr   ┆   ┆ ---   ┆ ---     ┆ es      ┆ _depend │</span>
<span class="go">│ ---      ┆ ---     ┆ ---     ┆ ---     ┆   ┆ u32   ┆ f64     ┆ ---     ┆ ence    │</span>
<span class="go">│ f64      ┆ f64     ┆ f64     ┆ f64     ┆   ┆       ┆         ┆ array[f ┆ ---     │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 64, 3]  ┆ f64     │</span>
<span class="go">╞══════════╪═════════╪═════════╪═════════╪═══╪═══════╪═════════╪═════════╪═════════╡</span>
<span class="go">│ 0.0      ┆ 0.0     ┆ 0.1     ┆ 0.0     ┆ … ┆ 1     ┆ 1.0     ┆ [0.0,   ┆ 0.3     │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.2]    ┆         │</span>
<span class="go">│ 1.0      ┆ 0.5     ┆ 0.5     ┆ 0.5     ┆ … ┆ 2     ┆ 2.0     ┆ [0.8,   ┆ 0.5     │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 1.0]    ┆         │</span>
<span class="go">│ 2.0      ┆ 1.0     ┆ 0.9     ┆ 0.0     ┆ … ┆ 1     ┆ 1.0     ┆ [1.8,   ┆ 0.7     │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 2.0]    ┆         │</span>
<span class="go">└──────────┴─────────┴─────────┴─────────┴───┴───────┴─────────┴─────────┴─────────┘</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/identification.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_marginal</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feature_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">predict_function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">n_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">bin_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
    <span class="n">n_max</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the marginal expectation conditional on a single feature.</span>

<span class="sd">    This function computes the (weighted) average of observed response and predictions</span>
<span class="sd">    conditional on a given feature.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs) or (n_obs, n_models)</span>
<span class="sd">        Predicted values, e.g. for the conditional expectation of the response,</span>
<span class="sd">        `E(Y|X)`.</span>
<span class="sd">    X : array-like of shape (n_obs, n_features) or None</span>
<span class="sd">        The dataframe or array of features to be passed to the model predict function.</span>
<span class="sd">    feature_name : int, str or None</span>
<span class="sd">        Column name (str) or index (int) of feature in `X`. If None, the total marginal</span>
<span class="sd">        is computed.</span>
<span class="sd">    predict_function : callable or None</span>
<span class="sd">        A callable to get prediction, i.e. `predict_function(X)`. Used to compute</span>
<span class="sd">        partial dependence. If `None`, partial dependence is omitted.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights. If given, the bias is calculated as weighted average of the</span>
<span class="sd">        identification function with these weights.</span>
<span class="sd">    n_bins : int</span>
<span class="sd">        The number of bins for numerical features and the maximal number of (most</span>
<span class="sd">        frequent) categories shown for categorical features. Due to ties, the effective</span>
<span class="sd">        number of bins might be smaller than `n_bins`. Null values are always included</span>
<span class="sd">        in the output, accounting for one bin. NaN values are treated as null values.</span>
<span class="sd">    bin_method : str</span>
<span class="sd">        The method to use for finding bin edges (boundaries). Options are:</span>

<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">        - `&quot;uniform&quot;`</span>
<span class="sd">    n_max : int or None</span>
<span class="sd">        Used only for partial dependence computation. The number of rows to subsample</span>
<span class="sd">        from X. This speeds up computation, in particular for slow predict functions.</span>
<span class="sd">    rng : np.random.Generator, int or None</span>
<span class="sd">        Used only for partial dependence computation. The random number generator used</span>
<span class="sd">        for subsampling of `n_max` rows. The input is internally wrapped by</span>
<span class="sd">        `np.random.default_rng(rng)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    df : polars.DataFrame</span>
<span class="sd">        The result table contains at least the columns:</span>

<span class="sd">        - `y_obs_mean`: Mean of `y_obs`</span>
<span class="sd">        - `y_pred_mean`: Mean of `y_pred`</span>
<span class="sd">        - `y_obs_stderr`: Standard error, i.e. standard deviation of `y_obs_mean`</span>
<span class="sd">        - `y_pred_stderr`: Standard error, i.e. standard deviation of `y_pred_mean`</span>
<span class="sd">        - `count`: Number of data rows</span>
<span class="sd">        - `weights`: Sum of weights</span>

<span class="sd">        If `feature ` is not None, then there is also the column:</span>

<span class="sd">        - `feature_name`: The actual name of the feature with the (binned) feature</span>
<span class="sd">          values.</span>

<span class="sd">        If `feature` is numerical, one also has:</span>

<span class="sd">        - `bin_edges`: The edges and standard deviation of the bins, i.e.</span>
<span class="sd">          (min, std, max).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The marginal values are computed as an estimation of:</span>

<span class="sd">    - `y_obs`: \(\mathbb{E}(Y|feature)\)</span>
<span class="sd">    - `y_pred`: \(\mathbb{E}(m(X)|feature)\)</span>

<span class="sd">    with \(feature\) the column specified by `feature_name`.</span>
<span class="sd">    Computationally that is more or less a group-by-aggregate operation on a dataset.</span>

<span class="sd">    The standard error for both are calculated in the standard way as</span>
<span class="sd">    \(\mathrm{SE} = \sqrt{\operatorname{Var}(\bar{Y})} = \frac{\sigma}{\sqrt{n}}\) and</span>
<span class="sd">    the standard variance estimator for \(\sigma^2\) with Bessel correction, i.e.</span>
<span class="sd">    division by \(n-1\) instead of \(n\).</span>

<span class="sd">    With case weights, the variance estimator becomes \(\operatorname{Var}(\bar{Y})</span>
<span class="sd">    = \frac{1}{n-1} \frac{1}{\sum_i w_i} \sum_i w_i (y_i - \bar{y})^2\) with</span>
<span class="sd">    the implied relation \(\operatorname{Var}(y_i) \sim \frac{1}{w_i} \).</span>
<span class="sd">    If your weights are for repeated observations, so-called frequency weights, then</span>
<span class="sd">    the above estimate is conservative because it uses \(n - 1\) instead</span>
<span class="sd">    of \((\sum_i w_i) - 1\).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; compute_marginal(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1, 2])</span>
<span class="sd">    shape: (1, 6)</span>
<span class="sd">    ┌────────────┬─────────────┬──────────────┬───────────────┬───────┬─────────┐</span>
<span class="sd">    │ y_obs_mean ┆ y_pred_mean ┆ y_obs_stderr ┆ y_pred_stderr ┆ count ┆ weights │</span>
<span class="sd">    │ ---        ┆ ---         ┆ ---          ┆ ---           ┆ ---   ┆ ---     │</span>
<span class="sd">    │ f64        ┆ f64         ┆ f64          ┆ f64           ┆ u32   ┆ f64     │</span>
<span class="sd">    ╞════════════╪═════════════╪══════════════╪═══════════════╪═══════╪═════════╡</span>
<span class="sd">    │ 0.5        ┆ 0.75        ┆ 0.288675     ┆ 0.629153      ┆ 4     ┆ 4.0     │</span>
<span class="sd">    └────────────┴─────────────┴──────────────┴───────────────┴───────┴─────────┘</span>
<span class="sd">    &gt;&gt;&gt; import polars as pl</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import Ridge</span>
<span class="sd">    &gt;&gt;&gt; pl.Config.set_tbl_width_chars(84)  # doctest: +ELLIPSIS</span>
<span class="sd">    &lt;class &#39;polars.config.Config&#39;&gt;</span>
<span class="sd">    &gt;&gt;&gt; y_obs, X =[0, 0, 1, 1], [[0, 1], [1, 1], [1, 2], [2, 2]]</span>
<span class="sd">    &gt;&gt;&gt; m = Ridge().fit(X, y_obs)</span>
<span class="sd">    &gt;&gt;&gt; compute_marginal(y_obs=y_obs, y_pred=m.predict(X), X=X, feature_name=0,</span>
<span class="sd">    ... predict_function=m.predict)</span>
<span class="sd">    shape: (3, 9)</span>
<span class="sd">    ┌──────────┬─────────┬─────────┬─────────┬───┬───────┬─────────┬─────────┬─────────┐</span>
<span class="sd">    │ feature  ┆ y_obs_m ┆ y_pred_ ┆ y_obs_s ┆ … ┆ count ┆ weights ┆ bin_edg ┆ partial │</span>
<span class="sd">    │ 0        ┆ ean     ┆ mean    ┆ tderr   ┆   ┆ ---   ┆ ---     ┆ es      ┆ _depend │</span>
<span class="sd">    │ ---      ┆ ---     ┆ ---     ┆ ---     ┆   ┆ u32   ┆ f64     ┆ ---     ┆ ence    │</span>
<span class="sd">    │ f64      ┆ f64     ┆ f64     ┆ f64     ┆   ┆       ┆         ┆ array[f ┆ ---     │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 64, 3]  ┆ f64     │</span>
<span class="sd">    ╞══════════╪═════════╪═════════╪═════════╪═══╪═══════╪═════════╪═════════╪═════════╡</span>
<span class="sd">    │ 0.0      ┆ 0.0     ┆ 0.1     ┆ 0.0     ┆ … ┆ 1     ┆ 1.0     ┆ [0.0,   ┆ 0.3     │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.2]    ┆         │</span>
<span class="sd">    │ 1.0      ┆ 0.5     ┆ 0.5     ┆ 0.5     ┆ … ┆ 2     ┆ 2.0     ┆ [0.8,   ┆ 0.5     │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 1.0]    ┆         │</span>
<span class="sd">    │ 2.0      ┆ 1.0     ┆ 0.9     ┆ 0.0     ┆ … ┆ 1     ┆ 1.0     ┆ [1.8,   ┆ 0.7     │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 2.0]    ┆         │</span>
<span class="sd">    └──────────┴─────────┴─────────┴─────────┴───┴───────┴─────────┴─────────┴─────────┘</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">n_pred</span> <span class="o">=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">pred_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">y_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;The array weights must be 1-dimensional, got weights.ndim=</span><span class="si">{</span><span class="n">w</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># X is completely ignored.</span>
        <span class="n">feature_input</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;X must be a data container like a (polars) dataframe or an (numpy) array.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">)):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;The argument &#39;feature_name&#39; must be an int or str; got </span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">feature_index</span> <span class="o">=</span> <span class="n">feature_name</span>
        <span class="n">feature_input</span> <span class="o">=</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">feature_index</span> <span class="o">=</span> <span class="n">X_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>
        <span class="n">feature_input</span> <span class="o">=</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_index</span><span class="p">)</span>

    <span class="n">df_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">pl</span><span class="o">.</span><span class="n">StringCache</span><span class="p">():</span>
        <span class="p">(</span>
            <span class="n">feature</span><span class="p">,</span>
            <span class="n">feature_name</span><span class="p">,</span>
            <span class="n">is_categorical</span><span class="p">,</span>
            <span class="n">is_string</span><span class="p">,</span>
            <span class="n">n_bins</span><span class="p">,</span>
            <span class="n">f_binned</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">bin_feature</span><span class="p">(</span>
            <span class="n">feature</span><span class="o">=</span><span class="n">feature_input</span><span class="p">,</span>
            <span class="n">feature_name</span><span class="o">=</span><span class="n">feature_name</span><span class="p">,</span>
            <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
            <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
            <span class="n">bin_method</span><span class="o">=</span><span class="n">bin_method</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">)):</span>
            <span class="c1"># Loop over columns of y_pred.</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_pred</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">feature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">y_obs_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
                <span class="n">y_pred_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
                <span class="n">weights_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
                <span class="n">count</span> <span class="o">=</span> <span class="n">y_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="c1"># Note: with Bessel correction</span>
                <span class="n">y_obs_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">y_obs</span> <span class="o">-</span> <span class="n">y_obs_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span>
                <span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
                <span class="n">y_pred_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">y_pred_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;y_obs_mean&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">y_obs_mean</span><span class="p">],</span>
                        <span class="s2">&quot;y_pred_mean&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">y_pred_mean</span><span class="p">],</span>
                        <span class="s2">&quot;count&quot;</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">count</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">UInt32</span><span class="p">),</span>
                        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">weights_sum</span><span class="p">],</span>
                        <span class="s2">&quot;y_obs_stderr&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_obs_stddev</span><span class="p">)],</span>
                        <span class="s2">&quot;y_pred_stderr&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_pred_stddev</span><span class="p">)],</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;y_obs&quot;</span><span class="p">:</span> <span class="n">y_obs</span><span class="p">,</span>
                        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                        <span class="n">feature_name</span><span class="p">:</span> <span class="n">feature</span><span class="p">,</span>
                        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span>
                    <span class="p">}</span>
                <span class="p">)</span>

                <span class="n">agg_list</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;y_obs&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">),</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;weights_sum&quot;</span><span class="p">),</span>
                    <span class="o">*</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_mean&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">(),</span>
                            <span class="p">(</span>
                                <span class="p">(</span>
                                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span>
                                    <span class="o">*</span> <span class="p">((</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">-</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_mean&quot;</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
                                <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                                <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                            <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_variance&quot;</span><span class="p">),</span>
                        <span class="p">]</span>
                        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;y_obs&quot;</span><span class="p">,</span> <span class="s2">&quot;y_pred&quot;</span><span class="p">]</span>
                    <span class="p">),</span>
                <span class="p">]</span>

                <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">is_string</span><span class="p">:</span>
                    <span class="n">groupby_name</span> <span class="o">=</span> <span class="n">feature_name</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># We also add the bin edges.</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">f_binned</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bin&quot;</span><span class="p">),</span> <span class="n">f_binned</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)]</span>
                    <span class="p">)</span>
                    <span class="n">groupby_name</span> <span class="o">=</span> <span class="s2">&quot;bin&quot;</span>
                    <span class="n">agg_list</span> <span class="o">+=</span> <span class="p">[</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;__feature_std&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">(),</span>
                    <span class="p">]</span>

                <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">df</span><span class="o">.</span><span class="n">lazy</span><span class="p">()</span>
                    <span class="o">.</span><span class="n">select</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span>
                        <span class="p">(</span>
                            <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_obs&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                            <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;y_obs_mean&quot;</span><span class="p">),</span>
                        <span class="p">(</span>
                            <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_pred&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                            <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;y_pred_mean&quot;</span><span class="p">),</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">agg_list</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
                            <span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_variance&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_variance&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_stderr&quot;</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;y_obs&quot;</span><span class="p">,</span> <span class="s2">&quot;y_pred&quot;</span><span class="p">)</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                    <span class="c1"># With sort and head alone, we could lose the null value, but we</span>
                    <span class="c1"># want to keep it.</span>
                    <span class="c1"># .sort(&quot;bias_count&quot;, descending=True)</span>
                    <span class="c1"># .head(n_bins)</span>
                    <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_null</span><span class="p">())</span>
                        <span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">))</span>
                        <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;__priority&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;__priority&quot;</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># FIXME: When n_bins=0, the result should be an empty dataframe</span>
                <span class="c1"># (0 rows and some columns). For some unknown reason as of</span>
                <span class="c1"># polars 0.20.20, the following sort neglects the head(0) statement.</span>
                <span class="c1"># Therefore, we place an explicit collect here. This should not be</span>
                <span class="c1"># needed!</span>
                <span class="k">if</span> <span class="n">n_bins</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">feature</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">lazy</span><span class="p">()</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_obs_mean&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_pred_mean&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_obs_stderr&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_pred_stderr&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights_sum&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">),</span>
                    <span class="p">]</span>
                    <span class="o">+</span> <span class="p">(</span>
                        <span class="p">[]</span>
                        <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">is_string</span>
                        <span class="k">else</span> <span class="p">[</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">),</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;__feature_std&quot;</span><span class="p">)]</span>
                    <span class="p">)</span>
                <span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">is_categorical</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_string</span><span class="p">:</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span>
                        <span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
                        <span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;__feature_std&quot;</span><span class="p">))</span>
                        <span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">())</span>
                        <span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">to_array</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
                        <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span>
                    <span class="p">)</span>

            <span class="c1"># Add column &quot;model&quot;.</span>
            <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">model_col_name</span> <span class="o">=</span> <span class="s2">&quot;model_&quot;</span> <span class="k">if</span> <span class="n">feature_name</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span> <span class="k">else</span> <span class="s2">&quot;model&quot;</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model_col_name</span><span class="p">,</span> <span class="p">[</span><span class="n">pred_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="p">)</span>

            <span class="c1"># Add partial dependence.</span>
            <span class="n">with_pd</span> <span class="o">=</span> <span class="n">predict_function</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">with_pd</span><span class="p">:</span>
                <span class="n">pd_values</span> <span class="o">=</span> <span class="n">compute_partial_dependence</span><span class="p">(</span>
                    <span class="n">pred_fun</span><span class="o">=</span><span class="n">predict_function</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                    <span class="n">feature_index</span><span class="o">=</span><span class="n">feature_index</span><span class="p">,</span>
                    <span class="n">grid</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="n">feature_name</span><span class="p">),</span>
                    <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                    <span class="n">n_max</span><span class="o">=</span><span class="n">n_max</span><span class="p">,</span>
                    <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;partial_dependence&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">pd_values</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># Select the columns in the correct order.</span>
            <span class="n">col_selection</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">col_selection</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_col_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="n">col_selection</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">feature_name</span><span class="p">))</span>
            <span class="n">col_selection</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="s2">&quot;y_obs_mean&quot;</span><span class="p">,</span>
                <span class="s2">&quot;y_pred_mean&quot;</span><span class="p">,</span>
                <span class="s2">&quot;y_obs_stderr&quot;</span><span class="p">,</span>
                <span class="s2">&quot;y_pred_stderr&quot;</span><span class="p">,</span>
                <span class="s2">&quot;count&quot;</span><span class="p">,</span>
                <span class="s2">&quot;weights&quot;</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_categorical</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_string</span><span class="p">:</span>
                <span class="n">col_selection</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">with_pd</span><span class="p">:</span>
                <span class="n">col_selection</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;partial_dependence&quot;</span><span class="p">]</span>
            <span class="n">df_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col_selection</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">df_list</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.identification.identification_function" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">identification_function</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.identification.identification_function" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Canonical identification function.</p>
<p>Identification functions act as generalised residuals. See <a href="#model_diagnostics.calibration.identification.identification_function--notes">Notes</a> for
further details.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code>, e.g. the conditional expectation of
the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The functional that is induced by the identification function <code>V</code>. Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile of quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> and <code>functional="expectile"</code> gives the mean.
<code>level=0.5</code> and <code>functional="quantile"</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>V</code></td>            <td>
                  <code>ndarray of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the identification function.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><a href="" id="notes"></a>
The function <a href="" id="model_diagnostics.calibration.identification.identification_function--notes"></a>
The function <span class="arithmatex">\(V(y, z)\)</span> for observation <span class="arithmatex">\(y=y_{pred}\)</span> and prediction
<span class="arithmatex">\(z=y_{pred}\)</span> is a strict identification function for the functional <span class="arithmatex">\(T\)</span>, or
induces the functional <span class="arithmatex">\(T\)</span> as:</p>
<div class="arithmatex">\[
\mathbb{E}[V(Y, z)] = 0\quad \Leftrightarrow\quad z\in T(F) \quad \forall
\text{ distributions } F
\in \mathcal{F}
\]</div>
<p>for some class of distributions <span class="arithmatex">\(\mathcal{F}\)</span>. Implemented examples of the
functional <span class="arithmatex">\(T\)</span> are mean, median, expectiles and quantiles.</p>
<table>
<thead>
<tr>
<th>functional</th>
<th>strict identification function <span class="arithmatex">\(V(y, z)\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>mean</td>
<td><span class="arithmatex">\(z - y\)</span></td>
</tr>
<tr>
<td>median</td>
<td><span class="arithmatex">\(\mathbf{1}\{z \ge y\} - \frac{1}{2}\)</span></td>
</tr>
<tr>
<td>expectile</td>
<td><span class="arithmatex">\(2 \mid\mathbf{1}\{z \ge y\} - \alpha\mid (z - y)\)</span></td>
</tr>
<tr>
<td>quantile</td>
<td><span class="arithmatex">\(\mathbf{1}\{z \ge y\} - \alpha\)</span></td>
</tr>
</tbody>
</table>
<p>For <code>level</code> <span class="arithmatex">\(\alpha\)</span>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[Gneiting2011]</code></dt>
<dd>
<p>T. Gneiting.
"Making and Evaluating Point Forecasts". (2011)
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>
<a href="https://arxiv.org/abs/0912.0902">arxiv:0912.0902</a></p>
</dd>
</dl>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">identification_function</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([-1,  1,  0,  1])</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/identification.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">identification_function</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">functional</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Canonical identification function.</span>

<span class="sd">    Identification functions act as generalised residuals. See [Notes](#notes) for</span>
<span class="sd">    further details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional`, e.g. the conditional expectation of</span>
<span class="sd">        the response, `E(Y|X)`.</span>
<span class="sd">    functional : str</span>
<span class="sd">        The functional that is induced by the identification function `V`. Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile of quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` and `functional=&quot;expectile&quot;` gives the mean.</span>
<span class="sd">        `level=0.5` and `functional=&quot;quantile&quot;` gives the median.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    V : ndarray of shape (n_obs)</span>
<span class="sd">        Values of the identification function.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    [](){#notes}</span>
<span class="sd">    The function \(V(y, z)\) for observation \(y=y_{pred}\) and prediction</span>
<span class="sd">    \(z=y_{pred}\) is a strict identification function for the functional \(T\), or</span>
<span class="sd">    induces the functional \(T\) as:</span>

<span class="sd">    \[</span>
<span class="sd">    \mathbb{E}[V(Y, z)] = 0\quad \Leftrightarrow\quad z\in T(F) \quad \forall</span>
<span class="sd">    \text{ distributions } F</span>
<span class="sd">    \in \mathcal{F}</span>
<span class="sd">    \]</span>

<span class="sd">    for some class of distributions \(\mathcal{F}\). Implemented examples of the</span>
<span class="sd">    functional \(T\) are mean, median, expectiles and quantiles.</span>

<span class="sd">    | functional | strict identification function \(V(y, z)\)           |</span>
<span class="sd">    | ---------- | ---------------------------------------------------- |</span>
<span class="sd">    | mean       | \(z - y\)                                            |</span>
<span class="sd">    | median     | \(\mathbf{1}\{z \ge y\} - \frac{1}{2}\)              |</span>
<span class="sd">    | expectile  | \(2 \mid\mathbf{1}\{z \ge y\} - \alpha\mid (z - y)\) |</span>
<span class="sd">    | quantile   | \(\mathbf{1}\{z \ge y\} - \alpha\)                   |</span>

<span class="sd">    For `level` \(\alpha\).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[Gneiting2011]`</span>

<span class="sd">    :   T. Gneiting.</span>
<span class="sd">        &quot;Making and Evaluating Point Forecasts&quot;. (2011)</span>
<span class="sd">        [doi:10.1198/jasa.2011.r10138](https://doi.org/10.1198/jasa.2011.r10138)</span>
<span class="sd">        [arxiv:0912.0902](https://arxiv.org/abs/0912.0902)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; identification_function(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2])</span>
<span class="sd">    array([-1,  1,  0,  1])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_o</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y_p</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y_o</span><span class="p">,</span> <span class="n">y_p</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">functional</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;expectile&quot;</span><span class="p">,</span> <span class="s2">&quot;quantile&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">level</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">level</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Argument level must fulfil 0 &lt; level &lt; 1, got </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">y_p</span> <span class="o">-</span> <span class="n">y_o</span>
    <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;median&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">y_p</span><span class="p">,</span> <span class="n">y_o</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
    <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;expectile&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">y_p</span><span class="p">,</span> <span class="n">y_o</span><span class="p">)</span> <span class="o">-</span> <span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_p</span> <span class="o">-</span> <span class="n">y_o</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;quantile&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">y_p</span><span class="p">,</span> <span class="n">y_o</span><span class="p">)</span> <span class="o">-</span> <span class="n">level</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">allowed_functionals</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">,</span> <span class="s2">&quot;expectile&quot;</span><span class="p">,</span> <span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Argument functional must be one of </span><span class="si">{</span><span class="n">allowed_functionals</span><span class="si">}</span><span class="s2">, got &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">functional</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; Christian Lorentzen 2022-present
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.sections", "navigation.expand", "navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "search.highlight"], "search": "../../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>