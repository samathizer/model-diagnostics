
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Tools for diagnostics and assessment of (machine learning) models">
      
      
        <meta name="author" content="Christian Lorentzen">
      
      
        <link rel="canonical" href="https://lorentzenchr.github.io/model-diagnostics/reference/model_diagnostics/calibration/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="identification/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.31">
    
    
      
        <title>calibration - Model Diagnostics</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model_diagnostics.calibration" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Model Diagnostics" class="md-header__button md-logo" aria-label="Model Diagnostics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Model Diagnostics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              calibration
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/lorentzenchr/model-diagnostics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lorentzenchr/model-diagnostics
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../examples/regression_on_workers_compensation/" class="md-tabs__link">
          
  
  Examples

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../development/" class="md-tabs__link">
        
  
    
  
  Development

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="https://github.com/lorentzenchr/model-diagnostics/releases" class="md-tabs__link">
        
  
    
  
  Release Notes

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Model Diagnostics" class="md-nav__button md-logo" aria-label="Model Diagnostics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Model Diagnostics
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/lorentzenchr/model-diagnostics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lorentzenchr/model-diagnostics
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Home
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/regression_on_workers_compensation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Regression on Workers' Compensation Dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/quantile_regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quantile Regression on Synthetic Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Classification on Nursery Dataset
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    model_diagnostics
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1" id="__nav_3_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            model_diagnostics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="./" class="md-nav__link md-nav__link--active">
              
  
  <span class="md-ellipsis">
    calibration
  </span>
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            calibration
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="identification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    identification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    plots
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_1_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../scoring/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    scoring
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            scoring
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scoring/plots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    plots
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scoring/scoring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scoring
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../development/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Development
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/lorentzenchr/model-diagnostics/releases" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Release Notes
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model_diagnostics.calibration" class="md-nav__link">
    <span class="md-ellipsis">
      calibration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="calibration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.compute_bias" class="md-nav__link">
    <span class="md-ellipsis">
      compute_bias
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.compute_marginal" class="md-nav__link">
    <span class="md-ellipsis">
      compute_marginal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.identification_function" class="md-nav__link">
    <span class="md-ellipsis">
      identification_function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.plot_bias" class="md-nav__link">
    <span class="md-ellipsis">
      plot_bias
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.plot_marginal" class="md-nav__link">
    <span class="md-ellipsis">
      plot_marginal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.calibration.plot_reliability_diagram" class="md-nav__link">
    <span class="md-ellipsis">
      plot_reliability_diagram
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>calibration</h1>

<div class="doc doc-object doc-module">



<h2 id="model_diagnostics.calibration" class="doc doc-heading">
            <code>calibration</code>


<a href="#model_diagnostics.calibration" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.compute_bias" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_bias</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bin_method</span><span class="o">=</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.compute_bias" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Compute generalised bias conditional on a feature.</p>
<p>This function computes and aggregates the generalised bias, i.e. the values of the
canonical identification function, versus (grouped by) a feature.
This is a good way to assess whether a model is conditionally calibrated or not.
Well calibrated models have bias terms around zero.
For the mean functional, the generalised bias is the negative residual
<code>y_pred - y_obs</code>.
See <a href="#model_diagnostics.calibration.compute_bias--notes">Notes</a> for further details.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs) or (n_obs, n_models)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values, e.g. for the conditional expectation of the response,
<code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Some feature column.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights. If given, the bias is calculated as weighted average of the
identification function with these weights.
Note that the standard errors and p-values in the output are based on the
assumption that the variance of the bias is inverse proportional to the
weights. See the Notes section for details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The functional that is induced by the identification function <code>V</code>. Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile of quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> and <code>functional="expectile"</code> gives the mean.
<code>level=0.5</code> and <code>functional="quantile"</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of bins for numerical features and the maximal number of (most
frequent) categories shown for categorical features. Due to ties, the effective
number of bins might be smaller than <code>n_bins</code>. Null values are always included
in the output, accounting for one bin. NaN values are treated as null values.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bin_method</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The method to use for finding bin edges (boundaries). Options are:</p>
<ul>
<li><code>"quantile"</code></li>
<li><code>"uniform"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;quantile&#39;</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>df</code></td>            <td>
                  <code><span title="polars.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The result table contains at least the columns:</p>
<ul>
<li><code>bias_mean</code>: Mean of the bias</li>
<li><code>bias_cout</code>: Number of data rows</li>
<li><code>bias_weights</code>: Sum of weights</li>
<li><code>bias_stderr</code>: Standard error, i.e. standard deviation of <code>bias_mean</code></li>
<li><code>p_value</code>: p-value of the 2-sided t-test with null hypothesis:
  <code>bias_mean = 0</code></li>
</ul>
<p>If <code>feautre</code> is not None, then there is also the column:</p>
<ul>
<li><code>feature_name</code>: The actual name of the feature with the (binned) feature
  values.</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><a href="" id="notes"></a>
A model <a href="" id="model_diagnostics.calibration.compute_bias--notes"></a>
A model <span class="arithmatex">\(m(X)\)</span> is conditionally calibrated iff
<span class="arithmatex">\(\mathbb{E}(V(m(X), Y)|X)=0\)</span> almost surely with canonical identification
function <span class="arithmatex">\(V\)</span>.
The empirical version, given some data, reads
<span class="arithmatex">\(\bar{V} = \frac{1}{n}\sum_i \phi(x_i) V(m(x_i), y_i)\)</span> with a test function
<span class="arithmatex">\(\phi(x_i)\)</span> that projects on the specified feature.
For a feature with only two distinct values <code>"a"</code> and <code>"b"</code>, this becomes
<span class="arithmatex">\(\bar{V} = \frac{1}{n_a}\sum_{i \text{ with }x_i=a} V(m(a), y_i)\)</span> with
<span class="arithmatex">\(n_a=\sum_{i \text{ with }x_i=a}\)</span> and similar for <code>"b"</code>.
With case weights, this reads
<span class="arithmatex">\(\bar{V} = \frac{1}{\sum_i w_i}\sum_i w_i \phi(x_i) V(m(x_i), y_i)\)</span>.
This generalises the classical residual (up to a minus sign) for target functionals
other than the mean. See <code>[FLM2022]</code>.</p>
<p>The standard error for <span class="arithmatex">\(\bar{V}\)</span> is calculated in the standard way as
<span class="arithmatex">\(\mathrm{SE} = \sqrt{\operatorname{Var}(\bar{V})} = \frac{\sigma}{\sqrt{n}}\)</span> and
the standard variance estimator for <span class="arithmatex">\(\sigma^2 = \operatorname{Var}(\phi(x_i)
V(m(x_i), y_i))\)</span> with Bessel correction, i.e. division by <span class="arithmatex">\(n-1\)</span> instead of
<span class="arithmatex">\(n\)</span>.</p>
<p>With case weights, the variance estimator becomes <span class="arithmatex">\(\operatorname{Var}(\bar{V})
= \frac{1}{n-1} \frac{1}{\sum_i w_i} \sum_i w_i (V(m(x_i), y_i) - \bar{V})^2\)</span> with
the implied relation <span class="arithmatex">\(\operatorname{Var}(V(m(x_i), y_i)) \sim \frac{1}{w_i} \)</span>.
If your weights are for repeated observations, so-called frequency weights, then
the above estimate is conservative because it uses <span class="arithmatex">\(n - 1\)</span> instead
of <span class="arithmatex">\((\sum_i w_i) - 1\)</span>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[FLM2022]</code></dt>
<dd>
<p>T. Fissler, C. Lorentzen, and M. Mayer.
"Model Comparison and Calibration Assessment". (2022)
<a href="https://arxiv.org/abs/2202.12780">arxiv:2202.12780</a>.</p>
</dd>
</dl>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">compute_bias</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">shape: (1, 5)</span>
<span class="go">┌───────────┬────────────┬──────────────┬─────────────┬──────────┐</span>
<span class="go">│ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value  │</span>
<span class="go">│ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---      │</span>
<span class="go">│ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64      │</span>
<span class="go">╞═══════════╪════════════╪══════════════╪═════════════╪══════════╡</span>
<span class="go">│ 0.25      ┆ 4          ┆ 4.0          ┆ 0.478714    ┆ 0.637618 │</span>
<span class="go">└───────────┴────────────┴──────────────┴─────────────┴──────────┘</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">compute_bias</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span><span class="n">feature</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">])</span>
<span class="go">shape: (2, 6)</span>
<span class="go">┌─────────┬───────────┬────────────┬──────────────┬─────────────┬─────────┐</span>
<span class="go">│ feature ┆ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value │</span>
<span class="go">│ ---     ┆ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---     │</span>
<span class="go">│ str     ┆ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64     │</span>
<span class="go">╞═════════╪═══════════╪════════════╪══════════════╪═════════════╪═════════╡</span>
<span class="go">│ a       ┆ 0.0       ┆ 2          ┆ 2.0          ┆ 1.0         ┆ 1.0     │</span>
<span class="go">│ b       ┆ 0.5       ┆ 2          ┆ 2.0          ┆ 0.5         ┆ 0.5     │</span>
<span class="go">└─────────┴───────────┴────────────┴──────────────┴─────────────┴─────────┘</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/identification.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_bias</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">feature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">functional</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">n_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">bin_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;quantile&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute generalised bias conditional on a feature.</span>

<span class="sd">    This function computes and aggregates the generalised bias, i.e. the values of the</span>
<span class="sd">    canonical identification function, versus (grouped by) a feature.</span>
<span class="sd">    This is a good way to assess whether a model is conditionally calibrated or not.</span>
<span class="sd">    Well calibrated models have bias terms around zero.</span>
<span class="sd">    For the mean functional, the generalised bias is the negative residual</span>
<span class="sd">    `y_pred - y_obs`.</span>
<span class="sd">    See [Notes](#notes) for further details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs) or (n_obs, n_models)</span>
<span class="sd">        Predicted values, e.g. for the conditional expectation of the response,</span>
<span class="sd">        `E(Y|X)`.</span>
<span class="sd">    feature : array-like of shape (n_obs) or None</span>
<span class="sd">        Some feature column.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights. If given, the bias is calculated as weighted average of the</span>
<span class="sd">        identification function with these weights.</span>
<span class="sd">        Note that the standard errors and p-values in the output are based on the</span>
<span class="sd">        assumption that the variance of the bias is inverse proportional to the</span>
<span class="sd">        weights. See the Notes section for details.</span>
<span class="sd">    functional : str</span>
<span class="sd">        The functional that is induced by the identification function `V`. Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile of quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` and `functional=&quot;expectile&quot;` gives the mean.</span>
<span class="sd">        `level=0.5` and `functional=&quot;quantile&quot;` gives the median.</span>
<span class="sd">    n_bins : int</span>
<span class="sd">        The number of bins for numerical features and the maximal number of (most</span>
<span class="sd">        frequent) categories shown for categorical features. Due to ties, the effective</span>
<span class="sd">        number of bins might be smaller than `n_bins`. Null values are always included</span>
<span class="sd">        in the output, accounting for one bin. NaN values are treated as null values.</span>
<span class="sd">    bin_method : str</span>
<span class="sd">        The method to use for finding bin edges (boundaries). Options are:</span>

<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">        - `&quot;uniform&quot;`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    df : polars.DataFrame</span>
<span class="sd">        The result table contains at least the columns:</span>

<span class="sd">        - `bias_mean`: Mean of the bias</span>
<span class="sd">        - `bias_cout`: Number of data rows</span>
<span class="sd">        - `bias_weights`: Sum of weights</span>
<span class="sd">        - `bias_stderr`: Standard error, i.e. standard deviation of `bias_mean`</span>
<span class="sd">        - `p_value`: p-value of the 2-sided t-test with null hypothesis:</span>
<span class="sd">          `bias_mean = 0`</span>

<span class="sd">        If `feautre ` is not None, then there is also the column:</span>

<span class="sd">        - `feature_name`: The actual name of the feature with the (binned) feature</span>
<span class="sd">          values.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    [](){#notes}</span>
<span class="sd">    A model \(m(X)\) is conditionally calibrated iff</span>
<span class="sd">    \(\mathbb{E}(V(m(X), Y)|X)=0\) almost surely with canonical identification</span>
<span class="sd">    function \(V\).</span>
<span class="sd">    The empirical version, given some data, reads</span>
<span class="sd">    \(\bar{V} = \frac{1}{n}\sum_i \phi(x_i) V(m(x_i), y_i)\) with a test function</span>
<span class="sd">    \(\phi(x_i)\) that projects on the specified feature.</span>
<span class="sd">    For a feature with only two distinct values `&quot;a&quot;` and `&quot;b&quot;`, this becomes</span>
<span class="sd">    \(\bar{V} = \frac{1}{n_a}\sum_{i \text{ with }x_i=a} V(m(a), y_i)\) with</span>
<span class="sd">    \(n_a=\sum_{i \text{ with }x_i=a}\) and similar for `&quot;b&quot;`.</span>
<span class="sd">    With case weights, this reads</span>
<span class="sd">    \(\bar{V} = \frac{1}{\sum_i w_i}\sum_i w_i \phi(x_i) V(m(x_i), y_i)\).</span>
<span class="sd">    This generalises the classical residual (up to a minus sign) for target functionals</span>
<span class="sd">    other than the mean. See `[FLM2022]`.</span>

<span class="sd">    The standard error for \(\bar{V}\) is calculated in the standard way as</span>
<span class="sd">    \(\mathrm{SE} = \sqrt{\operatorname{Var}(\bar{V})} = \frac{\sigma}{\sqrt{n}}\) and</span>
<span class="sd">    the standard variance estimator for \(\sigma^2 = \operatorname{Var}(\phi(x_i)</span>
<span class="sd">    V(m(x_i), y_i))\) with Bessel correction, i.e. division by \(n-1\) instead of</span>
<span class="sd">    \(n\).</span>

<span class="sd">    With case weights, the variance estimator becomes \(\operatorname{Var}(\bar{V})</span>
<span class="sd">    = \frac{1}{n-1} \frac{1}{\sum_i w_i} \sum_i w_i (V(m(x_i), y_i) - \bar{V})^2\) with</span>
<span class="sd">    the implied relation \(\operatorname{Var}(V(m(x_i), y_i)) \sim \frac{1}{w_i} \).</span>
<span class="sd">    If your weights are for repeated observations, so-called frequency weights, then</span>
<span class="sd">    the above estimate is conservative because it uses \(n - 1\) instead</span>
<span class="sd">    of \((\sum_i w_i) - 1\).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[FLM2022]`</span>

<span class="sd">    :   T. Fissler, C. Lorentzen, and M. Mayer.</span>
<span class="sd">        &quot;Model Comparison and Calibration Assessment&quot;. (2022)</span>
<span class="sd">        [arxiv:2202.12780](https://arxiv.org/abs/2202.12780).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; compute_bias(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2])</span>
<span class="sd">    shape: (1, 5)</span>
<span class="sd">    ┌───────────┬────────────┬──────────────┬─────────────┬──────────┐</span>
<span class="sd">    │ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value  │</span>
<span class="sd">    │ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---      │</span>
<span class="sd">    │ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64      │</span>
<span class="sd">    ╞═══════════╪════════════╪══════════════╪═════════════╪══════════╡</span>
<span class="sd">    │ 0.25      ┆ 4          ┆ 4.0          ┆ 0.478714    ┆ 0.637618 │</span>
<span class="sd">    └───────────┴────────────┴──────────────┴─────────────┴──────────┘</span>
<span class="sd">    &gt;&gt;&gt; compute_bias(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2],</span>
<span class="sd">    ... feature=[&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;])</span>
<span class="sd">    shape: (2, 6)</span>
<span class="sd">    ┌─────────┬───────────┬────────────┬──────────────┬─────────────┬─────────┐</span>
<span class="sd">    │ feature ┆ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value │</span>
<span class="sd">    │ ---     ┆ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---     │</span>
<span class="sd">    │ str     ┆ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64     │</span>
<span class="sd">    ╞═════════╪═══════════╪════════════╪══════════════╪═════════════╪═════════╡</span>
<span class="sd">    │ a       ┆ 0.0       ┆ 2          ┆ 2.0          ┆ 1.0         ┆ 1.0     │</span>
<span class="sd">    │ b       ┆ 0.5       ┆ 2          ┆ 2.0          ┆ 0.5         ┆ 0.5     │</span>
<span class="sd">    └─────────┴───────────┴────────────┴──────────────┴─────────────┴─────────┘</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">n_pred</span> <span class="o">=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">pred_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;The array weights must be 1-dimensional, got weights.ndim=</span><span class="si">{</span><span class="n">w</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

    <span class="n">df_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">pl</span><span class="o">.</span><span class="n">StringCache</span><span class="p">():</span>
        <span class="n">feature</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">is_categorical</span><span class="p">,</span> <span class="n">is_string</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">f_binned</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">bin_feature</span><span class="p">(</span>
                <span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
                <span class="n">feature_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
                <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
                <span class="n">bin_method</span><span class="o">=</span><span class="n">bin_method</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">)):</span>
            <span class="c1"># Loop over columns of y_pred.</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

            <span class="n">bias</span> <span class="o">=</span> <span class="n">identification_function</span><span class="p">(</span>
                <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
                <span class="n">y_pred</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                <span class="n">functional</span><span class="o">=</span><span class="n">functional</span><span class="p">,</span>
                <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">feature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">bias_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
                <span class="n">bias_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
                <span class="n">bias_count</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="c1"># Note: with Bessel correction</span>
                <span class="n">bias_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">((</span><span class="n">bias</span> <span class="o">-</span> <span class="n">bias_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias_count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;bias_mean&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">bias_mean</span><span class="p">],</span>
                        <span class="s2">&quot;bias_count&quot;</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">bias_count</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">UInt32</span><span class="p">),</span>
                        <span class="s2">&quot;bias_weights&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">bias_weights</span><span class="p">],</span>
                        <span class="s2">&quot;bias_stderr&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">bias_stddev</span><span class="p">)],</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;y_obs&quot;</span><span class="p">:</span> <span class="n">y_obs</span><span class="p">,</span>
                        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                        <span class="n">feature_name</span><span class="p">:</span> <span class="n">feature</span><span class="p">,</span>
                        <span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="n">bias</span><span class="p">,</span>
                        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span>
                    <span class="p">}</span>
                <span class="p">)</span>

                <span class="n">agg_list</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">(),</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">),</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_weights&quot;</span><span class="p">),</span>
                    <span class="p">(</span>
                        <span class="p">(</span>
                            <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span>
                            <span class="o">*</span> <span class="p">((</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                        <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;variance&quot;</span><span class="p">),</span>
                <span class="p">]</span>

                <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">is_string</span><span class="p">:</span>
                    <span class="n">groupby_name</span> <span class="o">=</span> <span class="n">feature_name</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">f_binned</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bin&quot;</span><span class="p">)])</span>
                    <span class="n">groupby_name</span> <span class="o">=</span> <span class="s2">&quot;bin&quot;</span>
                    <span class="n">agg_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

                <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">df</span><span class="o">.</span><span class="n">lazy</span><span class="p">()</span>
                    <span class="o">.</span><span class="n">select</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span>
                        <span class="p">(</span>
                            <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                            <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">),</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">agg_list</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
                            <span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;variance&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;variance&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">),</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                    <span class="c1"># With sort and head alone, we could lose the null value, but we</span>
                    <span class="c1"># want to keep it.</span>
                    <span class="c1"># .sort(&quot;bias_count&quot;, descending=True)</span>
                    <span class="c1"># .head(n_bins)</span>
                    <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_null</span><span class="p">())</span>
                        <span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">))</span>
                        <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;__priority&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;__priority&quot;</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># FIXME: When n_bins=0, the result should be an empty dataframe</span>
                <span class="c1"># (0 rows and some columns). For some unknown reason as of</span>
                <span class="c1"># polars 0.20.20, the following sort neglects the head(0) statement.</span>
                <span class="c1"># Therefore, we place an explicit collect here. This should not be</span>
                <span class="c1"># needed!</span>
                <span class="k">if</span> <span class="n">n_bins</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">feature</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">lazy</span><span class="p">()</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_weights&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

                <span class="c1"># if is_categorical:</span>
                <span class="c1">#     # Pyarrow does not yet support sorting dictionary type arrays,</span>
                <span class="c1">#     # see https://github.com/apache/arrow/issues/29887</span>
                <span class="c1">#     # We resort to pandas instead.</span>
                <span class="c1">#     import pyarrow as pa</span>
                <span class="c1">#     df = df.to_pandas().sort_values(feature_name)</span>
                <span class="c1">#     df = pa.Table.from_pandas(df)</span>

            <span class="c1"># Add column with p-value of 2-sided t-test.</span>
            <span class="c1"># We explicitly convert &quot;to_numpy&quot;, because otherwise we get:</span>
            <span class="c1">#   RuntimeWarning: A builtin ctypes object gave a PEP3118 format string</span>
            <span class="c1">#   that does not match its itemsize, so a best-guess will be made of the</span>
            <span class="c1">#   data type. Newer versions of python may behave correctly.</span>
            <span class="n">stderr_</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">)</span>
            <span class="n">p_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">stderr_</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span>
            <span class="n">p_value</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">((</span><span class="n">n</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">stderr_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">stderr_</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bias_count&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">stderr</span> <span class="o">=</span> <span class="n">stderr_</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="c1"># t-statistic t (-|t| and factor of 2 because of 2-sided test)</span>
            <span class="n">p_value</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">special</span><span class="o">.</span><span class="n">stdtr</span><span class="p">(</span>
                <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># degrees of freedom</span>
                <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">stderr</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="s2">&quot;p_value&quot;</span><span class="p">,</span> <span class="n">p_value</span><span class="p">))</span>

            <span class="c1"># Add column &quot;model&quot;.</span>
            <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">model_col_name</span> <span class="o">=</span> <span class="s2">&quot;model_&quot;</span> <span class="k">if</span> <span class="n">feature_name</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span> <span class="k">else</span> <span class="s2">&quot;model&quot;</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model_col_name</span><span class="p">,</span> <span class="p">[</span><span class="n">pred_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="p">)</span>

            <span class="c1"># Select the columns in the correct order.</span>
            <span class="n">col_selection</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">col_selection</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_col_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="n">col_selection</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>
            <span class="n">col_selection</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="s2">&quot;bias_mean&quot;</span><span class="p">,</span>
                <span class="s2">&quot;bias_count&quot;</span><span class="p">,</span>
                <span class="s2">&quot;bias_weights&quot;</span><span class="p">,</span>
                <span class="s2">&quot;bias_stderr&quot;</span><span class="p">,</span>
                <span class="s2">&quot;p_value&quot;</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="n">df_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col_selection</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">df_list</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.compute_marginal" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_marginal</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feature_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">predict_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bin_method</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">n_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.compute_marginal" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Compute the marginal expectation conditional on a single feature.</p>
<p>This function computes the (weighted) average of observed response and predictions
conditional on a given feature.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs) or (n_obs, n_models)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values, e.g. for the conditional expectation of the response,
<code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code>array-like of shape (n_obs, n_features) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dataframe or array of features to be passed to the model predict function.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature_name</code></td>
            <td>
                  <code>(int, str or None)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Column name (str) or index (int) of feature in <code>X</code>. If None, the total marginal
is computed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>predict_function</code></td>
            <td>
                  <code>callable or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A callable to get prediction, i.e. <code>predict_function(X)</code>. Used to compute
partial dependence. If <code>None</code>, partial dependence is omitted.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights. If given, the bias is calculated as weighted average of the
identification function with these weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of bins for numerical features and the maximal number of (most
frequent) categories shown for categorical features. Due to ties, the effective
number of bins might be smaller than <code>n_bins</code>. Null values are always included
in the output, accounting for one bin. NaN values are treated as null values.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bin_method</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The method to use for finding bin edges (boundaries). Options are:</p>
<ul>
<li><code>"quantile"</code></li>
<li><code>"uniform"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;uniform&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_max</code></td>
            <td>
                  <code>int or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Used only for partial dependence computation. The number of rows to subsample
from X. This speeds up computation, in particular for slow predict functions.</p>
              </div>
            </td>
            <td>
                  <code>1000</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>rng</code></td>
            <td>
                  <code>(<span title="numpy.random.Generator">Generator</span>, int or None)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Used only for partial dependence computation. The random number generator used
for subsampling of <code>n_max</code> rows. The input is internally wrapped by
<code>np.random.default_rng(rng)</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>df</code></td>            <td>
                  <code><span title="polars.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The result table contains at least the columns:</p>
<ul>
<li><code>y_obs_mean</code>: Mean of <code>y_obs</code></li>
<li><code>y_pred_mean</code>: Mean of <code>y_pred</code></li>
<li><code>y_obs_stderr</code>: Standard error, i.e. standard deviation of <code>y_obs_mean</code></li>
<li><code>y_pred_stderr</code>: Standard error, i.e. standard deviation of <code>y_pred_mean</code></li>
<li><code>count</code>: Number of data rows</li>
<li><code>weights</code>: Sum of weights</li>
</ul>
<p>If <code>feature</code> is not None, then there is also the column:</p>
<ul>
<li><code>feature_name</code>: The actual name of the feature with the (binned) feature
  values.</li>
</ul>
<p>If <code>feature</code> is numerical, one also has:</p>
<ul>
<li><code>bin_edges</code>: The edges and standard deviation of the bins, i.e.
  (min, std, max).</li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p>The marginal values are computed as an estimation of:</p>
<ul>
<li><code>y_obs</code>: <span class="arithmatex">\(\mathbb{E}(Y|feature)\)</span></li>
<li><code>y_pred</code>: <span class="arithmatex">\(\mathbb{E}(m(X)|feature)\)</span></li>
</ul>
<p>with <span class="arithmatex">\(feature\)</span> the column specified by <code>feature_name</code>.
Computationally that is more or less a group-by-aggregate operation on a dataset.</p>
<p>The standard error for both are calculated in the standard way as
<span class="arithmatex">\(\mathrm{SE} = \sqrt{\operatorname{Var}(\bar{Y})} = \frac{\sigma}{\sqrt{n}}\)</span> and
the standard variance estimator for <span class="arithmatex">\(\sigma^2\)</span> with Bessel correction, i.e.
division by <span class="arithmatex">\(n-1\)</span> instead of <span class="arithmatex">\(n\)</span>.</p>
<p>With case weights, the variance estimator becomes <span class="arithmatex">\(\operatorname{Var}(\bar{Y})
= \frac{1}{n-1} \frac{1}{\sum_i w_i} \sum_i w_i (y_i - \bar{y})^2\)</span> with
the implied relation <span class="arithmatex">\(\operatorname{Var}(y_i) \sim \frac{1}{w_i} \)</span>.
If your weights are for repeated observations, so-called frequency weights, then
the above estimate is conservative because it uses <span class="arithmatex">\(n - 1\)</span> instead
of <span class="arithmatex">\((\sum_i w_i) - 1\)</span>.</p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">compute_marginal</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">shape: (1, 6)</span>
<span class="go">┌────────────┬─────────────┬──────────────┬───────────────┬───────┬─────────┐</span>
<span class="go">│ y_obs_mean ┆ y_pred_mean ┆ y_obs_stderr ┆ y_pred_stderr ┆ count ┆ weights │</span>
<span class="go">│ ---        ┆ ---         ┆ ---          ┆ ---           ┆ ---   ┆ ---     │</span>
<span class="go">│ f64        ┆ f64         ┆ f64          ┆ f64           ┆ u32   ┆ f64     │</span>
<span class="go">╞════════════╪═════════════╪══════════════╪═══════════════╪═══════╪═════════╡</span>
<span class="go">│ 0.5        ┆ 0.75        ┆ 0.288675     ┆ 0.629153      ┆ 4     ┆ 4.0     │</span>
<span class="go">└────────────┴─────────────┴──────────────┴───────────────┴───────┴─────────┘</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">polars</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pl</span><span class="o">.</span><span class="n">Config</span><span class="o">.</span><span class="n">set_tbl_width_chars</span><span class="p">(</span><span class="mi">84</span><span class="p">)</span>
<span class="go">&lt;class &#39;polars.config.Config&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_obs</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">compute_marginal</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_name</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span><span class="n">predict_function</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">)</span>
<span class="go">shape: (3, 9)</span>
<span class="go">┌──────────┬─────────┬─────────┬─────────┬───┬───────┬─────────┬─────────┬─────────┐</span>
<span class="go">│ feature  ┆ y_obs_m ┆ y_pred_ ┆ y_obs_s ┆ … ┆ count ┆ weights ┆ bin_edg ┆ partial │</span>
<span class="go">│ 0        ┆ ean     ┆ mean    ┆ tderr   ┆   ┆ ---   ┆ ---     ┆ es      ┆ _depend │</span>
<span class="go">│ ---      ┆ ---     ┆ ---     ┆ ---     ┆   ┆ u32   ┆ f64     ┆ ---     ┆ ence    │</span>
<span class="go">│ f64      ┆ f64     ┆ f64     ┆ f64     ┆   ┆       ┆         ┆ array[f ┆ ---     │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 64, 3]  ┆ f64     │</span>
<span class="go">╞══════════╪═════════╪═════════╪═════════╪═══╪═══════╪═════════╪═════════╪═════════╡</span>
<span class="go">│ 0.0      ┆ 0.0     ┆ 0.1     ┆ 0.0     ┆ … ┆ 1     ┆ 1.0     ┆ [0.0,   ┆ 0.3     │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.2]    ┆         │</span>
<span class="go">│ 1.0      ┆ 0.5     ┆ 0.5     ┆ 0.5     ┆ … ┆ 2     ┆ 2.0     ┆ [0.8,   ┆ 0.5     │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 1.0]    ┆         │</span>
<span class="go">│ 2.0      ┆ 1.0     ┆ 0.9     ┆ 0.0     ┆ … ┆ 1     ┆ 1.0     ┆ [1.8,   ┆ 0.7     │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="go">│          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 2.0]    ┆         │</span>
<span class="go">└──────────┴─────────┴─────────┴─────────┴───┴───────┴─────────┴─────────┴─────────┘</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/identification.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_marginal</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feature_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">predict_function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">n_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">bin_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
    <span class="n">n_max</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the marginal expectation conditional on a single feature.</span>

<span class="sd">    This function computes the (weighted) average of observed response and predictions</span>
<span class="sd">    conditional on a given feature.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs) or (n_obs, n_models)</span>
<span class="sd">        Predicted values, e.g. for the conditional expectation of the response,</span>
<span class="sd">        `E(Y|X)`.</span>
<span class="sd">    X : array-like of shape (n_obs, n_features) or None</span>
<span class="sd">        The dataframe or array of features to be passed to the model predict function.</span>
<span class="sd">    feature_name : int, str or None</span>
<span class="sd">        Column name (str) or index (int) of feature in `X`. If None, the total marginal</span>
<span class="sd">        is computed.</span>
<span class="sd">    predict_function : callable or None</span>
<span class="sd">        A callable to get prediction, i.e. `predict_function(X)`. Used to compute</span>
<span class="sd">        partial dependence. If `None`, partial dependence is omitted.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights. If given, the bias is calculated as weighted average of the</span>
<span class="sd">        identification function with these weights.</span>
<span class="sd">    n_bins : int</span>
<span class="sd">        The number of bins for numerical features and the maximal number of (most</span>
<span class="sd">        frequent) categories shown for categorical features. Due to ties, the effective</span>
<span class="sd">        number of bins might be smaller than `n_bins`. Null values are always included</span>
<span class="sd">        in the output, accounting for one bin. NaN values are treated as null values.</span>
<span class="sd">    bin_method : str</span>
<span class="sd">        The method to use for finding bin edges (boundaries). Options are:</span>

<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">        - `&quot;uniform&quot;`</span>
<span class="sd">    n_max : int or None</span>
<span class="sd">        Used only for partial dependence computation. The number of rows to subsample</span>
<span class="sd">        from X. This speeds up computation, in particular for slow predict functions.</span>
<span class="sd">    rng : np.random.Generator, int or None</span>
<span class="sd">        Used only for partial dependence computation. The random number generator used</span>
<span class="sd">        for subsampling of `n_max` rows. The input is internally wrapped by</span>
<span class="sd">        `np.random.default_rng(rng)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    df : polars.DataFrame</span>
<span class="sd">        The result table contains at least the columns:</span>

<span class="sd">        - `y_obs_mean`: Mean of `y_obs`</span>
<span class="sd">        - `y_pred_mean`: Mean of `y_pred`</span>
<span class="sd">        - `y_obs_stderr`: Standard error, i.e. standard deviation of `y_obs_mean`</span>
<span class="sd">        - `y_pred_stderr`: Standard error, i.e. standard deviation of `y_pred_mean`</span>
<span class="sd">        - `count`: Number of data rows</span>
<span class="sd">        - `weights`: Sum of weights</span>

<span class="sd">        If `feature ` is not None, then there is also the column:</span>

<span class="sd">        - `feature_name`: The actual name of the feature with the (binned) feature</span>
<span class="sd">          values.</span>

<span class="sd">        If `feature` is numerical, one also has:</span>

<span class="sd">        - `bin_edges`: The edges and standard deviation of the bins, i.e.</span>
<span class="sd">          (min, std, max).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The marginal values are computed as an estimation of:</span>

<span class="sd">    - `y_obs`: \(\mathbb{E}(Y|feature)\)</span>
<span class="sd">    - `y_pred`: \(\mathbb{E}(m(X)|feature)\)</span>

<span class="sd">    with \(feature\) the column specified by `feature_name`.</span>
<span class="sd">    Computationally that is more or less a group-by-aggregate operation on a dataset.</span>

<span class="sd">    The standard error for both are calculated in the standard way as</span>
<span class="sd">    \(\mathrm{SE} = \sqrt{\operatorname{Var}(\bar{Y})} = \frac{\sigma}{\sqrt{n}}\) and</span>
<span class="sd">    the standard variance estimator for \(\sigma^2\) with Bessel correction, i.e.</span>
<span class="sd">    division by \(n-1\) instead of \(n\).</span>

<span class="sd">    With case weights, the variance estimator becomes \(\operatorname{Var}(\bar{Y})</span>
<span class="sd">    = \frac{1}{n-1} \frac{1}{\sum_i w_i} \sum_i w_i (y_i - \bar{y})^2\) with</span>
<span class="sd">    the implied relation \(\operatorname{Var}(y_i) \sim \frac{1}{w_i} \).</span>
<span class="sd">    If your weights are for repeated observations, so-called frequency weights, then</span>
<span class="sd">    the above estimate is conservative because it uses \(n - 1\) instead</span>
<span class="sd">    of \((\sum_i w_i) - 1\).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; compute_marginal(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1, 2])</span>
<span class="sd">    shape: (1, 6)</span>
<span class="sd">    ┌────────────┬─────────────┬──────────────┬───────────────┬───────┬─────────┐</span>
<span class="sd">    │ y_obs_mean ┆ y_pred_mean ┆ y_obs_stderr ┆ y_pred_stderr ┆ count ┆ weights │</span>
<span class="sd">    │ ---        ┆ ---         ┆ ---          ┆ ---           ┆ ---   ┆ ---     │</span>
<span class="sd">    │ f64        ┆ f64         ┆ f64          ┆ f64           ┆ u32   ┆ f64     │</span>
<span class="sd">    ╞════════════╪═════════════╪══════════════╪═══════════════╪═══════╪═════════╡</span>
<span class="sd">    │ 0.5        ┆ 0.75        ┆ 0.288675     ┆ 0.629153      ┆ 4     ┆ 4.0     │</span>
<span class="sd">    └────────────┴─────────────┴──────────────┴───────────────┴───────┴─────────┘</span>
<span class="sd">    &gt;&gt;&gt; import polars as pl</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import Ridge</span>
<span class="sd">    &gt;&gt;&gt; pl.Config.set_tbl_width_chars(84)  # doctest: +ELLIPSIS</span>
<span class="sd">    &lt;class &#39;polars.config.Config&#39;&gt;</span>
<span class="sd">    &gt;&gt;&gt; y_obs, X =[0, 0, 1, 1], [[0, 1], [1, 1], [1, 2], [2, 2]]</span>
<span class="sd">    &gt;&gt;&gt; m = Ridge().fit(X, y_obs)</span>
<span class="sd">    &gt;&gt;&gt; compute_marginal(y_obs=y_obs, y_pred=m.predict(X), X=X, feature_name=0,</span>
<span class="sd">    ... predict_function=m.predict)</span>
<span class="sd">    shape: (3, 9)</span>
<span class="sd">    ┌──────────┬─────────┬─────────┬─────────┬───┬───────┬─────────┬─────────┬─────────┐</span>
<span class="sd">    │ feature  ┆ y_obs_m ┆ y_pred_ ┆ y_obs_s ┆ … ┆ count ┆ weights ┆ bin_edg ┆ partial │</span>
<span class="sd">    │ 0        ┆ ean     ┆ mean    ┆ tderr   ┆   ┆ ---   ┆ ---     ┆ es      ┆ _depend │</span>
<span class="sd">    │ ---      ┆ ---     ┆ ---     ┆ ---     ┆   ┆ u32   ┆ f64     ┆ ---     ┆ ence    │</span>
<span class="sd">    │ f64      ┆ f64     ┆ f64     ┆ f64     ┆   ┆       ┆         ┆ array[f ┆ ---     │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 64, 3]  ┆ f64     │</span>
<span class="sd">    ╞══════════╪═════════╪═════════╪═════════╪═══╪═══════╪═════════╪═════════╪═════════╡</span>
<span class="sd">    │ 0.0      ┆ 0.0     ┆ 0.1     ┆ 0.0     ┆ … ┆ 1     ┆ 1.0     ┆ [0.0,   ┆ 0.3     │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.2]    ┆         │</span>
<span class="sd">    │ 1.0      ┆ 0.5     ┆ 0.5     ┆ 0.5     ┆ … ┆ 2     ┆ 2.0     ┆ [0.8,   ┆ 0.5     │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 1.0]    ┆         │</span>
<span class="sd">    │ 2.0      ┆ 1.0     ┆ 0.9     ┆ 0.0     ┆ … ┆ 1     ┆ 1.0     ┆ [1.8,   ┆ 0.7     │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 0.0,    ┆         │</span>
<span class="sd">    │          ┆         ┆         ┆         ┆   ┆       ┆         ┆ 2.0]    ┆         │</span>
<span class="sd">    └──────────┴─────────┴─────────┴─────────┴───┴───────┴─────────┴─────────┴─────────┘</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">n_pred</span> <span class="o">=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">pred_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">y_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;The array weights must be 1-dimensional, got weights.ndim=</span><span class="si">{</span><span class="n">w</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># X is completely ignored.</span>
        <span class="n">feature_input</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;X must be a data container like a (polars) dataframe or an (numpy) array.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">)):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;The argument &#39;feature_name&#39; must be an int or str; got </span><span class="si">{</span><span class="n">feature_name</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">feature_index</span> <span class="o">=</span> <span class="n">feature_name</span>
        <span class="n">feature_input</span> <span class="o">=</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">feature_index</span> <span class="o">=</span> <span class="n">X_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>
        <span class="n">feature_input</span> <span class="o">=</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_index</span><span class="p">)</span>

    <span class="n">df_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">pl</span><span class="o">.</span><span class="n">StringCache</span><span class="p">():</span>
        <span class="p">(</span>
            <span class="n">feature</span><span class="p">,</span>
            <span class="n">feature_name</span><span class="p">,</span>
            <span class="n">is_categorical</span><span class="p">,</span>
            <span class="n">is_string</span><span class="p">,</span>
            <span class="n">n_bins</span><span class="p">,</span>
            <span class="n">f_binned</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">bin_feature</span><span class="p">(</span>
            <span class="n">feature</span><span class="o">=</span><span class="n">feature_input</span><span class="p">,</span>
            <span class="n">feature_name</span><span class="o">=</span><span class="n">feature_name</span><span class="p">,</span>
            <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
            <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
            <span class="n">bin_method</span><span class="o">=</span><span class="n">bin_method</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">)):</span>
            <span class="c1"># Loop over columns of y_pred.</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_pred</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">feature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">y_obs_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
                <span class="n">y_pred_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
                <span class="n">weights_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
                <span class="n">count</span> <span class="o">=</span> <span class="n">y_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="c1"># Note: with Bessel correction</span>
                <span class="n">y_obs_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">y_obs</span> <span class="o">-</span> <span class="n">y_obs_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span>
                <span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
                <span class="n">y_pred_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">y_pred_mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span>
                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;y_obs_mean&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">y_obs_mean</span><span class="p">],</span>
                        <span class="s2">&quot;y_pred_mean&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">y_pred_mean</span><span class="p">],</span>
                        <span class="s2">&quot;count&quot;</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="n">count</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">UInt32</span><span class="p">),</span>
                        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">weights_sum</span><span class="p">],</span>
                        <span class="s2">&quot;y_obs_stderr&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_obs_stddev</span><span class="p">)],</span>
                        <span class="s2">&quot;y_pred_stderr&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_pred_stddev</span><span class="p">)],</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;y_obs&quot;</span><span class="p">:</span> <span class="n">y_obs</span><span class="p">,</span>
                        <span class="s2">&quot;y_pred&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                        <span class="n">feature_name</span><span class="p">:</span> <span class="n">feature</span><span class="p">,</span>
                        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="n">w</span><span class="p">,</span>
                    <span class="p">}</span>
                <span class="p">)</span>

                <span class="n">agg_list</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s2">&quot;y_obs&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">),</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;weights_sum&quot;</span><span class="p">),</span>
                    <span class="o">*</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_mean&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">(),</span>
                            <span class="p">(</span>
                                <span class="p">(</span>
                                    <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span>
                                    <span class="o">*</span> <span class="p">((</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">-</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_mean&quot;</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
                                <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                                <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                            <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_variance&quot;</span><span class="p">),</span>
                        <span class="p">]</span>
                        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;y_obs&quot;</span><span class="p">,</span> <span class="s2">&quot;y_pred&quot;</span><span class="p">]</span>
                    <span class="p">),</span>
                <span class="p">]</span>

                <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">is_string</span><span class="p">:</span>
                    <span class="n">groupby_name</span> <span class="o">=</span> <span class="n">feature_name</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># We also add the bin edges.</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">f_binned</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bin&quot;</span><span class="p">),</span> <span class="n">f_binned</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)]</span>
                    <span class="p">)</span>
                    <span class="n">groupby_name</span> <span class="o">=</span> <span class="s2">&quot;bin&quot;</span>
                    <span class="n">agg_list</span> <span class="o">+=</span> <span class="p">[</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;__feature_std&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">(),</span>
                    <span class="p">]</span>

                <span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">df</span><span class="o">.</span><span class="n">lazy</span><span class="p">()</span>
                    <span class="o">.</span><span class="n">select</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span>
                        <span class="p">(</span>
                            <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_obs&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                            <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;y_obs_mean&quot;</span><span class="p">),</span>
                        <span class="p">(</span>
                            <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_pred&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                            <span class="o">/</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;y_pred_mean&quot;</span><span class="p">),</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">group_by</span><span class="p">(</span><span class="n">groupby_name</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">agg_list</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
                            <span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_variance&quot;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_variance&quot;</span><span class="p">))</span>
                            <span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
                            <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;_stderr&quot;</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;y_obs&quot;</span><span class="p">,</span> <span class="s2">&quot;y_pred&quot;</span><span class="p">)</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                    <span class="c1"># With sort and head alone, we could lose the null value, but we</span>
                    <span class="c1"># want to keep it.</span>
                    <span class="c1"># .sort(&quot;bias_count&quot;, descending=True)</span>
                    <span class="c1"># .head(n_bins)</span>
                    <span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_null</span><span class="p">())</span>
                        <span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">))</span>
                        <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;__priority&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="s2">&quot;__priority&quot;</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># FIXME: When n_bins=0, the result should be an empty dataframe</span>
                <span class="c1"># (0 rows and some columns). For some unknown reason as of</span>
                <span class="c1"># polars 0.20.20, the following sort neglects the head(0) statement.</span>
                <span class="c1"># Therefore, we place an explicit collect here. This should not be</span>
                <span class="c1"># needed!</span>
                <span class="k">if</span> <span class="n">n_bins</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">feature</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="o">.</span><span class="n">lazy</span><span class="p">()</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_obs_mean&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_pred_mean&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_obs_stderr&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;y_pred_stderr&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;weights_sum&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;weights&quot;</span><span class="p">),</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">),</span>
                    <span class="p">]</span>
                    <span class="o">+</span> <span class="p">(</span>
                        <span class="p">[]</span>
                        <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">is_string</span>
                        <span class="k">else</span> <span class="p">[</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">),</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;__feature_std&quot;</span><span class="p">)]</span>
                    <span class="p">)</span>
                <span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="n">is_categorical</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_string</span><span class="p">:</span>
                    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                        <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span>
                        <span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
                        <span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;__feature_std&quot;</span><span class="p">))</span>
                        <span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">())</span>
                        <span class="o">.</span><span class="n">list</span><span class="o">.</span><span class="n">to_array</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
                        <span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span>
                    <span class="p">)</span>

            <span class="c1"># Add column &quot;model&quot;.</span>
            <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">model_col_name</span> <span class="o">=</span> <span class="s2">&quot;model_&quot;</span> <span class="k">if</span> <span class="n">feature_name</span> <span class="o">==</span> <span class="s2">&quot;model&quot;</span> <span class="k">else</span> <span class="s2">&quot;model&quot;</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model_col_name</span><span class="p">,</span> <span class="p">[</span><span class="n">pred_names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">*</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="p">)</span>

            <span class="c1"># Add partial dependence.</span>
            <span class="n">with_pd</span> <span class="o">=</span> <span class="n">predict_function</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">with_pd</span><span class="p">:</span>
                <span class="n">pd_values</span> <span class="o">=</span> <span class="n">compute_partial_dependence</span><span class="p">(</span>
                    <span class="n">pred_fun</span><span class="o">=</span><span class="n">predict_function</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                    <span class="n">feature_index</span><span class="o">=</span><span class="n">feature_index</span><span class="p">,</span>
                    <span class="n">grid</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="n">feature_name</span><span class="p">),</span>
                    <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                    <span class="n">n_max</span><span class="o">=</span><span class="n">n_max</span><span class="p">,</span>
                    <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                    <span class="n">pl</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;partial_dependence&quot;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">pd_values</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># Select the columns in the correct order.</span>
            <span class="n">col_selection</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">col_selection</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_col_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="n">col_selection</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">feature_name</span><span class="p">))</span>
            <span class="n">col_selection</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="s2">&quot;y_obs_mean&quot;</span><span class="p">,</span>
                <span class="s2">&quot;y_pred_mean&quot;</span><span class="p">,</span>
                <span class="s2">&quot;y_obs_stderr&quot;</span><span class="p">,</span>
                <span class="s2">&quot;y_pred_stderr&quot;</span><span class="p">,</span>
                <span class="s2">&quot;count&quot;</span><span class="p">,</span>
                <span class="s2">&quot;weights&quot;</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="k">if</span> <span class="n">feature_name</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_categorical</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_string</span><span class="p">:</span>
                <span class="n">col_selection</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">with_pd</span><span class="p">:</span>
                <span class="n">col_selection</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;partial_dependence&quot;</span><span class="p">]</span>
            <span class="n">df_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">col_selection</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">df_list</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.identification_function" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">identification_function</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.identification_function" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Canonical identification function.</p>
<p>Identification functions act as generalised residuals. See <a href="#model_diagnostics.calibration.identification_function--notes">Notes</a> for
further details.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code>, e.g. the conditional expectation of
the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The functional that is induced by the identification function <code>V</code>. Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile of quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> and <code>functional="expectile"</code> gives the mean.
<code>level=0.5</code> and <code>functional="quantile"</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>V</code></td>            <td>
                  <code>ndarray of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the identification function.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><a href="" id="notes"></a>
The function <a href="" id="model_diagnostics.calibration.identification_function--notes"></a>
The function <span class="arithmatex">\(V(y, z)\)</span> for observation <span class="arithmatex">\(y=y_{pred}\)</span> and prediction
<span class="arithmatex">\(z=y_{pred}\)</span> is a strict identification function for the functional <span class="arithmatex">\(T\)</span>, or
induces the functional <span class="arithmatex">\(T\)</span> as:</p>
<div class="arithmatex">\[
\mathbb{E}[V(Y, z)] = 0\quad \Leftrightarrow\quad z\in T(F) \quad \forall
\text{ distributions } F
\in \mathcal{F}
\]</div>
<p>for some class of distributions <span class="arithmatex">\(\mathcal{F}\)</span>. Implemented examples of the
functional <span class="arithmatex">\(T\)</span> are mean, median, expectiles and quantiles.</p>
<table>
<thead>
<tr>
<th>functional</th>
<th>strict identification function <span class="arithmatex">\(V(y, z)\)</span></th>
</tr>
</thead>
<tbody>
<tr>
<td>mean</td>
<td><span class="arithmatex">\(z - y\)</span></td>
</tr>
<tr>
<td>median</td>
<td><span class="arithmatex">\(\mathbf{1}\{z \ge y\} - \frac{1}{2}\)</span></td>
</tr>
<tr>
<td>expectile</td>
<td><span class="arithmatex">\(2 \mid\mathbf{1}\{z \ge y\} - \alpha\mid (z - y)\)</span></td>
</tr>
<tr>
<td>quantile</td>
<td><span class="arithmatex">\(\mathbf{1}\{z \ge y\} - \alpha\)</span></td>
</tr>
</tbody>
</table>
<p>For <code>level</code> <span class="arithmatex">\(\alpha\)</span>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[Gneiting2011]</code></dt>
<dd>
<p>T. Gneiting.
"Making and Evaluating Point Forecasts". (2011)
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>
<a href="https://arxiv.org/abs/0912.0902">arxiv:0912.0902</a></p>
</dd>
</dl>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">identification_function</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([-1,  1,  0,  1])</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/identification.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">identification_function</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">functional</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Canonical identification function.</span>

<span class="sd">    Identification functions act as generalised residuals. See [Notes](#notes) for</span>
<span class="sd">    further details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional`, e.g. the conditional expectation of</span>
<span class="sd">        the response, `E(Y|X)`.</span>
<span class="sd">    functional : str</span>
<span class="sd">        The functional that is induced by the identification function `V`. Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile of quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` and `functional=&quot;expectile&quot;` gives the mean.</span>
<span class="sd">        `level=0.5` and `functional=&quot;quantile&quot;` gives the median.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    V : ndarray of shape (n_obs)</span>
<span class="sd">        Values of the identification function.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    [](){#notes}</span>
<span class="sd">    The function \(V(y, z)\) for observation \(y=y_{pred}\) and prediction</span>
<span class="sd">    \(z=y_{pred}\) is a strict identification function for the functional \(T\), or</span>
<span class="sd">    induces the functional \(T\) as:</span>

<span class="sd">    \[</span>
<span class="sd">    \mathbb{E}[V(Y, z)] = 0\quad \Leftrightarrow\quad z\in T(F) \quad \forall</span>
<span class="sd">    \text{ distributions } F</span>
<span class="sd">    \in \mathcal{F}</span>
<span class="sd">    \]</span>

<span class="sd">    for some class of distributions \(\mathcal{F}\). Implemented examples of the</span>
<span class="sd">    functional \(T\) are mean, median, expectiles and quantiles.</span>

<span class="sd">    | functional | strict identification function \(V(y, z)\)           |</span>
<span class="sd">    | ---------- | ---------------------------------------------------- |</span>
<span class="sd">    | mean       | \(z - y\)                                            |</span>
<span class="sd">    | median     | \(\mathbf{1}\{z \ge y\} - \frac{1}{2}\)              |</span>
<span class="sd">    | expectile  | \(2 \mid\mathbf{1}\{z \ge y\} - \alpha\mid (z - y)\) |</span>
<span class="sd">    | quantile   | \(\mathbf{1}\{z \ge y\} - \alpha\)                   |</span>

<span class="sd">    For `level` \(\alpha\).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[Gneiting2011]`</span>

<span class="sd">    :   T. Gneiting.</span>
<span class="sd">        &quot;Making and Evaluating Point Forecasts&quot;. (2011)</span>
<span class="sd">        [doi:10.1198/jasa.2011.r10138](https://doi.org/10.1198/jasa.2011.r10138)</span>
<span class="sd">        [arxiv:0912.0902](https://arxiv.org/abs/0912.0902)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; identification_function(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2])</span>
<span class="sd">    array([-1,  1,  0,  1])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_o</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y_p</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y_o</span><span class="p">,</span> <span class="n">y_p</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">functional</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;expectile&quot;</span><span class="p">,</span> <span class="s2">&quot;quantile&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">level</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">level</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Argument level must fulfil 0 &lt; level &lt; 1, got </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">y_p</span> <span class="o">-</span> <span class="n">y_o</span>
    <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;median&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">y_p</span><span class="p">,</span> <span class="n">y_o</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
    <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;expectile&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">y_p</span><span class="p">,</span> <span class="n">y_o</span><span class="p">)</span> <span class="o">-</span> <span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_p</span> <span class="o">-</span> <span class="n">y_o</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;quantile&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">y_p</span><span class="p">,</span> <span class="n">y_o</span><span class="p">)</span> <span class="o">-</span> <span class="n">level</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">allowed_functionals</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">,</span> <span class="s2">&quot;expectile&quot;</span><span class="p">,</span> <span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Argument functional must be one of </span><span class="si">{</span><span class="n">allowed_functionals</span><span class="si">}</span><span class="s2">, got &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">functional</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.plot_bias" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_bias</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bin_method</span><span class="o">=</span><span class="s1">&#39;quantile&#39;</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.plot_bias" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Plot model bias conditional on a feature.</p>
<p>This plots the generalised bias (residuals), i.e. the values of the canonical
identification function, versus a feature. This is a good way to assess whether
a model is conditionally calibrated or not. Well calibrated models have bias terms
around zero.
See <a href="#model_diagnostics.calibration.plot_bias--notes">Notes</a> for further details.</p>
<p>For numerical features, NaN are treated as Null values. Null values are always
plotted as rightmost value on the x-axis and marked with a diamond instead of a
dot.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs) or (n_obs, n_models)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values, e.g. for the conditional expectation of the response,
<code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Some feature column.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights. If given, the bias is calculated as weighted average of the
identification function with these weights.
Note that the standard errors and p-values in the output are based on the
assumption that the variance of the bias is inverse proportional to the
weights. See the Notes section for details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The functional that is induced by the identification function <code>V</code>. Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile or quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt;= level &lt;= 1</code>.
<code>level=0.5</code> and <code>functional="expectile"</code> gives the mean.
<code>level=0.5</code> and <code>functional="quantile"</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of bins for numerical features and the maximal number of (most
frequent) categories shown for categorical features. Due to ties, the effective
number of bins might be smaller than <code>n_bins</code>. Null values are always included
in the output, accounting for one bin. NaN values are treated as null values.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bin_method</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The method to use for finding bin edges (boundaries). Options are:</p>
<ul>
<li>"quantile"</li>
<li>"uniform"</li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;quantile&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>confidence_level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Confidence level for error bars. If 0, no error bars are plotted. Value must
fulfil <code>0 &lt;= confidence_level &lt; 1</code>.</p>
              </div>
            </td>
            <td>
                  <code>0.9</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ax</code></td>
            <td>
                  <code>matplotlib.axes.Axes or plotly Figure</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axes object to draw the plot onto, otherwise uses the current Axes.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ax</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either the matplotlib axes or the plotly figure. This is configurable by
setting the <code>plot_backend</code> via
<a class="autorefs autorefs-internal" href="../#model_diagnostics.set_config"><code>model_diagnostics.set_config</code></a> or
<a class="autorefs autorefs-internal" href="../#model_diagnostics.config_context"><code>model_diagnostics.config_context</code></a>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><a href="" id="notes"></a>
A model <a href="" id="model_diagnostics.calibration.plot_bias--notes"></a>
A model <span class="arithmatex">\(m(X)\)</span> is conditionally calibrated iff <span class="arithmatex">\(E(V(m(X), Y))=0\)</span> a.s. The
empirical version, given some data, reads <span class="arithmatex">\(\frac{1}{n}\sum_i V(m(x_i), y_i)\)</span>.
See <code>[FLM2022]</code>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>FLM2022</code></dt>
<dd>
<p>T. Fissler, C. Lorentzen, and M. Mayer.
"Model Comparison and Calibration Assessment". (2022)
<a href="https://arxiv.org/abs/2202.12780">arxiv:2202.12780</a>.</p>
</dd>
</dl>
</details>
            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/plots.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot_bias</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">feature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">functional</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">n_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">bin_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;quantile&quot;</span><span class="p">,</span>
    <span class="n">confidence_level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Plot model bias conditional on a feature.</span>

<span class="sd">    This plots the generalised bias (residuals), i.e. the values of the canonical</span>
<span class="sd">    identification function, versus a feature. This is a good way to assess whether</span>
<span class="sd">    a model is conditionally calibrated or not. Well calibrated models have bias terms</span>
<span class="sd">    around zero.</span>
<span class="sd">    See [Notes](#notes) for further details.</span>

<span class="sd">    For numerical features, NaN are treated as Null values. Null values are always</span>
<span class="sd">    plotted as rightmost value on the x-axis and marked with a diamond instead of a</span>
<span class="sd">    dot.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs) or (n_obs, n_models)</span>
<span class="sd">        Predicted values, e.g. for the conditional expectation of the response,</span>
<span class="sd">        `E(Y|X)`.</span>
<span class="sd">    feature : array-like of shape (n_obs) or None</span>
<span class="sd">        Some feature column.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights. If given, the bias is calculated as weighted average of the</span>
<span class="sd">        identification function with these weights.</span>
<span class="sd">        Note that the standard errors and p-values in the output are based on the</span>
<span class="sd">        assumption that the variance of the bias is inverse proportional to the</span>
<span class="sd">        weights. See the Notes section for details.</span>
<span class="sd">    functional : str</span>
<span class="sd">        The functional that is induced by the identification function `V`. Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile or quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt;= level &lt;= 1`.</span>
<span class="sd">        `level=0.5` and `functional=&quot;expectile&quot;` gives the mean.</span>
<span class="sd">        `level=0.5` and `functional=&quot;quantile&quot;` gives the median.</span>
<span class="sd">    n_bins : int</span>
<span class="sd">        The number of bins for numerical features and the maximal number of (most</span>
<span class="sd">        frequent) categories shown for categorical features. Due to ties, the effective</span>
<span class="sd">        number of bins might be smaller than `n_bins`. Null values are always included</span>
<span class="sd">        in the output, accounting for one bin. NaN values are treated as null values.</span>
<span class="sd">    bin_method : str</span>
<span class="sd">        The method to use for finding bin edges (boundaries). Options are:</span>

<span class="sd">        - &quot;quantile&quot;</span>
<span class="sd">        - &quot;uniform&quot;</span>
<span class="sd">    confidence_level : float</span>
<span class="sd">        Confidence level for error bars. If 0, no error bars are plotted. Value must</span>
<span class="sd">        fulfil `0 &lt;= confidence_level &lt; 1`.</span>
<span class="sd">    ax : matplotlib.axes.Axes or plotly Figure</span>
<span class="sd">        Axes object to draw the plot onto, otherwise uses the current Axes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ax :</span>
<span class="sd">        Either the matplotlib axes or the plotly figure. This is configurable by</span>
<span class="sd">        setting the `plot_backend` via</span>
<span class="sd">        [`model_diagnostics.set_config`][model_diagnostics.set_config] or</span>
<span class="sd">        [`model_diagnostics.config_context`][model_diagnostics.config_context].</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    [](){#notes}</span>
<span class="sd">    A model \(m(X)\) is conditionally calibrated iff \(E(V(m(X), Y))=0\) a.s. The</span>
<span class="sd">    empirical version, given some data, reads \(\frac{1}{n}\sum_i V(m(x_i), y_i)\).</span>
<span class="sd">    See `[FLM2022]`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `FLM2022`</span>

<span class="sd">    :   T. Fissler, C. Lorentzen, and M. Mayer.</span>
<span class="sd">        &quot;Model Comparison and Calibration Assessment&quot;. (2022)</span>
<span class="sd">        [arxiv:2202.12780](https://arxiv.org/abs/2202.12780).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">confidence_level</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Argument confidence_level must fulfil 0 &lt;= level &lt; 1, got &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">confidence_level</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="n">with_errorbars</span> <span class="o">=</span> <span class="n">confidence_level</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">()[</span><span class="s2">&quot;plot_backend&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>

            <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">):</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="s2">&quot;matplotlib&quot;</span>
    <span class="k">elif</span> <span class="n">is_plotly_figure</span><span class="p">(</span><span class="n">ax</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>

        <span class="n">plot_backend</span> <span class="o">=</span> <span class="s2">&quot;plotly&quot;</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;The ax argument must be None, a matplotlib Axes or a plotly Figure, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">compute_bias</span><span class="p">(</span>
        <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
        <span class="n">feature</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span>
        <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
        <span class="n">functional</span><span class="o">=</span><span class="n">functional</span><span class="p">,</span>
        <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
        <span class="n">bin_method</span><span class="o">=</span><span class="n">bin_method</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fill_nan</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">with_errorbars</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;Some values of &#39;bias_stderr&#39; are null. Therefore no error bars are &quot;</span>
            <span class="s2">&quot;shown for that y_pred/model, despite the fact that confidence_level&gt;0 &quot;</span>
            <span class="s2">&quot;was set to True.&quot;</span>
        <span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;model_&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">col_model</span> <span class="o">=</span> <span class="s2">&quot;model_&quot;</span>
    <span class="k">elif</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">col_model</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">col_model</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">feature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We treat the predictions from different models as a feature.</span>
        <span class="n">feature_name</span> <span class="o">=</span> <span class="n">col_model</span>
        <span class="n">feature_has_nulls</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">feature_name</span> <span class="o">=</span> <span class="n">array_name</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;feature&quot;</span><span class="p">)</span>
        <span class="n">feature_has_nulls</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="n">is_categorical</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">is_string</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">feature_dtype</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">if</span> <span class="n">feature_dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="n">pl</span><span class="o">.</span><span class="n">Categorical</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">Enum</span><span class="p">]:</span>
        <span class="n">is_categorical</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">feature_dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="n">pl</span><span class="o">.</span><span class="n">Utf8</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">Object</span><span class="p">]:</span>
        <span class="n">is_string</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">n_x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">n_unique</span><span class="p">()</span>

    <span class="c1"># horizontal line at y=0</span>
    <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dotted&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">add_hline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="s2">&quot;dash&quot;</span><span class="p">:</span> <span class="s2">&quot;dot&quot;</span><span class="p">},</span> <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># bias plot</span>
    <span class="k">if</span> <span class="n">feature</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">col_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pred_names</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># pred_names = df[col_model].unique() this automatically sorts</span>
        <span class="n">pred_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">n_models</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">)</span>
    <span class="n">with_label</span> <span class="o">=</span> <span class="n">feature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">n_models</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">feature_has_nulls</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">is_string</span> <span class="ow">or</span> <span class="n">is_categorical</span><span class="p">)</span> <span class="ow">and</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
        <span class="c1"># We want the Null values at the end and therefore sort again.</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nulls_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pred_names</span><span class="p">):</span>
        <span class="n">filter_condition</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">col_model</span><span class="p">)</span> <span class="o">==</span> <span class="n">m</span>
        <span class="n">df_i</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">filter_condition</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">m</span> <span class="k">if</span> <span class="n">with_label</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">df_i</span><span class="p">[</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">with_errorbars_i</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">with_errorbars_i</span> <span class="o">=</span> <span class="n">with_errorbars</span>

        <span class="k">if</span> <span class="n">with_errorbars_i</span><span class="p">:</span>
            <span class="c1"># We scale bias_stderr by the corresponding value of the t-distribution</span>
            <span class="c1"># to get our desired confidence level.</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">df_i</span><span class="p">[</span><span class="s2">&quot;bias_count&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">conf_level_fct</span> <span class="o">=</span> <span class="n">special</span><span class="o">.</span><span class="n">stdtrit</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># degrees of freedom, if n=0 =&gt; bias_stderr=0.</span>
                <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">confidence_level</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">df_i</span> <span class="o">=</span> <span class="n">df_i</span><span class="o">.</span><span class="n">with_columns</span><span class="p">(</span>
                <span class="p">[(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="n">conf_level_fct</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">)]</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">is_string</span> <span class="ow">or</span> <span class="n">is_categorical</span><span class="p">:</span>
            <span class="n">df_ii</span> <span class="o">=</span> <span class="n">df_i</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_not_null</span><span class="p">())</span>
            <span class="c1"># We x-shift a little for a better visual.</span>
            <span class="n">span</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_x</span> <span class="o">/</span> <span class="n">n_models</span>  <span class="c1"># length for one cat value and one model</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_x</span> <span class="o">-</span> <span class="n">feature_has_nulls</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">n_models</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="n">n_models</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">span</span> <span class="o">*</span> <span class="mf">0.5</span>
            <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span>
                    <span class="n">x</span><span class="p">,</span>
                    <span class="n">df_ii</span><span class="p">[</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">],</span>
                    <span class="n">yerr</span><span class="o">=</span><span class="n">df_ii</span><span class="p">[</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">with_errorbars_i</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
                    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">,</span>
                    <span class="n">capsize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">df_ii</span><span class="p">[</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">],</span>
                    <span class="n">error_y</span><span class="o">=</span><span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;data&quot;</span><span class="p">,</span>  <span class="c1"># value of error bar given in data coordinates</span>
                        <span class="s2">&quot;array&quot;</span><span class="p">:</span> <span class="n">df_ii</span><span class="p">[</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">with_errorbars_i</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
                        <span class="s2">&quot;visible&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">)},</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">with_errorbars_i</span><span class="p">:</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="n">df_i</span><span class="p">[</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_i</span><span class="p">[</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">]</span>
                <span class="n">upper</span> <span class="o">=</span> <span class="n">df_i</span><span class="p">[</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df_i</span><span class="p">[</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
                    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
                        <span class="n">df_i</span><span class="p">[</span><span class="n">feature_name</span><span class="p">],</span>
                        <span class="n">lower</span><span class="p">,</span>
                        <span class="n">upper</span><span class="p">,</span>
                        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># plotly has no equivalent of fill_between and needs a bit more</span>
                    <span class="c1"># coding</span>
                    <span class="n">color</span> <span class="o">=</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_i</span><span class="p">[</span><span class="n">feature_name</span><span class="p">],</span> <span class="n">df_i</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">]]),</span>
                        <span class="n">y</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]]),</span>
                        <span class="n">fill</span><span class="o">=</span><span class="s2">&quot;toself&quot;</span><span class="p">,</span>
                        <span class="n">fillcolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                        <span class="n">hoverinfo</span><span class="o">=</span><span class="s2">&quot;skip&quot;</span><span class="p">,</span>
                        <span class="n">line</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">color</span><span class="p">},</span>
                        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
                        <span class="n">opacity</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                        <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                    <span class="n">df_i</span><span class="p">[</span><span class="n">feature_name</span><span class="p">],</span>
                    <span class="n">df_i</span><span class="p">[</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">],</span>
                    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;solid&quot;</span><span class="p">,</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">df_i</span><span class="p">[</span><span class="n">feature_name</span><span class="p">],</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">df_i</span><span class="p">[</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">],</span>
                    <span class="n">marker_symbol</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines+markers&quot;</span><span class="p">,</span>
                    <span class="n">line</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">)},</span>
                    <span class="n">name</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
            <span class="c1"># Null values are plotted as diamonds as rightmost point.</span>
            <span class="n">df_i_null</span> <span class="o">=</span> <span class="n">df_i</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_null</span><span class="p">())</span>

            <span class="k">if</span> <span class="n">is_string</span> <span class="ow">or</span> <span class="n">is_categorical</span><span class="p">:</span>
                <span class="n">x_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">n_x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x_min</span> <span class="o">=</span> <span class="n">df_i</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
                <span class="n">x_max</span> <span class="o">=</span> <span class="n">df_i</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">n_x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># df_i[feature_name] is the null value.</span>
                    <span class="n">x_null</span><span class="p">,</span> <span class="n">span</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span>
                <span class="k">elif</span> <span class="n">n_x</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">x_null</span><span class="p">,</span> <span class="n">span</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_max</span><span class="p">]),</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x_max</span> <span class="o">/</span> <span class="n">n_models</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x_max</span> <span class="o">+</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_x</span><span class="p">])</span>
                    <span class="n">span</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_null</span> <span class="o">-</span> <span class="n">x_max</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_models</span>

            <span class="k">if</span> <span class="n">n_models</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x_null</span> <span class="o">=</span> <span class="n">x_null</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="n">n_models</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">span</span> <span class="o">*</span> <span class="mf">0.5</span>

            <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
                <span class="n">color</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_lines</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get_color</span><span class="p">()</span>  <span class="c1"># previous line color</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span>
                    <span class="n">x_null</span><span class="p">,</span>
                    <span class="n">df_i_null</span><span class="p">[</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">],</span>
                    <span class="n">yerr</span><span class="o">=</span><span class="n">df_i_null</span><span class="p">[</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">with_errorbars_i</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span>
                    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">,</span>
                    <span class="n">capsize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">x_null</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">df_i_null</span><span class="p">[</span><span class="s2">&quot;bias_mean&quot;</span><span class="p">],</span>
                    <span class="n">error_y</span><span class="o">=</span><span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;data&quot;</span><span class="p">,</span>  <span class="c1"># value of error bar given in data coordinates</span>
                        <span class="s2">&quot;array&quot;</span><span class="p">:</span> <span class="n">df_i_null</span><span class="p">[</span><span class="s2">&quot;bias_stderr&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">with_errorbars_i</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
                        <span class="s2">&quot;visible&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                    <span class="p">},</span>
                    <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="s2">&quot;symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;diamond&quot;</span><span class="p">},</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
                    <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">is_string</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
            <span class="c1"># Without cast to pl.Uft8, the following error might occur:</span>
            <span class="c1"># exceptions.ComputeError: cannot combine categorical under a global string</span>
            <span class="c1"># cache with a non cached categorical</span>
            <span class="n">tick_labels</span> <span class="o">=</span> <span class="n">df_i</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">Utf8</span><span class="p">)</span><span class="o">.</span><span class="n">fill_null</span><span class="p">(</span><span class="s2">&quot;Null&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tick_labels</span> <span class="o">=</span> <span class="n">df_i</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span>
        <span class="n">x_label</span> <span class="o">=</span> <span class="n">feature_name</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_x</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">tick_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
                <span class="n">xaxis</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;tickmode&quot;</span><span class="p">:</span> <span class="s2">&quot;array&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;tickvals&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_x</span><span class="p">),</span>
                    <span class="s2">&quot;ticktext&quot;</span><span class="p">:</span> <span class="n">tick_labels</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x_label</span> <span class="o">=</span> <span class="s2">&quot;binned &quot;</span> <span class="o">+</span> <span class="n">feature_name</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_label</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

    <span class="k">if</span> <span class="n">feature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Bias Plot&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model_name</span> <span class="o">=</span> <span class="n">array_name</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="c1"># test for empty string &quot;&quot;</span>
        <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Bias Plot&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">model_name</span> <span class="k">else</span> <span class="s2">&quot;Bias Plot &quot;</span> <span class="o">+</span> <span class="n">model_name</span>

    <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="n">x_label</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">xaxis_title</span><span class="o">=</span><span class="n">x_label</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">with_label</span> <span class="ow">and</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
            <span class="c1"># Add legend entry for diamonds as Null values.</span>
            <span class="c1"># Unfortunately, the Null value legend entry often appears first, but we</span>
            <span class="c1"># want it at the end.</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Null values&quot;</span><span class="p">)</span>
            <span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_legend_handles_labels</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;Null values&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;Null values&quot;</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;Null values&quot;</span><span class="p">)</span>
                <span class="c1"># i can&#39;t be the last index</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span> <span class="o">+</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                <span class="n">handles</span> <span class="o">=</span> <span class="n">handles</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">handles</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span> <span class="o">+</span> <span class="p">[</span><span class="n">handles</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="n">handles</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">with_label</span> <span class="ow">and</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span>
            <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Null values&quot;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;grey&quot;</span><span class="p">,</span> <span class="s2">&quot;symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;diamond&quot;</span><span class="p">},</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.plot_marginal" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_marginal</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">feature_name</span><span class="p">,</span> <span class="n">predict_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bin_method</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">n_max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.plot_marginal" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Plot marginal observed and predicted conditional on a feature.</p>
<p>This plot provides a means to inspect a model per feature.
The average of observed and predicted are plotted as well as a histogram of the
feature.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values, e.g. for the conditional expectation of the response,
<code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>X</code></td>
            <td>
                  <code>array-like of shape (n_obs, n_features)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dataframe or array of features to be passed to the model predict function.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature_name</code></td>
            <td>
                  <code>str or int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Column name (str) or index (int) of feature in <code>X</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>predict_function</code></td>
            <td>
                  <code>callable or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A callable to get prediction, i.e. <code>predict_function(X)</code>. Used to compute
partial dependence. If <code>None</code>, partial dependence is omitted.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights. If given, the bias is calculated as weighted average of the
identification function with these weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_bins</code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of bins for numerical features and the maximal number of (most
frequent) categories shown for categorical features. Due to ties, the effective
number of bins might be smaller than <code>n_bins</code>. Null values are always included
in the output, accounting for one bin. NaN values are treated as null values.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>bin_method</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The method to use for finding bin edges (boundaries). Options are:</p>
<ul>
<li>"quantile"</li>
<li>"uniform"</li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;uniform&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_max</code></td>
            <td>
                  <code>int or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Used only for partial dependence computation. The number of rows to subsample
from X. This speeds up computation, in particular for slow predict functions.</p>
              </div>
            </td>
            <td>
                  <code>1000</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>rng</code></td>
            <td>
                  <code>(<span title="numpy.random.Generator">Generator</span>, int or None)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Used only for partial dependence computation. The random number generator used
for subsampling of <code>n_max</code> rows. The input is internally wrapped by
<code>np.random.default_rng(rng)</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ax</code></td>
            <td>
                  <code>matplotlib.axes.Axes or plotly Figure</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axes object to draw the plot onto, otherwise uses the current Axes.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ax</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either the matplotlib axes or the plotly figure. This is configurable by
setting the <code>plot_backend</code> via
<a class="autorefs autorefs-internal" href="../#model_diagnostics.set_config"><code>model_diagnostics.set_config</code></a> or
<a class="autorefs autorefs-internal" href="../#model_diagnostics.config_context"><code>model_diagnostics.config_context</code></a>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/plots.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot_marginal</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">feature_name</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">predict_function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">n_bins</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">bin_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
    <span class="n">n_max</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="n">rng</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Plot marginal observed and predicted conditional on a feature.</span>

<span class="sd">    This plot provides a means to inspect a model per feature.</span>
<span class="sd">    The average of observed and predicted are plotted as well as a histogram of the</span>
<span class="sd">    feature.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values, e.g. for the conditional expectation of the response,</span>
<span class="sd">        `E(Y|X)`.</span>
<span class="sd">    X : array-like of shape (n_obs, n_features)</span>
<span class="sd">        The dataframe or array of features to be passed to the model predict function.</span>
<span class="sd">    feature_name : str or int</span>
<span class="sd">        Column name (str) or index (int) of feature in `X`.</span>
<span class="sd">    predict_function : callable or None</span>
<span class="sd">        A callable to get prediction, i.e. `predict_function(X)`. Used to compute</span>
<span class="sd">        partial dependence. If `None`, partial dependence is omitted.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights. If given, the bias is calculated as weighted average of the</span>
<span class="sd">        identification function with these weights.</span>
<span class="sd">    n_bins : int</span>
<span class="sd">        The number of bins for numerical features and the maximal number of (most</span>
<span class="sd">        frequent) categories shown for categorical features. Due to ties, the effective</span>
<span class="sd">        number of bins might be smaller than `n_bins`. Null values are always included</span>
<span class="sd">        in the output, accounting for one bin. NaN values are treated as null values.</span>
<span class="sd">    bin_method : str</span>
<span class="sd">        The method to use for finding bin edges (boundaries). Options are:</span>

<span class="sd">        - &quot;quantile&quot;</span>
<span class="sd">        - &quot;uniform&quot;</span>
<span class="sd">    n_max : int or None</span>
<span class="sd">        Used only for partial dependence computation. The number of rows to subsample</span>
<span class="sd">        from X. This speeds up computation, in particular for slow predict functions.</span>
<span class="sd">    rng : np.random.Generator, int or None</span>
<span class="sd">        Used only for partial dependence computation. The random number generator used</span>
<span class="sd">        for subsampling of `n_max` rows. The input is internally wrapped by</span>
<span class="sd">        `np.random.default_rng(rng)`.</span>
<span class="sd">    ax : matplotlib.axes.Axes or plotly Figure</span>
<span class="sd">        Axes object to draw the plot onto, otherwise uses the current Axes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ax :</span>
<span class="sd">        Either the matplotlib axes or the plotly figure. This is configurable by</span>
<span class="sd">        setting the `plot_backend` via</span>
<span class="sd">        [`model_diagnostics.set_config`][model_diagnostics.set_config] or</span>
<span class="sd">        [`model_diagnostics.config_context`][model_diagnostics.config_context].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">()[</span><span class="s2">&quot;plot_backend&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">plotly.subplots</span> <span class="kn">import</span> <span class="n">make_subplots</span>

            <span class="c1"># fig = ax = go.Figure()</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">make_subplots</span><span class="p">(</span><span class="n">specs</span><span class="o">=</span><span class="p">[[{</span><span class="s2">&quot;secondary_y&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}]])</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">):</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="s2">&quot;matplotlib&quot;</span>
    <span class="k">elif</span> <span class="n">is_plotly_figure</span><span class="p">(</span><span class="n">ax</span><span class="p">):</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="s2">&quot;plotly&quot;</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span>
        <span class="c1"># Take care to mimick make_subplots for secondary y axis.</span>
        <span class="c1"># The following code is by comparing</span>
        <span class="c1">#   make_subplots(specs=[[{&quot;secondary_y&quot;: True}]])</span>
        <span class="c1"># vs</span>
        <span class="c1">#   go.Figure()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">fig</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span> <span class="s2">&quot;yaxis2&quot;</span><span class="p">):</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
                <span class="n">xaxis</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;anchor&quot;</span><span class="p">:</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;domain&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.94</span><span class="p">]},</span>
                <span class="n">yaxis</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;anchor&quot;</span><span class="p">:</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;domain&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]},</span>
                <span class="n">yaxis2</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;anchor&quot;</span><span class="p">:</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;overlaying&quot;</span><span class="p">:</span> <span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="s2">&quot;side&quot;</span><span class="p">:</span> <span class="s2">&quot;right&quot;</span><span class="p">},</span>
            <span class="p">)</span>
            <span class="n">SubplotRef</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span>  <span class="c1"># noqa: PYI024</span>
                <span class="s2">&quot;SubplotRef&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;subplot_type&quot;</span><span class="p">,</span> <span class="s2">&quot;layout_keys&quot;</span><span class="p">,</span> <span class="s2">&quot;trace_kwargs&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">_grid_ref</span> <span class="o">=</span> <span class="p">[</span>  <span class="c1"># noqa: SLF001</span>
                <span class="p">[</span>
                    <span class="p">(</span>
                        <span class="n">SubplotRef</span><span class="p">(</span>
                            <span class="n">subplot_type</span><span class="o">=</span><span class="s2">&quot;xy&quot;</span><span class="p">,</span>
                            <span class="n">layout_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;xaxis&quot;</span><span class="p">,</span> <span class="s2">&quot;yaxis&quot;</span><span class="p">),</span>
                            <span class="n">trace_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;xaxis&quot;</span><span class="p">:</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;yaxis&quot;</span><span class="p">:</span> <span class="s2">&quot;y&quot;</span><span class="p">},</span>
                        <span class="p">),</span>
                        <span class="n">SubplotRef</span><span class="p">(</span>
                            <span class="n">subplot_type</span><span class="o">=</span><span class="s2">&quot;xy&quot;</span><span class="p">,</span>
                            <span class="n">layout_keys</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;xaxis&quot;</span><span class="p">,</span> <span class="s2">&quot;yaxis2&quot;</span><span class="p">),</span>
                            <span class="n">trace_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;xaxis&quot;</span><span class="p">:</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;yaxis&quot;</span><span class="p">:</span> <span class="s2">&quot;y2&quot;</span><span class="p">},</span>
                        <span class="p">),</span>
                    <span class="p">)</span>
                <span class="p">]</span>
            <span class="p">]</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">_grid_str</span> <span class="o">=</span> <span class="s2">&quot;This is the format of your plot grid:</span><span class="se">\n</span><span class="s2">[ (1,1) x,y,y2 ]</span><span class="se">\n</span><span class="s2">&quot;</span>  <span class="c1"># noqa: SLF001</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;The ax argument must be None, a matplotlib Axes or a plotly Figure, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="c1"># estimator = getattr(predict_callable, &quot;__self__&quot;, None)</span>
    <span class="n">n_pred</span> <span class="o">=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Parameter y_pred has shape (n_obs, </span><span class="si">{</span><span class="n">n_pred</span><span class="si">}</span><span class="s2">), but only &quot;</span>
            <span class="s2">&quot;(n_obs) and (n_obs, 1) are allowd.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">compute_marginal</span><span class="p">(</span>
        <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
        <span class="n">feature_name</span><span class="o">=</span><span class="n">feature_name</span><span class="p">,</span>
        <span class="n">predict_function</span><span class="o">=</span><span class="n">predict_function</span><span class="p">,</span>
        <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
        <span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span>
        <span class="n">bin_method</span><span class="o">=</span><span class="n">bin_method</span><span class="p">,</span>
        <span class="n">n_max</span><span class="o">=</span><span class="n">n_max</span><span class="p">,</span>
        <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">feature_name</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">feature_has_nulls</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">n_bins_eff</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">feature_has_nulls</span>
    <span class="c1"># If df contains the columns &quot;bin_edges&quot;, it&#39;s a numerical feature.</span>
    <span class="n">is_categorical</span> <span class="o">=</span> <span class="s2">&quot;bin_edges&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span>

    <span class="n">n_x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">n_unique</span><span class="p">()</span>

    <span class="c1"># marginal plot</span>
    <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">and</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
        <span class="c1"># We want the Null values at the end and therefore sort again.</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">feature_name</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nulls_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df_no_nulls</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_not_null</span><span class="p">())</span>

    <span class="c1"># Numerical columns are sometimes better treated as categorical.</span>
    <span class="n">num_as_cat</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_categorical</span><span class="p">:</span>
        <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">df_no_nulls</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="s2">&quot;bin_edges&quot;</span><span class="p">)</span>
        <span class="n">num_as_cat</span> <span class="o">=</span> <span class="p">(</span>
            <span class="c1"># left bin edge = right bin edge</span>
            <span class="p">(</span><span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">first</span><span class="p">()</span> <span class="o">==</span> <span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">())</span>
            <span class="c1"># feature == left bin edge</span>
            <span class="o">|</span> <span class="p">(</span><span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">first</span><span class="p">()</span> <span class="o">==</span> <span class="n">df_no_nulls</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="n">feature_name</span><span class="p">))</span>
            <span class="c1"># feature == right bin edge</span>
            <span class="o">|</span> <span class="p">(</span><span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">()</span> <span class="o">==</span> <span class="n">df_no_nulls</span><span class="o">.</span><span class="n">get_column</span><span class="p">(</span><span class="n">feature_name</span><span class="p">))</span>
            <span class="c1"># standard deviation of feature in bin == 0</span>
            <span class="o">|</span> <span class="p">(</span><span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

    <span class="c1"># First the histogram of weights on secondary y-axis.</span>
    <span class="c1"># Other graph elements should appear on top of it. For plotly, we therefore need to</span>
    <span class="c1"># plot the histogram on the primary y-axis and put primary to the right and</span>
    <span class="c1"># secondary to the left. All other plotly graphs are put on the secondary yaxis.</span>
    <span class="c1">#</span>
    <span class="c1"># We x-shift a little for a better visual.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_x</span> <span class="o">-</span> <span class="n">feature_has_nulls</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_categorical</span>
        <span class="k">else</span> <span class="n">df_no_nulls</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">num_as_cat</span><span class="p">:</span>
            <span class="n">ax2</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                <span class="n">height</span><span class="o">=</span><span class="n">df_no_nulls</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgrey&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># We can&#39;t use</span>
            <span class="c1">#   ax2.hist(</span>
            <span class="c1">#       x=df_no_nulls[feature_name],</span>
            <span class="c1">#       weights=df_no_nulls[&quot;weights&quot;] / df[&quot;weights&quot;].sum(),</span>
            <span class="c1">#       bins=np.r_[bin_edges[0][0], bin_edges.arr.last()],  # n_bins_eff,</span>
            <span class="c1">#       color=&quot;lightgrey&quot;,</span>
            <span class="c1">#       edgecolor=&quot;grey&quot;,</span>
            <span class="c1">#       rwidth=0.8 if n_bins_eff &lt;= 2 else None,</span>
            <span class="c1">#   )</span>
            <span class="c1"># because we might have empty bins.</span>
            <span class="n">ax2</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">()</span> <span class="o">+</span> <span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">first</span><span class="p">()),</span>
                <span class="n">height</span><span class="o">=</span><span class="n">df_no_nulls</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
                <span class="n">width</span><span class="o">=</span><span class="p">(</span><span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">()</span> <span class="o">-</span> <span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">first</span><span class="p">())</span>
                <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">n_bins_eff</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="mf">0.8</span><span class="p">),</span>
                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgrey&quot;</span><span class="p">,</span>
                <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="c1"># https://stackoverflow.com/questions/30505616/how-to-arrange-plots-of-secondary-axis-to-be-below-plots-of-primary-axis-in-matp</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_zorder</span><span class="p">(</span><span class="n">ax2</span><span class="o">.</span><span class="n">get_zorder</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_frame_on</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_categorical</span> <span class="ow">or</span> <span class="n">num_as_cat</span><span class="p">:</span>
            <span class="c1"># fig.add_histogram(</span>
            <span class="c1">#     x=x, # df_no_nulls[feature_name],</span>
            <span class="c1">#     y=df_no_nulls[&quot;weights&quot;] / df[&quot;weights&quot;].sum(),</span>
            <span class="c1">#     histfunc=&quot;sum&quot;,</span>
            <span class="c1">#     marker={&quot;color&quot;: &quot;lightgrey&quot;},</span>
            <span class="c1">#     secondary_y=False,</span>
            <span class="c1">#     showlegend=False,</span>
            <span class="c1"># )</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">add_bar</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">df_no_nulls</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
                <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;lightgrey&quot;</span><span class="p">},</span>
                <span class="n">secondary_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">add_bar</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">()</span> <span class="o">+</span> <span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">first</span><span class="p">()),</span>
                <span class="n">y</span><span class="o">=</span><span class="n">df_no_nulls</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
                <span class="n">width</span><span class="o">=</span><span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">()</span> <span class="o">-</span> <span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">first</span><span class="p">(),</span>
                <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;lightgrey&quot;</span><span class="p">,</span> <span class="s2">&quot;line&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;width&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;grey&quot;</span><span class="p">}},</span>
                <span class="n">secondary_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">yaxis_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="n">yaxis2_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_bins_eff</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">bargap</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
        <span class="n">df_null</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span><span class="o">.</span><span class="n">is_null</span><span class="p">())</span>
        <span class="c1"># Null values are plotted as rightmost point at x_null.</span>
        <span class="k">if</span> <span class="n">is_categorical</span><span class="p">:</span>
            <span class="n">x_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">n_x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
            <span class="c1"># matplotlib default width = 0.8</span>
            <span class="n">width</span> <span class="o">=</span> <span class="mf">0.8</span> <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_min</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
            <span class="n">x_max</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">n_x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># df[feature_name] is the null value.</span>
                <span class="n">x_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">n_x</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">x_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_max</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x_null</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x_max</span> <span class="o">+</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_x</span><span class="p">])</span>
            <span class="n">width</span> <span class="o">=</span> <span class="n">x_null</span> <span class="o">-</span> <span class="n">bin_edges</span><span class="o">.</span><span class="n">arr</span><span class="o">.</span><span class="n">last</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">width</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">width</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">width</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_x</span> <span class="o">/</span> <span class="mf">2.0</span>

        <span class="c1"># Null value histogram</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax2</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">x_null</span><span class="p">,</span>
                <span class="n">height</span><span class="o">=</span><span class="n">df_null</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
                <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgrey&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">add_bar</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">x_null</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">df_null</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
                <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span>
                <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;lightgrey&quot;</span><span class="p">},</span>
                <span class="n">secondary_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="n">plot_items</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;y_obs_mean&quot;</span><span class="p">,</span> <span class="s2">&quot;y_pred_mean&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">predict_function</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plot_items</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;partial_dependence&quot;</span><span class="p">)</span>
    <span class="n">label_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;y_obs_mean&quot;</span><span class="p">:</span> <span class="s2">&quot;mean y_obs&quot;</span><span class="p">,</span>
        <span class="s2">&quot;y_pred_mean&quot;</span><span class="p">:</span> <span class="s2">&quot;mean y_pred&quot;</span><span class="p">,</span>
        <span class="s2">&quot;partial_dependence&quot;</span><span class="p">:</span> <span class="s2">&quot;partial dependence&quot;</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">plot_items</span><span class="p">):</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">label_dict</span><span class="p">[</span><span class="n">m</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">is_categorical</span><span class="p">:</span>
            <span class="c1"># We x-shift a little for a better visual.</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_x</span> <span class="o">-</span> <span class="n">feature_has_nulls</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                    <span class="n">x</span><span class="p">,</span>
                    <span class="n">df_no_nulls</span><span class="p">[</span><span class="n">m</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
                    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">df_no_nulls</span><span class="p">[</span><span class="n">m</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">)},</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                    <span class="n">secondary_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">],</span>
                <span class="n">df</span><span class="p">[</span><span class="n">m</span><span class="p">],</span>
                <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span> <span class="k">if</span> <span class="n">m</span> <span class="o">==</span> <span class="s2">&quot;partial_dependence&quot;</span> <span class="k">else</span> <span class="s2">&quot;solid&quot;</span><span class="p">,</span>
                <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">],</span>
                <span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">m</span><span class="p">],</span>
                <span class="n">marker_symbol</span><span class="o">=</span><span class="s2">&quot;circle&quot;</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines+markers&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
                    <span class="s2">&quot;dash&quot;</span><span class="p">:</span> <span class="s2">&quot;dash&quot;</span> <span class="k">if</span> <span class="n">m</span> <span class="o">==</span> <span class="s2">&quot;partial_dependence&quot;</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="n">name</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
                <span class="n">secondary_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
            <span class="c1"># Null values are plotted as diamonds as rightmost point.</span>
            <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
                <span class="n">color</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_lines</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get_color</span><span class="p">()</span>  <span class="c1"># previous line color</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                    <span class="n">x_null</span><span class="p">,</span>
                    <span class="n">df_null</span><span class="p">[</span><span class="n">m</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span>
                    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;None&quot;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">x_null</span><span class="p">,</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">df_null</span><span class="p">[</span><span class="n">m</span><span class="p">],</span>
                    <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="s2">&quot;symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;diamond&quot;</span><span class="p">},</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
                    <span class="n">secondary_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="n">is_categorical</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">null_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Without cast to pl.Uft8, the following error might occur:</span>
            <span class="c1"># exceptions.ComputeError: cannot combine categorical under a global string</span>
            <span class="c1"># cache with a non cached categorical</span>
            <span class="n">tick_labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">Utf8</span><span class="p">)</span><span class="o">.</span><span class="n">fill_null</span><span class="p">(</span><span class="s2">&quot;Null&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tick_labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_name</span><span class="p">]</span>
        <span class="n">x_label</span> <span class="o">=</span> <span class="n">feature_name</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_x</span><span class="p">),</span> <span class="n">labels</span><span class="o">=</span><span class="n">tick_labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span>
                <span class="n">xaxis</span><span class="o">=</span><span class="p">{</span>
                    <span class="s2">&quot;tickmode&quot;</span><span class="p">:</span> <span class="s2">&quot;array&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;tickvals&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_x</span><span class="p">),</span>
                    <span class="s2">&quot;ticktext&quot;</span><span class="p">:</span> <span class="n">tick_labels</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="n">feature_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x_label</span> <span class="o">=</span> <span class="s2">&quot;binned &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x_label</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

    <span class="n">model_name</span> <span class="o">=</span> <span class="n">array_name</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="c1"># test for empty string &quot;&quot;</span>
    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Marginal Plot&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">model_name</span> <span class="k">else</span> <span class="s2">&quot;Marginal Plot &quot;</span> <span class="o">+</span> <span class="n">model_name</span>

    <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="n">x_label</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">xaxis_title</span><span class="o">=</span><span class="n">x_label</span><span class="p">,</span> <span class="n">yaxis2_title</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">[</span><span class="s2">&quot;layout&quot;</span><span class="p">][</span><span class="s2">&quot;yaxis&quot;</span><span class="p">][</span><span class="s2">&quot;showgrid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
            <span class="c1"># Add legend entry for diamonds as Null values.</span>
            <span class="c1"># Unfortunately, the Null value legend entry often appears first, but we</span>
            <span class="c1"># want it at the end.</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Null values&quot;</span><span class="p">)</span>
            <span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_legend_handles_labels</span><span class="p">()</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;Null values&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;Null values&quot;</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
                <span class="n">i</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;Null values&quot;</span><span class="p">)</span>
                <span class="c1"># i can&#39;t be the last index</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span> <span class="o">+</span> <span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                <span class="n">handles</span> <span class="o">=</span> <span class="n">handles</span><span class="p">[:</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">handles</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]</span> <span class="o">+</span> <span class="p">[</span><span class="n">handles</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="n">handles</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">feature_has_nulls</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span>
            <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;markers&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Null values&quot;</span><span class="p">,</span>
            <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;size&quot;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;grey&quot;</span><span class="p">,</span> <span class="s2">&quot;symbol&quot;</span><span class="p">:</span> <span class="s2">&quot;diamond&quot;</span><span class="p">},</span>
            <span class="n">secondary_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.calibration.plot_reliability_diagram" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_reliability_diagram</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">diagram_type</span><span class="o">=</span><span class="s1">&#39;reliability&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.calibration.plot_reliability_diagram" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Plot a reliability diagram.</p>
<p>A reliability diagram or calibration curve assesses auto-calibration. It plots the
conditional expectation given the predictions <code>E(y_obs|y_pred)</code> (y-axis) vs the
predictions <code>y_pred</code> (x-axis).
The conditional expectation is estimated via isotonic regression (PAV algorithm)
of <code>y_obs</code> on <code>y_pred</code>.
See <a href="#model_diagnostics.calibration.plot_reliability_diagram--notes">Notes</a> for further details.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs) or (n_obs, n_models)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values, e.g. for the conditional expectation of the response,
<code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The functional that is induced by the identification function <code>V</code>. Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile or quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt;= level &lt;= 1</code>.
<code>level=0.5</code> and <code>functional="expectile"</code> gives the mean.
<code>level=0.5</code> and <code>functional="quantile"</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>n_bootstrap</code></td>
            <td>
                  <code>int or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If not <code>None</code>, then <code>scipy.stats.bootstrap</code> with <code>n_resamples=n_bootstrap</code>
is used to calculate confidence intervals at level <code>confidence_level</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>confidence_level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Confidence level for bootstrap uncertainty regions.</p>
              </div>
            </td>
            <td>
                  <code>0.9</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>diagram_type</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ul>
<li><code>"reliability"</code>: Plot a reliability diagram.</li>
<li><code>"bias"</code>: Plot roughly a 45 degree rotated reliability diagram. The resulting
  plot is similar to <code>plot_bias</code>, i.e. <code>y_pred - E(y_obs|y_pred)</code> vs <code>y_pred</code>.</li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;reliability&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ax</code></td>
            <td>
                  <code>matplotlib.axes.Axes or plotly Figure</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axes object to draw the plot onto, otherwise uses the current Axes.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ax</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either the matplotlib axes or the plotly figure. This is configurable by
setting the <code>plot_backend</code> via
<a class="autorefs autorefs-internal" href="../#model_diagnostics.set_config"><code>model_diagnostics.set_config</code></a> or
<a class="autorefs autorefs-internal" href="../#model_diagnostics.config_context"><code>model_diagnostics.config_context</code></a>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><a href="" id="notes"></a>
The expectation conditional on the predictions is <a href="" id="model_diagnostics.calibration.plot_reliability_diagram--notes"></a>
The expectation conditional on the predictions is <span class="arithmatex">\(E(Y|y_{pred})\)</span>. This object is
estimated by the pool-adjacent violator (PAV) algorithm, which has very desirable
properties:</p>
<div class="highlight"><pre><span></span><code>- It is non-parametric without any tuning parameter. Thus, the results are
  easily reproducible.
- Optimal selection of bins
- Statistical consistent estimator
</code></pre></div>
<p>For details, refer to <code>[Dimitriadis2021]</code>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[Dimitriadis2021]</code></dt>
<dd>
<p>T. Dimitriadis, T. Gneiting, and A. I. Jordan.
"Stable reliability diagrams for probabilistic classifiers".
In: Proceedings of the National Academy of Sciences 118.8 (2021), e2016191118.
<a href="https://doi.org/10.1073/pnas.2016191118">doi:10.1073/pnas.2016191118</a>.</p>
</dd>
</dl>
</details>
            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/calibration/plots.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot_reliability_diagram</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">functional</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">n_bootstrap</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">confidence_level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">diagram_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;reliability&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Plot a reliability diagram.</span>

<span class="sd">    A reliability diagram or calibration curve assesses auto-calibration. It plots the</span>
<span class="sd">    conditional expectation given the predictions `E(y_obs|y_pred)` (y-axis) vs the</span>
<span class="sd">    predictions `y_pred` (x-axis).</span>
<span class="sd">    The conditional expectation is estimated via isotonic regression (PAV algorithm)</span>
<span class="sd">    of `y_obs` on `y_pred`.</span>
<span class="sd">    See [Notes](#notes) for further details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs) or (n_obs, n_models)</span>
<span class="sd">        Predicted values, e.g. for the conditional expectation of the response,</span>
<span class="sd">        `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>
<span class="sd">    functional : str</span>
<span class="sd">        The functional that is induced by the identification function `V`. Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile or quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt;= level &lt;= 1`.</span>
<span class="sd">        `level=0.5` and `functional=&quot;expectile&quot;` gives the mean.</span>
<span class="sd">        `level=0.5` and `functional=&quot;quantile&quot;` gives the median.</span>
<span class="sd">    n_bootstrap : int or None</span>
<span class="sd">        If not `None`, then `scipy.stats.bootstrap` with `n_resamples=n_bootstrap`</span>
<span class="sd">        is used to calculate confidence intervals at level `confidence_level`.</span>
<span class="sd">    confidence_level : float</span>
<span class="sd">        Confidence level for bootstrap uncertainty regions.</span>
<span class="sd">    diagram_type: str</span>
<span class="sd">        - `&quot;reliability&quot;`: Plot a reliability diagram.</span>
<span class="sd">        - `&quot;bias&quot;`: Plot roughly a 45 degree rotated reliability diagram. The resulting</span>
<span class="sd">          plot is similar to `plot_bias`, i.e. `y_pred - E(y_obs|y_pred)` vs `y_pred`.</span>
<span class="sd">    ax : matplotlib.axes.Axes or plotly Figure</span>
<span class="sd">        Axes object to draw the plot onto, otherwise uses the current Axes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ax :</span>
<span class="sd">        Either the matplotlib axes or the plotly figure. This is configurable by</span>
<span class="sd">        setting the `plot_backend` via</span>
<span class="sd">        [`model_diagnostics.set_config`][model_diagnostics.set_config] or</span>
<span class="sd">        [`model_diagnostics.config_context`][model_diagnostics.config_context].</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    [](){#notes}</span>
<span class="sd">    The expectation conditional on the predictions is \(E(Y|y_{pred})\). This object is</span>
<span class="sd">    estimated by the pool-adjacent violator (PAV) algorithm, which has very desirable</span>
<span class="sd">    properties:</span>

<span class="sd">        - It is non-parametric without any tuning parameter. Thus, the results are</span>
<span class="sd">          easily reproducible.</span>
<span class="sd">        - Optimal selection of bins</span>
<span class="sd">        - Statistical consistent estimator</span>

<span class="sd">    For details, refer to `[Dimitriadis2021]`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[Dimitriadis2021]`</span>

<span class="sd">    :   T. Dimitriadis, T. Gneiting, and A. I. Jordan.</span>
<span class="sd">        &quot;Stable reliability diagrams for probabilistic classifiers&quot;.</span>
<span class="sd">        In: Proceedings of the National Academy of Sciences 118.8 (2021), e2016191118.</span>
<span class="sd">        [doi:10.1073/pnas.2016191118](https://doi.org/10.1073/pnas.2016191118).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">()[</span><span class="s2">&quot;plot_backend&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>

            <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">):</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="s2">&quot;matplotlib&quot;</span>
    <span class="k">elif</span> <span class="n">is_plotly_figure</span><span class="p">(</span><span class="n">ax</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>

        <span class="n">plot_backend</span> <span class="o">=</span> <span class="s2">&quot;plotly&quot;</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;The ax argument must be None, a matplotlib Axes or a plotly Figure, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">diagram_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;reliability&quot;</span><span class="p">,</span> <span class="s2">&quot;bias&quot;</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;Parameter diagram_type must be either &#39;reliability&#39;, &#39;bias&#39;, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="n">diagram_type</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">n_cols</span> <span class="o">:=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n_cols</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y_obs</span> <span class="o">=</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Array-like y_obs has more than 2 dimensions, y_obs.shape[1]=</span><span class="si">{</span><span class="n">n_cols</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">get_array_min_max</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">diagram_type</span> <span class="o">==</span> <span class="s2">&quot;reliability&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">],</span> <span class="p">[</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dotted&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">],</span>
                <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">],</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="s2">&quot;dash&quot;</span><span class="p">:</span> <span class="s2">&quot;dot&quot;</span><span class="p">},</span>
                <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="k">elif</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="c1"># horizontal line at y=0</span>

        <span class="c1"># The following plots in axis coordinates</span>
        <span class="c1"># ax.axhline(y=0, xmin=0, xmax=1, color=&quot;k&quot;, linestyle=&quot;dotted&quot;)</span>
        <span class="c1"># but we plot in data coordinates instead.</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="n">y_min</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="n">y_max</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dotted&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># horizontal line at y=0</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">add_hline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="s2">&quot;dash&quot;</span><span class="p">:</span> <span class="s2">&quot;dot&quot;</span><span class="p">},</span> <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_bootstrap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">iso_statistic</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_values</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
                <span class="n">iso_b</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">IsotonicRegression_skl</span><span class="p">(</span><span class="n">out_of_bounds</span><span class="o">=</span><span class="s2">&quot;clip&quot;</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">set_output</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">iso_b</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">iso_statistic</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_values</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
                <span class="n">iso_b</span> <span class="o">=</span> <span class="n">IsotonicRegression</span><span class="p">(</span><span class="n">functional</span><span class="o">=</span><span class="n">functional</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">iso_b</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span>

    <span class="n">n_pred</span> <span class="o">=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">pred_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">)):</span>
        <span class="n">y_pred_i</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">iso</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">IsotonicRegression_skl</span><span class="p">()</span>
                <span class="o">.</span><span class="n">set_output</span><span class="p">(</span><span class="n">transform</span><span class="o">=</span><span class="s2">&quot;default&quot;</span><span class="p">)</span>
                <span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y_pred_i</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">iso</span> <span class="o">=</span> <span class="n">IsotonicRegression</span><span class="p">(</span><span class="n">functional</span><span class="o">=</span><span class="n">functional</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">y_pred_i</span><span class="p">,</span> <span class="n">y_obs</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span>
            <span class="p">)</span>

        <span class="c1"># confidence intervals</span>
        <span class="k">if</span> <span class="n">n_bootstrap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">data</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred_i</span><span class="p">)</span> <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred_i</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

            <span class="n">boot</span> <span class="o">=</span> <span class="n">bootstrap</span><span class="p">(</span>
                <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                <span class="n">statistic</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">iso_statistic</span><span class="p">,</span> <span class="n">x_values</span><span class="o">=</span><span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span><span class="p">),</span>
                <span class="n">n_resamples</span><span class="o">=</span><span class="n">n_bootstrap</span><span class="p">,</span>
                <span class="n">paired</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">confidence_level</span><span class="o">=</span><span class="n">confidence_level</span><span class="p">,</span>
                <span class="c1"># Note: method=&quot;bca&quot; might result in</span>
                <span class="c1"># DegenerateDataWarning: The BCa confidence interval cannot be</span>
                <span class="c1"># calculated. This problem is known to occur when the distribution is</span>
                <span class="c1"># degenerate or the statistic is np.min.</span>
                <span class="n">method</span><span class="o">=</span><span class="s2">&quot;basic&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># We make the interval conservatively monotone increasing by applying</span>
            <span class="c1"># np.maximum.accumulate etc.</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="o">-</span><span class="n">boot</span><span class="o">.</span><span class="n">confidence_interval</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">boot</span><span class="o">.</span><span class="n">confidence_interval</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">diagram_type</span> <span class="o">==</span> <span class="s2">&quot;bias&quot;</span><span class="p">:</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span> <span class="o">-</span> <span class="n">lower</span>
                <span class="n">upper</span> <span class="o">=</span> <span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span> <span class="o">-</span> <span class="n">upper</span>
            <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># plotly has not equivalent of fill_between and needs a bit more coding</span>
                <span class="n">color</span> <span class="o">=</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                    <span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span><span class="p">,</span> <span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
                    <span class="n">y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span>
                    <span class="n">fill</span><span class="o">=</span><span class="s2">&quot;toself&quot;</span><span class="p">,</span>
                    <span class="n">fillcolor</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                    <span class="n">hoverinfo</span><span class="o">=</span><span class="s2">&quot;skip&quot;</span><span class="p">,</span>
                    <span class="n">line</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">color</span><span class="p">},</span>
                    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
                    <span class="n">opacity</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># reliability curve</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">pred_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="n">y_plot</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">iso</span><span class="o">.</span><span class="n">y_thresholds_</span>
            <span class="k">if</span> <span class="n">diagram_type</span> <span class="o">==</span> <span class="s2">&quot;reliability&quot;</span>
            <span class="k">else</span> <span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span> <span class="o">-</span> <span class="n">iso</span><span class="o">.</span><span class="n">y_thresholds_</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span><span class="p">,</span> <span class="n">y_plot</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">iso</span><span class="o">.</span><span class="n">X_thresholds_</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_plot</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">)},</span>
                <span class="n">name</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="n">xlabel_mapping</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="s2">&quot;E(Y|X)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="s2">&quot;median(Y|X)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;expectile&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">-expectile(Y|X)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;quantile&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">-quantile(Y|X)&quot;</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">ylabel_mapping</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="s2">&quot;E(Y|prediction)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;median&quot;</span><span class="p">:</span> <span class="s2">&quot;median(Y|prediction)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;expectile&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">-expectile(Y|prediction)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;quantile&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">-quantile(Y|prediction)&quot;</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;prediction for &quot;</span> <span class="o">+</span> <span class="n">xlabel_mapping</span><span class="p">[</span><span class="n">functional</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">diagram_type</span> <span class="o">==</span> <span class="s2">&quot;reliability&quot;</span><span class="p">:</span>
        <span class="n">ylabel</span> <span class="o">=</span> <span class="s2">&quot;estimated &quot;</span> <span class="o">+</span> <span class="n">ylabel_mapping</span><span class="p">[</span><span class="n">functional</span><span class="p">]</span>
        <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Reliability Diagram&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ylabel</span> <span class="o">=</span> <span class="s2">&quot;prediction - estimated &quot;</span> <span class="o">+</span> <span class="n">ylabel_mapping</span><span class="p">[</span><span class="n">functional</span><span class="p">]</span>
        <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Bias Reliability Diagram&quot;</span>

    <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">title</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">pred_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="n">ylabel</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">xaxis_title</span><span class="o">=</span><span class="n">xlabel</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; Christian Lorentzen 2022-present
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.sections", "navigation.expand", "navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "search.highlight"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>