
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Tools for diagnostics and assessment of (machine learning) models">
      
      
        <meta name="author" content="Christian Lorentzen">
      
      
        <link rel="canonical" href="https://lorentzenchr.github.io/model-diagnostics/reference/model_diagnostics/scoring/">
      
      
        <link rel="prev" href="../calibration/plots/">
      
      
        <link rel="next" href="plots/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.31">
    
    
      
        <title>scoring - Model Diagnostics</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model_diagnostics.scoring" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Model Diagnostics" class="md-header__button md-logo" aria-label="Model Diagnostics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Model Diagnostics
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              scoring
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/lorentzenchr/model-diagnostics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lorentzenchr/model-diagnostics
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../examples/regression_on_workers_compensation/" class="md-tabs__link">
          
  
  Examples

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../development/" class="md-tabs__link">
        
  
    
  
  Development

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="https://github.com/lorentzenchr/model-diagnostics/releases" class="md-tabs__link">
        
  
    
  
  Release Notes

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Model Diagnostics" class="md-nav__button md-logo" aria-label="Model Diagnostics" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Model Diagnostics
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/lorentzenchr/model-diagnostics" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    lorentzenchr/model-diagnostics
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Home
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/regression_on_workers_compensation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Regression on Workers' Compensation Dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/quantile_regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quantile Regression on Synthetic Data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../examples/classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Classification on Nursery Dataset
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    model_diagnostics
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1" id="__nav_3_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            model_diagnostics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_1_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../calibration/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    calibration
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            calibration
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../calibration/identification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    identification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../calibration/plots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    plots
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="./" class="md-nav__link md-nav__link--active">
              
  
  <span class="md-ellipsis">
    scoring
  </span>
  

            </a>
            
              
              <label class="md-nav__link md-nav__link--active" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            scoring
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    plots
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="scoring/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scoring
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../development/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Development
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/lorentzenchr/model-diagnostics/releases" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Release Notes
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model_diagnostics.scoring" class="md-nav__link">
    <span class="md-ellipsis">
      scoring
    </span>
  </a>
  
    <nav class="md-nav" aria-label="scoring">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.ElementaryScore" class="md-nav__link">
    <span class="md-ellipsis">
      ElementaryScore
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.GammaDeviance" class="md-nav__link">
    <span class="md-ellipsis">
      GammaDeviance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.HomogeneousExpectileScore" class="md-nav__link">
    <span class="md-ellipsis">
      HomogeneousExpectileScore
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.HomogeneousQuantileScore" class="md-nav__link">
    <span class="md-ellipsis">
      HomogeneousQuantileScore
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.LogLoss" class="md-nav__link">
    <span class="md-ellipsis">
      LogLoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.PinballLoss" class="md-nav__link">
    <span class="md-ellipsis">
      PinballLoss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.PoissonDeviance" class="md-nav__link">
    <span class="md-ellipsis">
      PoissonDeviance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.SquaredError" class="md-nav__link">
    <span class="md-ellipsis">
      SquaredError
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.decompose" class="md-nav__link">
    <span class="md-ellipsis">
      decompose
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model_diagnostics.scoring.plot_murphy_diagram" class="md-nav__link">
    <span class="md-ellipsis">
      plot_murphy_diagram
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>scoring</h1>

<div class="doc doc-object doc-module">



<h2 id="model_diagnostics.scoring" class="doc doc-heading">
            <code>scoring</code>


<a href="#model_diagnostics.scoring" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">



  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h3 id="model_diagnostics.scoring.ElementaryScore" class="doc doc-heading">
            <code>ElementaryScore</code>


<a href="#model_diagnostics.scoring.ElementaryScore" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


      <p>Elementary scoring function.</p>
<p>The smaller the better.</p>
<p>The elementary scoring function is consistent for the specified <code>functional</code> for
all values of <code>eta</code> and is the main ingredient for Murphy diagrams.
See <a href="#model_diagnostics.scoring.ElementaryScore--notes">Notes</a> for further details.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>eta</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Free parameter.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The functional that is induced by the identification function <code>V</code>. Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile of quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> and <code>functional="expectile"</code> gives the mean.
<code>level=0.5</code> and <code>functional="quantile"</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><a href="" id="notes"></a>
The elementary scoring or loss function is given by<a href="" id="model_diagnostics.scoring.ElementaryScore--notes"></a>
The elementary scoring or loss function is given by</p>
<div class="arithmatex">\[
S_\eta(y, z) = (\mathbf{1}\{\eta \le z\} - \mathbf{1}\{\eta \le y\})
V(y, \eta)
\]</div>
<p>with <a class="autorefs autorefs-internal" href="../calibration/#model_diagnostics.calibration.identification_function">identification functions</a>
<span class="arithmatex">\(V\)</span> for the given <code>functional</code> <span class="arithmatex">\(T\)</span> . If allows for the mixture or Choquet
representation</p>
<div class="arithmatex">\[
S(y, z) = \int S_\eta(y, z) \,dH(\eta)
\]</div>
<p>for some locally finite measure <span class="arithmatex">\(H\)</span>. It follows that the scoring function <span class="arithmatex">\(S\)</span>
is consistent for <span class="arithmatex">\(T\)</span>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[Jordan2022]</code></dt>
<dd>
<p>A.I. Jordan, A. Mühlemann, J.F. Ziegel.
"Characterizing the optimal solutions to the isotonic regression problem for
identifiable functionals". (2022)
<a href="https://doi.org/10.1007/s10463-021-00808-0">doi:10.1007/s10463-021-00808-0</a></p>
</dd>
<dt><code>[GneitingResin2022]</code></dt>
<dd>
<p>T. Gneiting, J. Resin.
"Regression Diagnostics meets Forecast Evaluation: Conditional Calibration,
Reliability Diagrams, and Coefficient of Determination".
<a href="https://arxiv.org/abs/2108.03210">arxiv:2108.03210</a></p>
</dd>
</dl>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">el_score</span> <span class="o">=</span> <span class="n">ElementaryScore</span><span class="p">(</span><span class="n">eta</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">el_score</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">0.5</span>
</code></pre></div>

              <details class="quote">
                <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ElementaryScore</span><span class="p">(</span><span class="n">_BaseScoringFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Elementary scoring function.</span>

<span class="sd">    The smaller the better.</span>

<span class="sd">    The elementary scoring function is consistent for the specified `functional` for</span>
<span class="sd">    all values of `eta` and is the main ingredient for Murphy diagrams.</span>
<span class="sd">    See [Notes](#notes) for further details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    eta : float</span>
<span class="sd">        Free parameter.</span>
<span class="sd">    functional : str</span>
<span class="sd">        The functional that is induced by the identification function `V`. Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile of quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` and `functional=&quot;expectile&quot;` gives the mean.</span>
<span class="sd">        `level=0.5` and `functional=&quot;quantile&quot;` gives the median.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    [](){#notes}</span>
<span class="sd">    The elementary scoring or loss function is given by</span>

<span class="sd">    \[</span>
<span class="sd">    S_\eta(y, z) = (\mathbf{1}\{\eta \le z\} - \mathbf{1}\{\eta \le y\})</span>
<span class="sd">    V(y, \eta)</span>
<span class="sd">    \]</span>

<span class="sd">    with [identification functions]</span>
<span class="sd">    [model_diagnostics.calibration.identification_function]</span>
<span class="sd">    \(V\) for the given `functional` \(T\) . If allows for the mixture or Choquet</span>
<span class="sd">    representation</span>

<span class="sd">    \[</span>
<span class="sd">    S(y, z) = \int S_\eta(y, z) \,dH(\eta)</span>
<span class="sd">    \]</span>

<span class="sd">    for some locally finite measure \(H\). It follows that the scoring function \(S\)</span>
<span class="sd">    is consistent for \(T\).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[Jordan2022]`</span>

<span class="sd">    :   A.I. Jordan, A. Mühlemann, J.F. Ziegel.</span>
<span class="sd">        &quot;Characterizing the optimal solutions to the isotonic regression problem for</span>
<span class="sd">        identifiable functionals&quot;. (2022)</span>
<span class="sd">        [doi:10.1007/s10463-021-00808-0](https://doi.org/10.1007/s10463-021-00808-0)</span>

<span class="sd">    `[GneitingResin2022]`</span>

<span class="sd">    :   T. Gneiting, J. Resin.</span>
<span class="sd">        &quot;Regression Diagnostics meets Forecast Evaluation: Conditional Calibration,</span>
<span class="sd">        Reliability Diagrams, and Coefficient of Determination&quot;.</span>
<span class="sd">        [arxiv:2108.03210](https://arxiv.org/abs/2108.03210)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; el_score = ElementaryScore(eta=2, functional=&quot;mean&quot;)</span>
<span class="sd">    &gt;&gt;&gt; el_score(y_obs=[1, 2, 2, 1], y_pred=[4, 1, 2, 3])  # doctest: +SKIP</span>
<span class="sd">    0.5</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># FIXME: numpy 2.0.0, doctest skip should not be necessary.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">eta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">functional</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">eta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_functional</span> <span class="o">=</span> <span class="n">functional</span>
        <span class="k">if</span> <span class="n">level</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">level</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Argument level must fulfil 0 &lt; level &lt; 1, got </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="n">level</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">functional</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_functional</span>

    <span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_obs : array-like of shape (n_obs)</span>
<span class="sd">            Observed values of the response variable.</span>
<span class="sd">        y_pred : array-like of shape (n_obs)</span>
<span class="sd">            Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">            expectation of the response, `E(Y|X)`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score_per_obs : ndarray</span>
<span class="sd">            Values of the scoring function for each observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
        <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

        <span class="n">eta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span>
        <span class="n">eta_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">eta_term</span> <span class="o">*</span> <span class="n">identification_function</span><span class="p">(</span>
            <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
            <span class="n">y_pred</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">eta</span><span class="p">)),</span>
            <span class="n">functional</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">functional</span><span class="p">,</span>
            <span class="n">level</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.ElementaryScore.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.ElementaryScore.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Mean or average score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The average score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean or average score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The average score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.ElementaryScore.score_per_obs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.ElementaryScore.score_per_obs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Score per observation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score_per_obs</code></td>            <td>
                  <code>ndarray</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the scoring function for each observation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score_per_obs : ndarray</span>
<span class="sd">        Values of the scoring function for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="n">eta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eta</span>
    <span class="n">eta_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eta_term</span> <span class="o">*</span> <span class="n">identification_function</span><span class="p">(</span>
        <span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">eta</span><span class="p">)),</span>
        <span class="n">functional</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">functional</span><span class="p">,</span>
        <span class="n">level</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="model_diagnostics.scoring.GammaDeviance" class="doc doc-heading">
            <code>GammaDeviance</code>


<a href="#model_diagnostics.scoring.GammaDeviance" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


      <p>Gamma deviance.</p>
<p>The smaller the better, minimum is zero.</p>
<p>The Gamma deviance is strictly consistent for the mean.
It has a degree of homogeneity of 0 and is therefore insensitive to a change of
units or multiplication of <code>y_obs</code> and <code>y_pred</code> by the same positive constant.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="model_diagnostics.scoring.GammaDeviance.functional">functional</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"mean"</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><span class="arithmatex">\(S(y, z) = 2(\frac{y}{z} -\log\frac{y}{z} - 1)\)</span></p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">gd</span> <span class="o">=</span> <span class="n">GammaDeviance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gd</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">0.2972674459459178</span>
</code></pre></div>

              <details class="quote">
                <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">GammaDeviance</span><span class="p">(</span><span class="n">HomogeneousExpectileScore</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gamma deviance.</span>

<span class="sd">    The smaller the better, minimum is zero.</span>

<span class="sd">    The Gamma deviance is strictly consistent for the mean.</span>
<span class="sd">    It has a degree of homogeneity of 0 and is therefore insensitive to a change of</span>
<span class="sd">    units or multiplication of `y_obs` and `y_pred` by the same positive constant.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    functional: str</span>
<span class="sd">        &quot;mean&quot;</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    \(S(y, z) = 2(\frac{y}{z} -\log\frac{y}{z} - 1)\)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; gd = GammaDeviance()</span>
<span class="sd">    &gt;&gt;&gt; gd(y_obs=[3, 2, 1, 1], y_pred=[2, 1, 1 , 2])  # doctest: +SKIP</span>
<span class="sd">    0.2972674459459178</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># FIXME: numpy 2.0.0, doctest skip should not be necessary.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.GammaDeviance.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.GammaDeviance.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Mean or average score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The average score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean or average score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The average score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.GammaDeviance.score_per_obs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.GammaDeviance.score_per_obs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Score per observation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score_per_obs</code></td>            <td>
                  <code>ndarray</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the scoring function for each observation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score_per_obs : ndarray</span>
<span class="sd">        Values of the scoring function for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Fast path</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt;= 0 and z &gt; 0</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is y_obs &gt;= 0 and &quot;</span>
                <span class="s2">&quot;y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">y_z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_z</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_z</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># self.degree &lt; 1</span>
        <span class="c1"># Domain: y &gt;= 0 and z &gt; 0 for 0 &lt; self.degree &lt; 1</span>
        <span class="c1"># Domain: y &gt; 0  and z &gt; 0 else</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;y_obs &gt;= 0 and y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="c1"># Note: We add 0.0 to be sure we have floating points. Integers are not</span>
        <span class="c1"># allowerd to be raised to a negative power.</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">score</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="model_diagnostics.scoring.HomogeneousExpectileScore" class="doc doc-heading">
            <code>HomogeneousExpectileScore</code>


<a href="#model_diagnostics.scoring.HomogeneousExpectileScore" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


      <p>Homogeneous scoring function of degree h for expectiles.</p>
<p>The smaller the better, minimum is zero.</p>
<p>Up to a multiplicative constant, these are the only scoring functions that are
strictly consistent for expectiles at level alpha and homogeneous functions.
The possible additive constant is chosen such that the minimal function value
equals zero.</p>
<p>Note that the &frac12;-expectile (level alpha=0.5) equals the mean.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>degree</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Degree of homogeneity.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> gives the mean.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="model_diagnostics.scoring.HomogeneousExpectileScore.functional">functional</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"mean" if <code>level=0.5</code>, else "expectile"</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p>The homogeneous score of degree <span class="arithmatex">\(h\)</span> is given by</p>
<div class="arithmatex">\[
S_\alpha^h(y, z) = 2 |\mathbf{1}\{z \ge y\} - \alpha| \frac{2}{h(h-1)}
\left(|y|^h - |z|^h - h \operatorname{sign}(z) |z|^{h-1} (y-z)\right)
\]</div>
<p>Note that the first term, <span class="arithmatex">\(2 |\mathbf{1}\{z \ge y\} - \alpha|\)</span> equals 1 for
<span class="arithmatex">\(\alpha=0.5\)</span>.
There are important domain restrictions and limits:</p>
<ul>
<li>
<p><span class="arithmatex">\(h&gt;1\)</span>: All real numbers <span class="arithmatex">\(y\)</span> and <span class="arithmatex">\(z\)</span> are allowed.</p>
<p>Special case <span class="arithmatex">\(h=2, \alpha=\frac{1}{2}\)</span> equals the squared error, aka Normal
deviance <span class="arithmatex">\(S(y, z) = (y - z)^2\)</span>.</p>
</li>
<li>
<p><span class="arithmatex">\(0 &lt; h \leq 1\)</span>: Only <span class="arithmatex">\(y \geq 0\)</span>, <span class="arithmatex">\(z&gt;0\)</span> are allowed.</p>
<p>Special case <span class="arithmatex">\(h=1, \alpha=\frac{1}{2}\)</span> (by taking the limit) equals the
Poisson deviance <span class="arithmatex">\(S(y, z) = 2(y\log\frac{y}{z} - y + z)\)</span>.</p>
</li>
<li>
<p><span class="arithmatex">\(h \leq 0\)</span>: Only <span class="arithmatex">\(y&gt;0\)</span>, <span class="arithmatex">\(z&gt;0\)</span> are allowed.</p>
<p>Special case <span class="arithmatex">\(h=0, \alpha=\frac{1}{2}\)</span> (by taking the limit) equals the Gamma
deviance <span class="arithmatex">\(S(y, z) = 2(\frac{y}{z} -\log\frac{y}{z} - 1)\)</span>.</p>
</li>
</ul>
<p>For the common domains, <span class="arithmatex">\(S_{\frac{1}{2}}^h\)</span> equals the
<a href="https://en.wikipedia.org/wiki/Tweedie_distribution">Tweedie deviance</a> with the
following relation between the degree of homogeneity <span class="arithmatex">\(h\)</span> and the Tweedie
power <span class="arithmatex">\(p\)</span>: <span class="arithmatex">\(h = 2-p\)</span>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[Gneiting2011]</code></dt>
<dd>
<p>T. Gneiting.
"Making and Evaluating Point Forecasts". (2011)
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>
<a href="https://arxiv.org/abs/0912.0902">arxiv:0912.0902</a></p>
</dd>
</dl>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">hes</span> <span class="o">=</span> <span class="n">HomogeneousExpectileScore</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hes</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">0.95</span>
</code></pre></div>

              <details class="quote">
                <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">HomogeneousExpectileScore</span><span class="p">(</span><span class="n">_BaseScoringFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Homogeneous scoring function of degree h for expectiles.</span>

<span class="sd">    The smaller the better, minimum is zero.</span>

<span class="sd">    Up to a multiplicative constant, these are the only scoring functions that are</span>
<span class="sd">    strictly consistent for expectiles at level alpha and homogeneous functions.</span>
<span class="sd">    The possible additive constant is chosen such that the minimal function value</span>
<span class="sd">    equals zero.</span>

<span class="sd">    Note that the 1/2-expectile (level alpha=0.5) equals the mean.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    degree : float</span>
<span class="sd">        Degree of homogeneity.</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` gives the mean.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    functional: str</span>
<span class="sd">        &quot;mean&quot; if `level=0.5`, else &quot;expectile&quot;</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The homogeneous score of degree \(h\) is given by</span>

<span class="sd">    \[</span>
<span class="sd">    S_\alpha^h(y, z) = 2 |\mathbf{1}\{z \ge y\} - \alpha| \frac{2}{h(h-1)}</span>
<span class="sd">    \left(|y|^h - |z|^h - h \operatorname{sign}(z) |z|^{h-1} (y-z)\right)</span>
<span class="sd">    \]</span>

<span class="sd">    Note that the first term, \(2 |\mathbf{1}\{z \ge y\} - \alpha|\) equals 1 for</span>
<span class="sd">    \(\alpha=0.5\).</span>
<span class="sd">    There are important domain restrictions and limits:</span>

<span class="sd">    - \(h&gt;1\): All real numbers \(y\) and \(z\) are allowed.</span>

<span class="sd">        Special case \(h=2, \alpha=\frac{1}{2}\) equals the squared error, aka Normal</span>
<span class="sd">        deviance \(S(y, z) = (y - z)^2\).</span>

<span class="sd">    - \(0 &lt; h \leq 1\): Only \(y \geq 0\), \(z&gt;0\) are allowed.</span>

<span class="sd">        Special case \(h=1, \alpha=\frac{1}{2}\) (by taking the limit) equals the</span>
<span class="sd">        Poisson deviance \(S(y, z) = 2(y\log\frac{y}{z} - y + z)\).</span>

<span class="sd">    - \(h \leq 0\): Only \(y&gt;0\), \(z&gt;0\) are allowed.</span>

<span class="sd">        Special case \(h=0, \alpha=\frac{1}{2}\) (by taking the limit) equals the Gamma</span>
<span class="sd">        deviance \(S(y, z) = 2(\frac{y}{z} -\log\frac{y}{z} - 1)\).</span>

<span class="sd">    For the common domains, \(S_{\frac{1}{2}}^h\) equals the</span>
<span class="sd">    [Tweedie deviance](https://en.wikipedia.org/wiki/Tweedie_distribution) with the</span>
<span class="sd">    following relation between the degree of homogeneity \(h\) and the Tweedie</span>
<span class="sd">    power \(p\): \(h = 2-p\).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[Gneiting2011]`</span>

<span class="sd">    :   T. Gneiting.</span>
<span class="sd">        &quot;Making and Evaluating Point Forecasts&quot;. (2011)</span>
<span class="sd">        [doi:10.1198/jasa.2011.r10138](https://doi.org/10.1198/jasa.2011.r10138)</span>
<span class="sd">        [arxiv:0912.0902](https://arxiv.org/abs/0912.0902)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; hes = HomogeneousExpectileScore(degree=2, level=0.1)</span>
<span class="sd">    &gt;&gt;&gt; hes(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2])  # doctest: +SKIP</span>
<span class="sd">    0.95</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># FIXME: numpy 2.0.0, doctest skip should not be necessary.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="k">if</span> <span class="n">level</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">level</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Argument level must fulfil 0 &lt; level &lt; 1, got </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="n">level</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">functional</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;mean&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;expectile&quot;</span>

    <span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_obs : array-like of shape (n_obs)</span>
<span class="sd">            Observed values of the response variable.</span>
<span class="sd">        y_pred : array-like of shape (n_obs)</span>
<span class="sd">            Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">            expectation of the response, `E(Y|X)`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score_per_obs : ndarray</span>
<span class="sd">            Values of the scoring function for each observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
        <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># Fast path</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">z_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
                <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
                <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
                <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Domain: y &gt;= 0 and z &gt; 0</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is y_obs &gt;= 0 and &quot;</span>
                    <span class="s2">&quot;y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="n">y_z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_z</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_z</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># self.degree &lt; 1</span>
            <span class="c1"># Domain: y &gt;= 0 and z &gt; 0 for 0 &lt; self.degree &lt; 1</span>
            <span class="c1"># Domain: y &gt; 0  and z &gt; 0 else</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                        <span class="s2">&quot;y_obs &gt;= 0 and y_pred &gt; 0.&quot;</span>
                    <span class="p">)</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="c1"># Note: We add 0.0 to be sure we have floating points. Integers are not</span>
            <span class="c1"># allowerd to be raised to a negative power.</span>
            <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
                <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
                <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">score</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.HomogeneousExpectileScore.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.HomogeneousExpectileScore.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Mean or average score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The average score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean or average score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The average score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.HomogeneousExpectileScore.score_per_obs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.HomogeneousExpectileScore.score_per_obs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Score per observation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score_per_obs</code></td>            <td>
                  <code>ndarray</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the scoring function for each observation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score_per_obs : ndarray</span>
<span class="sd">        Values of the scoring function for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Fast path</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt;= 0 and z &gt; 0</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is y_obs &gt;= 0 and &quot;</span>
                <span class="s2">&quot;y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">y_z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_z</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_z</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># self.degree &lt; 1</span>
        <span class="c1"># Domain: y &gt;= 0 and z &gt; 0 for 0 &lt; self.degree &lt; 1</span>
        <span class="c1"># Domain: y &gt; 0  and z &gt; 0 else</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;y_obs &gt;= 0 and y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="c1"># Note: We add 0.0 to be sure we have floating points. Integers are not</span>
        <span class="c1"># allowerd to be raised to a negative power.</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">score</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="model_diagnostics.scoring.HomogeneousQuantileScore" class="doc doc-heading">
            <code>HomogeneousQuantileScore</code>


<a href="#model_diagnostics.scoring.HomogeneousQuantileScore" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


      <p>Homogeneous scoring function of degree h for quantiles.</p>
<p>The smaller the better, minimum is zero.</p>
<p>Up to a multiplicative constant, these are the only scoring funtions that are
strictly consistent for quantiles at level alpha and homogeneous functions.
The possible additive constant is chosen such that the minimal function value
equals zero.</p>
<p>Note that the &frac12;-quantile (level alpha=0.5) equals the median.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>degree</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Degree of homogeneity.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="model_diagnostics.scoring.HomogeneousQuantileScore.functional">functional</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"quantile"</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p>The homogeneous score of degree <span class="arithmatex">\(h\)</span> is given by</p>
<div class="arithmatex">\[
S_\alpha^h(y, z) = (\mathbf{1}\{z \ge y\} - \alpha) \frac{z^h - y^h}{h}
\]</div>
<p>There are important domain restrictions and limits:</p>
<ul>
<li>
<p><span class="arithmatex">\(h\)</span> positive odd integer: All real numbers <span class="arithmatex">\(y\)</span> and <span class="arithmatex">\(z\)</span> are allowed.</p>
<ul>
<li>Special case <span class="arithmatex">\(h=1\)</span> equals the pinball loss,
  <span class="arithmatex">\(S(y, z) = (\mathbf{1}\{z \ge y\} - \alpha) (z - y)\)</span>.</li>
<li>Special case <span class="arithmatex">\(h=1, \alpha=\frac{1}{2}\)</span> equals half the absolute error
  <span class="arithmatex">\(S(y, z) = \frac{1}{2}|z - y|\)</span>.</li>
</ul>
</li>
<li>
<p><span class="arithmatex">\(h\)</span> real valued: Only <span class="arithmatex">\(y&gt;0\)</span>, <span class="arithmatex">\(z&gt;0\)</span> are allowed.</p>
<p>Special case <span class="arithmatex">\(h=0\)</span> (by taking the limit) equals
<span class="arithmatex">\(S(y, z) = |\mathbf{1}\{z \ge y\} - \alpha| \log\frac{z}{y}\)</span>.</p>
</li>
</ul>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[Gneiting2011]</code></dt>
<dd>
<p>T. Gneiting.
"Making and Evaluating Point Forecasts". (2011)
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>
<a href="https://arxiv.org/abs/0912.0902">arxiv:0912.0902</a></p>
</dd>
</dl>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">hqs</span> <span class="o">=</span> <span class="n">HomogeneousQuantileScore</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hqs</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">0.6083333333333334</span>
</code></pre></div>

              <details class="quote">
                <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">HomogeneousQuantileScore</span><span class="p">(</span><span class="n">_BaseScoringFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Homogeneous scoring function of degree h for quantiles.</span>

<span class="sd">    The smaller the better, minimum is zero.</span>

<span class="sd">    Up to a multiplicative constant, these are the only scoring funtions that are</span>
<span class="sd">    strictly consistent for quantiles at level alpha and homogeneous functions.</span>
<span class="sd">    The possible additive constant is chosen such that the minimal function value</span>
<span class="sd">    equals zero.</span>

<span class="sd">    Note that the 1/2-quantile (level alpha=0.5) equals the median.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    degree : float</span>
<span class="sd">        Degree of homogeneity.</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` gives the median.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    functional: str</span>
<span class="sd">        &quot;quantile&quot;</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The homogeneous score of degree \(h\) is given by</span>

<span class="sd">    \[</span>
<span class="sd">    S_\alpha^h(y, z) = (\mathbf{1}\{z \ge y\} - \alpha) \frac{z^h - y^h}{h}</span>
<span class="sd">    \]</span>

<span class="sd">    There are important domain restrictions and limits:</span>

<span class="sd">    - \(h\) positive odd integer: All real numbers \(y\) and \(z\) are allowed.</span>

<span class="sd">        - Special case \(h=1\) equals the pinball loss,</span>
<span class="sd">          \(S(y, z) = (\mathbf{1}\{z \ge y\} - \alpha) (z - y)\).</span>
<span class="sd">        - Special case \(h=1, \alpha=\frac{1}{2}\) equals half the absolute error</span>
<span class="sd">          \(S(y, z) = \frac{1}{2}|z - y|\).</span>

<span class="sd">    - \(h\) real valued: Only \(y&gt;0\), \(z&gt;0\) are allowed.</span>

<span class="sd">        Special case \(h=0\) (by taking the limit) equals</span>
<span class="sd">        \(S(y, z) = |\mathbf{1}\{z \ge y\} - \alpha| \log\frac{z}{y}\).</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[Gneiting2011]`</span>

<span class="sd">    :   T. Gneiting.</span>
<span class="sd">        &quot;Making and Evaluating Point Forecasts&quot;. (2011)</span>
<span class="sd">        [doi:10.1198/jasa.2011.r10138](https://doi.org/10.1198/jasa.2011.r10138)</span>
<span class="sd">        [arxiv:0912.0902](https://arxiv.org/abs/0912.0902)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; hqs = HomogeneousQuantileScore(degree=3, level=0.1)</span>
<span class="sd">    &gt;&gt;&gt; hqs(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2])  # doctest: +SKIP</span>
<span class="sd">    0.6083333333333334</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># FIXME: numpy 2.0.0, doctest skip should not be necessary.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">degree</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">=</span> <span class="n">degree</span>
        <span class="k">if</span> <span class="n">level</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">level</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Argument level must fulfil 0 &lt; level &lt; 1, got </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="n">level</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">functional</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;quantile&quot;</span>

    <span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_obs : array-like of shape (n_obs)</span>
<span class="sd">            Observed values of the response variable.</span>
<span class="sd">        y_pred : array-like of shape (n_obs)</span>
<span class="sd">            Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">            expectation of the response, `E(Y|X)`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score_per_obs : ndarray</span>
<span class="sd">            Values of the scoring function for each observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
        <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Fast path</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">y</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Odd positive degree</span>
            <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">z</span> <span class="o">/</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.HomogeneousQuantileScore.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.HomogeneousQuantileScore.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Mean or average score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The average score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean or average score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The average score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.HomogeneousQuantileScore.score_per_obs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.HomogeneousQuantileScore.score_per_obs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Score per observation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score_per_obs</code></td>            <td>
                  <code>ndarray</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the scoring function for each observation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score_per_obs : ndarray</span>
<span class="sd">        Values of the scoring function for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Fast path</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">y</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Odd positive degree</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">z</span> <span class="o">/</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="model_diagnostics.scoring.LogLoss" class="doc doc-heading">
            <code>LogLoss</code>


<a href="#model_diagnostics.scoring.LogLoss" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


      <p>Log loss.</p>
<p>The smaller the better, minimum is zero.</p>
<p>The log loss is a strictly consistent scoring function for the mean for
observations and predictions in the range 0 to 1.
It is also referred to as (half the) Bernoulli deviance,
(half the) Binomial log-likelihood, logistic loss and binary cross-entropy.
Its minimal function value is zero.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="model_diagnostics.scoring.LogLoss.functional">functional</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"mean"</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p>The log loss for <span class="arithmatex">\(y,z \in [0,1]\)</span> is given by</p>
<div class="arithmatex">\[
S(y, z) = - y \log\frac{z}{y} - (1 - y) \log\frac{1-z}{1-y}
\]</div>
<p>If one restricts to <span class="arithmatex">\(y\in \{0, 1\}\)</span>, this simplifies to</p>
<div class="arithmatex">\[
S(y, z) = - y \log(z) - (1 - y) \log(1-z)
\]</div>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">ll</span> <span class="o">=</span> <span class="n">LogLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ll</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span> <span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">0.17603033705165635</span>
</code></pre></div>

              <details class="quote">
                <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LogLoss</span><span class="p">(</span><span class="n">_BaseScoringFunction</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Log loss.</span>

<span class="sd">    The smaller the better, minimum is zero.</span>

<span class="sd">    The log loss is a strictly consistent scoring function for the mean for</span>
<span class="sd">    observations and predictions in the range 0 to 1.</span>
<span class="sd">    It is also referred to as (half the) Bernoulli deviance,</span>
<span class="sd">    (half the) Binomial log-likelihood, logistic loss and binary cross-entropy.</span>
<span class="sd">    Its minimal function value is zero.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    functional: str</span>
<span class="sd">        &quot;mean&quot;</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The log loss for \(y,z \in [0,1]\) is given by</span>

<span class="sd">    \[</span>
<span class="sd">    S(y, z) = - y \log\frac{z}{y} - (1 - y) \log\frac{1-z}{1-y}</span>
<span class="sd">    \]</span>

<span class="sd">    If one restricts to \(y\in \{0, 1\}\), this simplifies to</span>

<span class="sd">    \[</span>
<span class="sd">    S(y, z) = - y \log(z) - (1 - y) \log(1-z)</span>
<span class="sd">    \]</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; ll = LogLoss()</span>
<span class="sd">    &gt;&gt;&gt; ll(y_obs=[0, 0.5, 1, 1], y_pred=[0.1, 0.2, 0.8 , 0.9], weights=[1, 2, 1, 1])  # doctest: +SKIP</span>
<span class="sd">    0.17603033705165635</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

    <span class="c1"># FIXME: numpy 2.0.0, doctest skip should not be necessary.</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">functional</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;mean&quot;</span>

    <span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_obs : array-like of shape (n_obs)</span>
<span class="sd">            Observed values of the response variable.</span>
<span class="sd">        y_pred : array-like of shape (n_obs)</span>
<span class="sd">            Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">            expectation of the response, `E(Y|X)`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score_per_obs : ndarray</span>
<span class="sd">            Values of the scoring function for each observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
        <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

        <span class="n">score</span> <span class="o">=</span> <span class="o">-</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="n">score</span> <span class="o">+=</span> <span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.LogLoss.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.LogLoss.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Mean or average score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The average score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean or average score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The average score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.LogLoss.score_per_obs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.LogLoss.score_per_obs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Score per observation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score_per_obs</code></td>            <td>
                  <code>ndarray</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the scoring function for each observation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score_per_obs : ndarray</span>
<span class="sd">        Values of the scoring function for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="n">score</span> <span class="o">=</span> <span class="o">-</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="n">score</span> <span class="o">+=</span> <span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="model_diagnostics.scoring.PinballLoss" class="doc doc-heading">
            <code>PinballLoss</code>


<a href="#model_diagnostics.scoring.PinballLoss" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


      <p>Pinball loss.</p>
<p>The smaller the better, minimum is zero.</p>
<p>The pinball loss is strictly consistent for quantiles.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="model_diagnostics.scoring.PinballLoss.functional">functional</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"quantile"</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p>The pinball loss has degree of homogeneity 1 and is given by</p>
<div class="arithmatex">\[
S_\alpha(y, z) = (\mathbf{1}\{z \ge y\} - \alpha) (z - y)
\]</div>
<p>The authors do not know where and when the term <em>pinball loss</em> was coined. It is
most famously used in quantile regression.</p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">pl</span> <span class="o">=</span> <span class="n">PinballLoss</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pl</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">0.275</span>
</code></pre></div>

              <details class="quote">
                <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PinballLoss</span><span class="p">(</span><span class="n">HomogeneousQuantileScore</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Pinball loss.</span>

<span class="sd">    The smaller the better, minimum is zero.</span>

<span class="sd">    The pinball loss is strictly consistent for quantiles.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` gives the median.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    functional: str</span>
<span class="sd">        &quot;quantile&quot;</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The pinball loss has degree of homogeneity 1 and is given by</span>

<span class="sd">    \[</span>
<span class="sd">    S_\alpha(y, z) = (\mathbf{1}\{z \ge y\} - \alpha) (z - y)</span>
<span class="sd">    \]</span>

<span class="sd">    The authors do not know where and when the term *pinball loss* was coined. It is</span>
<span class="sd">    most famously used in quantile regression.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; pl = PinballLoss(level=0.9)</span>
<span class="sd">    &gt;&gt;&gt; pl(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2])  # doctest: +SKIP</span>
<span class="sd">    0.275</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># FIXME: numpy 2.0.0, doctest skip should not be necessary.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.PinballLoss.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.PinballLoss.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Mean or average score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The average score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean or average score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The average score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.PinballLoss.score_per_obs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.PinballLoss.score_per_obs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Score per observation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score_per_obs</code></td>            <td>
                  <code>ndarray</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the scoring function for each observation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score_per_obs : ndarray</span>
<span class="sd">        Values of the scoring function for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Fast path</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">y</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Odd positive degree</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">z</span> <span class="o">/</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="model_diagnostics.scoring.PoissonDeviance" class="doc doc-heading">
            <code>PoissonDeviance</code>


<a href="#model_diagnostics.scoring.PoissonDeviance" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


      <p>Poisson deviance.</p>
<p>The smaller the better, minimum is zero.</p>
<p>The Poisson deviance is strictly consistent for the mean.
It has a degree of homogeneity of 1.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="model_diagnostics.scoring.PoissonDeviance.functional">functional</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"mean"</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><span class="arithmatex">\(S(y, z) = 2(y\log\frac{y}{z} - y + z)\)</span></p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span> <span class="o">=</span> <span class="n">PoissonDeviance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pd</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">1.6534264097200273</span>
</code></pre></div>

              <details class="quote">
                <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PoissonDeviance</span><span class="p">(</span><span class="n">HomogeneousExpectileScore</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Poisson deviance.</span>

<span class="sd">    The smaller the better, minimum is zero.</span>

<span class="sd">    The Poisson deviance is strictly consistent for the mean.</span>
<span class="sd">    It has a degree of homogeneity of 1.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    functional: str</span>
<span class="sd">        &quot;mean&quot;</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    \(S(y, z) = 2(y\log\frac{y}{z} - y + z)\)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; pd = PoissonDeviance()</span>
<span class="sd">    &gt;&gt;&gt; pd(y_obs=[0, 0, 1, 1], y_pred=[2, 1, 1 , 2])  # doctest: +SKIP</span>
<span class="sd">    1.6534264097200273</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># FIXME: numpy 2.0.0, doctest skip should not be necessary.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.PoissonDeviance.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.PoissonDeviance.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Mean or average score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The average score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean or average score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The average score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.PoissonDeviance.score_per_obs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.PoissonDeviance.score_per_obs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Score per observation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score_per_obs</code></td>            <td>
                  <code>ndarray</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the scoring function for each observation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score_per_obs : ndarray</span>
<span class="sd">        Values of the scoring function for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Fast path</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt;= 0 and z &gt; 0</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is y_obs &gt;= 0 and &quot;</span>
                <span class="s2">&quot;y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">y_z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_z</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_z</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># self.degree &lt; 1</span>
        <span class="c1"># Domain: y &gt;= 0 and z &gt; 0 for 0 &lt; self.degree &lt; 1</span>
        <span class="c1"># Domain: y &gt; 0  and z &gt; 0 else</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;y_obs &gt;= 0 and y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="c1"># Note: We add 0.0 to be sure we have floating points. Integers are not</span>
        <span class="c1"># allowerd to be raised to a negative power.</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">score</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="model_diagnostics.scoring.SquaredError" class="doc doc-heading">
            <code>SquaredError</code>


<a href="#model_diagnostics.scoring.SquaredError" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">


      <p>Squared error.</p>
<p>The smaller the better, minimum is zero.</p>
<p>The squared error is strictly consistent for the mean.
It has a degree of homogeneity of 2.
In the context of probabilistic classification, it is also known as Brier score.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="model_diagnostics.scoring.SquaredError.functional">functional</span></code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>"mean"</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><span class="arithmatex">\(S(y, z) = (y - z)^2\)</span></p>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">se</span> <span class="o">=</span> <span class="n">SquaredError</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">se</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">0.75</span>
</code></pre></div>

              <details class="quote">
                <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SquaredError</span><span class="p">(</span><span class="n">HomogeneousExpectileScore</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Squared error.</span>

<span class="sd">    The smaller the better, minimum is zero.</span>

<span class="sd">    The squared error is strictly consistent for the mean.</span>
<span class="sd">    It has a degree of homogeneity of 2.</span>
<span class="sd">    In the context of probabilistic classification, it is also known as Brier score.</span>


<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    functional: str</span>
<span class="sd">        &quot;mean&quot;</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    \(S(y, z) = (y - z)^2\)</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; se = SquaredError()</span>
<span class="sd">    &gt;&gt;&gt; se(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1 , 2])  # doctest: +SKIP</span>
<span class="sd">    0.75</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># FIXME: numpy 2.0.0, doctest skip should not be necessary.</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.SquaredError.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.SquaredError.__call__" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Mean or average score.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score</code></td>            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The average score.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mean or average score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score : float</span>
<span class="sd">        The average score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="model_diagnostics.scoring.SquaredError.score_per_obs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">score_per_obs</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.SquaredError.score_per_obs" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

      <p>Score per observation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>score_per_obs</code></td>            <td>
                  <code>ndarray</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Values of the scoring function for each observation.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">score_per_obs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Score per observation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score_per_obs : ndarray</span>
<span class="sd">        Values of the scoring function for each observation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">validate_2_arrays</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># Fast path</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">z_abs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z_abs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt;= 0 and z &gt; 0</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is y_obs &gt;= 0 and &quot;</span>
                <span class="s2">&quot;y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span> <span class="o">+</span> <span class="n">z</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Domain: y &gt; 0 and z &gt; 0.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">y_z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">/</span> <span class="n">z</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_z</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_z</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># self.degree &lt; 1</span>
        <span class="c1"># Domain: y &gt;= 0 and z &gt; 0 for 0 &lt; self.degree &lt; 1</span>
        <span class="c1"># Domain: y &gt; 0  and z &gt; 0 else</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;y_obs &gt;= 0 and y_pred &gt; 0.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">((</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Valid domain for degree=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;y_obs &gt; 0 and y_pred &gt; 0.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="c1"># Note: We add 0.0 to be sure we have floating points. Integers are not</span>
        <span class="c1"># allowerd to be raised to a negative power.</span>
        <span class="n">score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span><span class="p">))</span>
            <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
            <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="mf">0.0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">degree</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">score</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">level</span><span class="p">)</span> <span class="o">*</span> <span class="n">score</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.scoring.decompose" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">decompose</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">scoring_function</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.decompose" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Additive decomposition of scores.</p>
<p>The score is decomposed as
<code>score = miscalibration - discrimination + uncertainty</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs) or (n_obs, n_models)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values of the <code>functional</code> of interest, e.g. the conditional
expectation of the response, <code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scoring_function</code></td>
            <td>
                  <code>callable</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A scoring function with signature roughly
<code>fun(y_obs, y_pred, weights) -&gt; float</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The target functional which <code>y_pred</code> aims to predict.
If <code>None</code>, then it will be inferred from <code>scoring_function.functional</code>.
Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Functionals like expectiles and quantiles have a level (often called alpha).
If <code>None</code>, then it will be inferred from <code>scoring_function.level</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>decomposition</code></td>            <td>
                  <code><span title="polars.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The resulting score decomposition as a dataframe with columns:</p>
<ul>
<li><code>miscalibration</code></li>
<li><code>discrimination</code></li>
<li><code>uncertainty</code></li>
<li><code>score</code>: the average score</li>
</ul>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td></td>            <td>
                  <code>If `y_pred` contains several predictions, i.e. it is 2-dimension with shape</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
<td></td>            <td>
                  <code>`(n_obs, n_pred)` and `n_pred &gt;1`, then there is the additional column:</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ul>
<li><code>model</code></li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p>To be precise, this function returns the decomposition of the score in terms of
auto-miscalibration, auto-discrimination (or resolution) and uncertainy (or
entropy), see <code>[FLM2022]</code> and references therein.
The key element is to estimate the recalibrated predictions, i.e. <span class="arithmatex">\(T(Y|m(X))\)</span> for
the target functional <span class="arithmatex">\(T\)</span> and model predictions <span class="arithmatex">\(m(X)\)</span>.
This is accomplished by isotonic regression, <code>[Dimitriadis2021]</code> and
<code>[Gneiting2021]</code>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[FLM2022]</code></dt>
<dd>
<p>T. Fissler, C. Lorentzen, and M. Mayer.
"Model Comparison and Calibration Assessment". (2022)
<a href="https://arxiv.org/abs/2202.12780">arxiv:2202.12780</a>.</p>
</dd>
<dt><code>[Dimitriadis2021]</code></dt>
<dd>
<p>T. Dimitriadis, T. Gneiting, and A. I. Jordan.
"Stable reliability diagrams for probabilistic classifiers". (2021)
<a href="https://doi.org/10.1073/pnas.2016191118">doi:10.1073/pnas.2016191118</a></p>
</dd>
<dt><code>[Gneiting2021]</code></dt>
<dd>
<p>T. Gneiting and J. Resin.
"Regression Diagnostics meets Forecast Evaluation: Conditional Calibration,
Reliability Diagrams, and Coefficient of Determination". (2021).
<a href="https://arxiv.org/abs/2108.03210">arXiv:2108.03210</a>.</p>
</dd>
</dl>
</details>

<p><span class="doc-section-title">Examples:</span></p>
    <div class="highlight"><pre><span></span><code><span class="gp">&gt;&gt;&gt; </span><span class="n">decompose</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_pred</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span><span class="n">scoring_function</span><span class="o">=</span><span class="n">SquaredError</span><span class="p">())</span>
<span class="go">shape: (1, 4)</span>
<span class="go">┌────────────────┬────────────────┬─────────────┬───────┐</span>
<span class="go">│ miscalibration ┆ discrimination ┆ uncertainty ┆ score │</span>
<span class="go">│ ---            ┆ ---            ┆ ---         ┆ ---   │</span>
<span class="go">│ f64            ┆ f64            ┆ f64         ┆ f64   │</span>
<span class="go">╞════════════════╪════════════════╪═════════════╪═══════╡</span>
<span class="go">│ 0.625          ┆ 0.125          ┆ 0.25        ┆ 0.75  │</span>
<span class="go">└────────────────┴────────────────┴─────────────┴───────┘</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/scoring.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">decompose</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">scoring_function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>  <span class="c1"># TODO: make type hint stricter</span>
    <span class="n">functional</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Additive decomposition of scores.</span>

<span class="sd">    The score is decomposed as</span>
<span class="sd">    `score = miscalibration - discrimination + uncertainty`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">    y_pred : array-like of shape (n_obs) or (n_obs, n_models)</span>
<span class="sd">        Predicted values of the `functional` of interest, e.g. the conditional</span>
<span class="sd">        expectation of the response, `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>
<span class="sd">    scoring_function : callable</span>
<span class="sd">        A scoring function with signature roughly</span>
<span class="sd">        `fun(y_obs, y_pred, weights) -&gt; float`.</span>
<span class="sd">    functional : str or None</span>
<span class="sd">        The target functional which `y_pred` aims to predict.</span>
<span class="sd">        If `None`, then it will be inferred from `scoring_function.functional`.</span>
<span class="sd">        Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float or None</span>
<span class="sd">        Functionals like expectiles and quantiles have a level (often called alpha).</span>
<span class="sd">        If `None`, then it will be inferred from `scoring_function.level`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    decomposition : polars.DataFrame</span>
<span class="sd">        The resulting score decomposition as a dataframe with columns:</span>

<span class="sd">        - `miscalibration`</span>
<span class="sd">        - `discrimination`</span>
<span class="sd">        - `uncertainty`</span>
<span class="sd">        - `score`: the average score</span>

<span class="sd">    If `y_pred` contains several predictions, i.e. it is 2-dimension with shape</span>
<span class="sd">    `(n_obs, n_pred)` and `n_pred &gt;1`, then there is the additional column:</span>

<span class="sd">        - `model`</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    To be precise, this function returns the decomposition of the score in terms of</span>
<span class="sd">    auto-miscalibration, auto-discrimination (or resolution) and uncertainy (or</span>
<span class="sd">    entropy), see `[FLM2022]` and references therein.</span>
<span class="sd">    The key element is to estimate the recalibrated predictions, i.e. \(T(Y|m(X))\) for</span>
<span class="sd">    the target functional \(T\) and model predictions \(m(X)\).</span>
<span class="sd">    This is accomplished by isotonic regression, `[Dimitriadis2021]` and</span>
<span class="sd">    `[Gneiting2021]`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[FLM2022]`</span>

<span class="sd">    :   T. Fissler, C. Lorentzen, and M. Mayer.</span>
<span class="sd">        &quot;Model Comparison and Calibration Assessment&quot;. (2022)</span>
<span class="sd">        [arxiv:2202.12780](https://arxiv.org/abs/2202.12780).</span>

<span class="sd">    `[Dimitriadis2021]`</span>

<span class="sd">    :   T. Dimitriadis, T. Gneiting, and A. I. Jordan.</span>
<span class="sd">        &quot;Stable reliability diagrams for probabilistic classifiers&quot;. (2021)</span>
<span class="sd">        [doi:10.1073/pnas.2016191118](https://doi.org/10.1073/pnas.2016191118)</span>

<span class="sd">    `[Gneiting2021]`</span>

<span class="sd">    :   T. Gneiting and J. Resin.</span>
<span class="sd">        &quot;Regression Diagnostics meets Forecast Evaluation: Conditional Calibration,</span>
<span class="sd">        Reliability Diagrams, and Coefficient of Determination&quot;. (2021).</span>
<span class="sd">        [arXiv:2108.03210](https://arxiv.org/abs/2108.03210).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; decompose(y_obs=[0, 0, 1, 1], y_pred=[-1, 1, 1, 2],</span>
<span class="sd">    ... scoring_function=SquaredError())</span>
<span class="sd">    shape: (1, 4)</span>
<span class="sd">    ┌────────────────┬────────────────┬─────────────┬───────┐</span>
<span class="sd">    │ miscalibration ┆ discrimination ┆ uncertainty ┆ score │</span>
<span class="sd">    │ ---            ┆ ---            ┆ ---         ┆ ---   │</span>
<span class="sd">    │ f64            ┆ f64            ┆ f64         ┆ f64   │</span>
<span class="sd">    ╞════════════════╪════════════════╪═════════════╪═══════╡</span>
<span class="sd">    │ 0.625          ┆ 0.125          ┆ 0.25        ┆ 0.75  │</span>
<span class="sd">    └────────────────┴────────────────┴─────────────┴───────┘</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">functional</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">scoring_function</span><span class="p">,</span> <span class="s2">&quot;functional&quot;</span><span class="p">):</span>
            <span class="n">functional</span> <span class="o">=</span> <span class="n">scoring_function</span><span class="o">.</span><span class="n">functional</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;You set functional=None, but scoring_function has no attribute &quot;</span>
                <span class="s2">&quot;functional.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">level</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">level</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="k">if</span> <span class="n">functional</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;expectile&quot;</span><span class="p">,</span> <span class="s2">&quot;quantile&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">scoring_function</span><span class="p">,</span> <span class="s2">&quot;level&quot;</span><span class="p">):</span>
                <span class="n">level</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">scoring_function</span><span class="o">.</span><span class="n">level</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;You set level=None, but scoring_function has no attribute &quot;</span>
                    <span class="s2">&quot;level.&quot;</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">allowed_functionals</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;median&quot;</span><span class="p">,</span> <span class="s2">&quot;expectile&quot;</span><span class="p">,</span> <span class="s2">&quot;quantile&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">functional</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_functionals</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The functional must be one of </span><span class="si">{</span><span class="n">allowed_functionals</span><span class="si">}</span><span class="s2">, got &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">functional</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">functional</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;expectile&quot;</span><span class="p">,</span> <span class="s2">&quot;quantile&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">level</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">level</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;The level must fulfil 0 &lt; level &lt; 1, got </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">n_pred</span> <span class="o">=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">pred_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">y_o</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">validate_same_first_dimension</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">y_o</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>  <span class="c1"># needed to satisfy mypy</span>
        <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;The array weights must be 1-dimensional, got weights.ndim=</span><span class="si">{</span><span class="n">w</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
        <span class="n">iso</span> <span class="o">=</span> <span class="n">IsotonicRegression_skl</span><span class="p">(</span><span class="n">y_min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y_max</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">marginal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y_o</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">iso</span> <span class="o">=</span> <span class="n">IsotonicRegression</span><span class="p">(</span><span class="n">functional</span><span class="o">=</span><span class="n">functional</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;expectile&quot;</span><span class="p">:</span>
            <span class="n">marginal</span> <span class="o">=</span> <span class="n">expectile</span><span class="p">(</span><span class="n">y_o</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">level</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;quantile&quot;</span><span class="p">:</span>
            <span class="n">marginal</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span>
                <span class="n">quantile_lower</span><span class="p">(</span><span class="n">y_o</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span> <span class="o">+</span> <span class="n">quantile_upper</span><span class="p">(</span><span class="n">y_o</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">y_o</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">marginal</span> <span class="o">==</span> <span class="n">y_o</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="c1"># y_o is constant. We need to check if y_o is allowed as argument to y_pred.</span>
        <span class="c1"># For instance for the poisson deviance, y_o = 0 is allowed. But 0 is forbidden</span>
        <span class="c1"># as a prediction.</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">scoring_function</span><span class="p">(</span><span class="n">y_o</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">marginal</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Your y_obs is constant and lies outside the allowed range of y_pred &quot;</span>
                <span class="s2">&quot;of your scoring function. Therefore, the score decomposition cannot &quot;</span>
                <span class="s2">&quot;be applied.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">exc</span>

    <span class="c1"># The recalibrated versions, further down, could contain min(y_obs) and that could</span>
    <span class="c1"># be outside of the valid domain, e.g. y_pred = 0 for the Poisson deviance where</span>
    <span class="c1"># y_obs=0 is allowed. We detect that here:</span>
    <span class="n">y_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">y_o</span><span class="p">)</span>
    <span class="n">y_min_allowed</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">scoring_function</span><span class="p">(</span><span class="n">y_o</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y_min</span><span class="p">]),</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">w</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="n">y_min_allowed</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">marginal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">y_o</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">marginal</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">score_marginal</span> <span class="o">=</span> <span class="n">scoring_function</span><span class="p">(</span><span class="n">y_o</span><span class="p">,</span> <span class="n">marginal</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>

    <span class="n">df_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">)):</span>
        <span class="c1"># Loop over columns of y_pred.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">iso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_o</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
        <span class="n">recalibrated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">iso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">y_min_allowed</span> <span class="ow">and</span> <span class="n">recalibrated</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">y_min</span><span class="p">:</span>
            <span class="c1"># Oh dear, this needs quite some extra work:</span>
            <span class="c1"># First index of value greater than y_min</span>
            <span class="n">idx1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">recalibrated</span> <span class="o">&gt;</span> <span class="n">y_min</span><span class="p">)</span>
            <span class="n">val1</span> <span class="o">=</span> <span class="n">recalibrated</span><span class="p">[</span><span class="n">idx1</span><span class="p">]</span>
            <span class="c1"># First index of value greater than the value at idx1.</span>
            <span class="n">idx2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">recalibrated</span> <span class="o">&gt;</span> <span class="n">val1</span><span class="p">)</span>
            <span class="c1"># Note that val1 may already be the largest value of the array =&gt; idx2 = 0.</span>
            <span class="k">if</span> <span class="n">idx2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">idx2</span> <span class="o">=</span> <span class="n">recalibrated</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># We merge the first 2 blocks of the isotonic regression as it violates</span>
            <span class="c1"># our domain requirements.</span>
            <span class="n">re2</span> <span class="o">=</span> <span class="n">recalibrated</span><span class="p">[:</span><span class="n">idx2</span><span class="p">]</span>
            <span class="n">w2</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">w</span><span class="p">[:</span><span class="n">idx2</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
                <span class="n">recalibrated</span><span class="p">[:</span><span class="n">idx2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">re2</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w2</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;expectile&quot;</span><span class="p">:</span>
                <span class="n">recalibrated</span><span class="p">[:</span><span class="n">idx2</span><span class="p">]</span> <span class="o">=</span> <span class="n">expectile</span><span class="p">(</span><span class="n">re2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">level</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">w2</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">functional</span> <span class="o">==</span> <span class="s2">&quot;quantile&quot;</span><span class="p">:</span>
                <span class="c1"># Note, no scoring function known that could end up here.</span>
                <span class="n">lower</span> <span class="o">=</span> <span class="n">quantile_lower</span><span class="p">(</span><span class="n">re2</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span>
                <span class="n">upper</span> <span class="o">=</span> <span class="n">quantile_upper</span><span class="p">(</span><span class="n">re2</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span>
                <span class="n">recalibrated</span><span class="p">[:</span><span class="n">idx2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">lower</span> <span class="o">+</span> <span class="n">upper</span><span class="p">)</span>

        <span class="n">score</span> <span class="o">=</span> <span class="n">scoring_function</span><span class="p">(</span><span class="n">y_o</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">score_recalibrated</span> <span class="o">=</span> <span class="n">scoring_function</span><span class="p">(</span><span class="n">y_o</span><span class="p">,</span> <span class="n">recalibrated</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;The recalibrated predictions obtained from isotonic regression are &quot;</span>
                <span class="s2">&quot;very likely outside the allowed range of y_pred of your scoring &quot;</span>
                <span class="s2">&quot;function. Therefore, the score decomposition cannot be applied.&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">exc</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">pred_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="s2">&quot;miscalibration&quot;</span><span class="p">:</span> <span class="n">score</span> <span class="o">-</span> <span class="n">score_recalibrated</span><span class="p">,</span>
                <span class="s2">&quot;discrimination&quot;</span><span class="p">:</span> <span class="n">score_marginal</span> <span class="o">-</span> <span class="n">score_recalibrated</span><span class="p">,</span>
                <span class="s2">&quot;uncertainty&quot;</span><span class="p">:</span> <span class="n">score_marginal</span><span class="p">,</span>
                <span class="s2">&quot;score&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="n">df_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">df_list</span><span class="p">)</span>

    <span class="c1"># Remove column &quot;model&quot; for a single model.</span>
    <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model_diagnostics.scoring.plot_murphy_diagram" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">plot_murphy_diagram</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">etas</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#model_diagnostics.scoring.plot_murphy_diagram" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

      <p>Plot a Murphy diagram.</p>
<p>A Murphy diagram plots the scores of elementary scoring functions <code>ElementaryScore</code>
over a range of their free parameter <code>eta</code>. This shows, if a model dominates all
others over a wide class of scoring functions or if the ranking is very much
dependent on the choice of scoring function.
See <a href="#model_diagnostics.scoring.plot_murphy_diagram--notes">Notes</a> for further details.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>y_obs</code></td>
            <td>
                  <code>array-like of shape (n_obs)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Observed values of the response variable.
For binary classification, y_obs is expected to be in the interval [0, 1].</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>y_pred</code></td>
            <td>
                  <code>array-like of shape (n_obs) or (n_obs, n_models)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted values, e.g. for the conditional expectation of the response,
<code>E(Y|X)</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td>
                  <code>array-like of shape (n_obs) or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Case weights.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>etas</code></td>
            <td>
                  <code>int or array - like</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If an integer is given, equidistant points between min and max y values are
generater. If an array-like is given, those points are used.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>functional</code></td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The functional that is induced by the identification function <code>V</code>. Options are:</p>
<ul>
<li><code>"mean"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"median"</code>. Argument <code>level</code> is neglected.</li>
<li><code>"expectile"</code></li>
<li><code>"quantile"</code></li>
</ul>
              </div>
            </td>
            <td>
                  <code>&#39;mean&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>level</code></td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The level of the expectile of quantile. (Often called <span class="arithmatex">\(\alpha\)</span>.)
It must be <code>0 &lt; level &lt; 1</code>.
<code>level=0.5</code> and <code>functional="expectile"</code> gives the mean.
<code>level=0.5</code> and <code>functional="quantile"</code> gives the median.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ax</code></td>
            <td>
                  <code><span title="matplotlib.axes.Axes">Axes</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Axes object to draw the plot onto, otherwise uses the current Axes.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>ax</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either the matplotlib axes or the plotly figure. This is configurable by
setting the <code>plot_backend</code> via
<a class="autorefs autorefs-internal" href="../#model_diagnostics.set_config"><code>model_diagnostics.set_config</code></a> or
<a class="autorefs autorefs-internal" href="../#model_diagnostics.config_context"><code>model_diagnostics.config_context</code></a>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<details class="note" open>
  <summary>Notes</summary>
  <p><a href="" id="notes"></a>
For details, refer to <a href="" id="model_diagnostics.scoring.plot_murphy_diagram--notes"></a>
For details, refer to <code>[Ehm2015]</code>.</p>
</details>

<details class="references" open>
  <summary>References</summary>
  <dl>
<dt><code>[Ehm2015]</code></dt>
<dd>
<p>W. Ehm, T. Gneiting, A. Jordan, F. Krüger.
"Of Quantiles and Expectiles: Consistent Scoring Functions, Choquet
Representations, and Forecast Rankings".
<a href="https://arxiv.org/abs/1503.08195">arxiv:1503.08195</a>.</p>
</dd>
</dl>
</details>
            <details class="quote">
              <summary>Source code in <code>src/model_diagnostics/scoring/plots.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">plot_murphy_diagram</span><span class="p">(</span>
    <span class="n">y_obs</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">etas</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">functional</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">ax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Plot a Murphy diagram.</span>

<span class="sd">    A Murphy diagram plots the scores of elementary scoring functions `ElementaryScore`</span>
<span class="sd">    over a range of their free parameter `eta`. This shows, if a model dominates all</span>
<span class="sd">    others over a wide class of scoring functions or if the ranking is very much</span>
<span class="sd">    dependent on the choice of scoring function.</span>
<span class="sd">    See [Notes](#notes) for further details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y_obs : array-like of shape (n_obs)</span>
<span class="sd">        Observed values of the response variable.</span>
<span class="sd">        For binary classification, y_obs is expected to be in the interval [0, 1].</span>
<span class="sd">    y_pred : array-like of shape (n_obs) or (n_obs, n_models)</span>
<span class="sd">        Predicted values, e.g. for the conditional expectation of the response,</span>
<span class="sd">        `E(Y|X)`.</span>
<span class="sd">    weights : array-like of shape (n_obs) or None</span>
<span class="sd">        Case weights.</span>
<span class="sd">    etas : int or array-like</span>
<span class="sd">        If an integer is given, equidistant points between min and max y values are</span>
<span class="sd">        generater. If an array-like is given, those points are used.</span>
<span class="sd">    functional : str</span>
<span class="sd">        The functional that is induced by the identification function `V`. Options are:</span>

<span class="sd">        - `&quot;mean&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;median&quot;`. Argument `level` is neglected.</span>
<span class="sd">        - `&quot;expectile&quot;`</span>
<span class="sd">        - `&quot;quantile&quot;`</span>
<span class="sd">    level : float</span>
<span class="sd">        The level of the expectile of quantile. (Often called \(\alpha\).)</span>
<span class="sd">        It must be `0 &lt; level &lt; 1`.</span>
<span class="sd">        `level=0.5` and `functional=&quot;expectile&quot;` gives the mean.</span>
<span class="sd">        `level=0.5` and `functional=&quot;quantile&quot;` gives the median.</span>
<span class="sd">    ax : matplotlib.axes.Axes</span>
<span class="sd">        Axes object to draw the plot onto, otherwise uses the current Axes.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ax :</span>
<span class="sd">        Either the matplotlib axes or the plotly figure. This is configurable by</span>
<span class="sd">        setting the `plot_backend` via</span>
<span class="sd">        [`model_diagnostics.set_config`][model_diagnostics.set_config] or</span>
<span class="sd">        [`model_diagnostics.config_context`][model_diagnostics.config_context].</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    [](){#notes}</span>
<span class="sd">    For details, refer to `[Ehm2015]`.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    `[Ehm2015]`</span>

<span class="sd">    :   W. Ehm, T. Gneiting, A. Jordan, F. Krüger.</span>
<span class="sd">        &quot;Of Quantiles and Expectiles: Consistent Scoring Functions, Choquet</span>
<span class="sd">        Representations, and Forecast Rankings&quot;.</span>
<span class="sd">        [arxiv:1503.08195](https://arxiv.org/abs/1503.08195).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">()[</span><span class="s2">&quot;plot_backend&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>

            <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">mpl</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">Axes</span><span class="p">):</span>
        <span class="n">plot_backend</span> <span class="o">=</span> <span class="s2">&quot;matplotlib&quot;</span>
    <span class="k">elif</span> <span class="n">is_plotly_figure</span><span class="p">(</span><span class="n">ax</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>

        <span class="n">plot_backend</span> <span class="o">=</span> <span class="s2">&quot;plotly&quot;</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">ax</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;The ax argument must be None, a matplotlib Axes or a plotly Figure, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">n_cols</span> <span class="o">:=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n_cols</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y_obs</span> <span class="o">=</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Array-like y_obs has more than 2 dimensions, y_obs.shape[1]=</span><span class="si">{</span><span class="n">n_cols</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">y_pred_min</span><span class="p">,</span> <span class="n">y_pred_max</span> <span class="o">=</span> <span class="n">get_array_min_max</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">y_obs_min</span><span class="p">,</span> <span class="n">y_obs_max</span> <span class="o">=</span> <span class="n">get_array_min_max</span><span class="p">(</span><span class="n">y_obs</span><span class="p">)</span>
    <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">y_pred_min</span><span class="p">,</span> <span class="n">y_obs_min</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">y_pred_max</span><span class="p">,</span> <span class="n">y_obs_max</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">y_min</span> <span class="o">==</span> <span class="n">y_max</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;All values y_obs and y_pred are one single and same value.&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">etas</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="n">etas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">etas</span><span class="p">,</span> <span class="n">endpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">etas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">etas</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">etas</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">etas</span> <span class="o">=</span> <span class="n">etas</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">etas</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">elementary_score</span><span class="p">(</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="n">sf</span> <span class="o">=</span> <span class="n">ElementaryScore</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">functional</span><span class="o">=</span><span class="n">functional</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sf</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="n">n_pred</span> <span class="o">=</span> <span class="n">length_of_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">pred_names</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_sorted_array_names</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">)):</span>
        <span class="n">y_pred_i</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">get_second_dimension</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="n">y_plot</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">elementary_score</span><span class="p">(</span><span class="n">y_obs</span><span class="o">=</span><span class="n">y_obs</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred_i</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="n">eta</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">eta</span> <span class="ow">in</span> <span class="n">etas</span>
        <span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">pred_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">etas</span><span class="p">,</span> <span class="n">y_plot</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">add_scatter</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">etas</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_plot</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;lines&quot;</span><span class="p">,</span>
                <span class="n">line</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="n">get_plotly_color</span><span class="p">(</span><span class="n">i</span><span class="p">)},</span>
                <span class="n">name</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="n">xlabel</span> <span class="o">=</span> <span class="s2">&quot;eta&quot;</span>
    <span class="n">ylabel</span> <span class="o">=</span> <span class="s2">&quot;score&quot;</span>
    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Murphy Diagram&quot;</span>
    <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">title</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">pred_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">plot_backend</span> <span class="o">==</span> <span class="s2">&quot;matplotlib&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="n">ylabel</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">n_pred</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">showlegend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">xaxis_title</span><span class="o">=</span><span class="n">xlabel</span><span class="p">,</span> <span class="n">yaxis_title</span><span class="o">=</span><span class="n">ylabel</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ax</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; Christian Lorentzen 2022-present
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.sections", "navigation.expand", "navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "search.highlight"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>